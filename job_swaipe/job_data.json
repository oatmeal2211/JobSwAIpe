{"job_title":{"0":"Full Stack Data Scientist","1":"Senior AI Engineer","2":"Data Engineer","3":"Language Specialist","4":"Campus Hire 2024 - Algorithm Engineer","5":"Assct Data Insights Engineer (1011579)","6":"Senior Data Scientist","7":"Technical \/ Quantitative Analyst","8":"Machine Learning Engineer","9":"Data Scientist","10":"Internship for Data Analytics Students","11":"Data Analyst","12":"Data Scientist - Global Insurtech","13":"Data Governance Expert- Cloud","14":"Data Scientist","15":"Intermediate AI Engineer","16":"Senior Data Scientist","17":"IT Senior\/Engineer (Artificial Intelligence\/Machine Learning)","18":"Language Specialist - Chinese\/English","19":"System Analyst","20":"Senior AI Engineer","21":"Data Support Analyst","22":"BI & Data Analyst Executive","23":"System Analyst","24":"Campus Hire 2024 - Algorithm Engineer","25":"Big Data Engineer - Cloud","26":"Data Engineer","27":"Junior Data Engineer","28":"Big Data Engineer","29":"Data Analyst (Email Grader)","30":"Data Analyst (CRM)","31":"Senior Data Analyst","32":"Data Engineer Assistant","33":"Junior System Analyst (IT)","34":"Operations Research Scientist","35":"Senior Executive, Data Engineer","36":"System Analyst","37":"Business Analytics Executive","38":"Senior Data Engineer","39":"Programmer - Machine Learning","40":"Data Engineer - Leading Fintech Firm","41":"Data Engineer","42":"Engineer Information Technology - Production Data Warehouse","43":"Data Engineer (Junior to Mid level)","44":"Solution Analyst, Enterprise & Broadband Solutions (FTTH)","45":"Manager, Data Analytics","46":"Senior Data Engineer","47":"Data Engineer","48":"Data Analyst, 12 months extendable contract position","49":"Senior Executive, Research and Analytics","50":"Oracle Database administrator","51":"Data Scientist (Digital Technology Solutions)","52":"AI Specialist","53":"Artificial Intelligence (AI) Specialist","54":"Data Engineering and Analytics Specialist","55":"Senior Data Scientist (Analytics) - Ads","56":"Senior Staff Specialist Data Management","57":"BI Developer","58":"Executive, IT (BI)","59":"Database Engineer","60":"Data Center Project Engineer (Cloud BU)","61":"Machine Learning Engineer (Artificial Intelligence)","62":"Data Warehouse Engineer","63":"Data Scientist Manager","64":"Agronomist","65":"Data Analysis Specialist","66":"Internship - Digital Solutions Technology (IT) (Data Science\/AI)","67":"Data Scientist [up to 10k]","68":"Software Engineer (Data Support)","69":"Data Analyst","70":"Senior Machine Learning Engineer","71":"Data Scientist (Hybrid Working)","72":"SCM Data Scientist Analytics Team Lead (1-Yr-Contract)","73":"Executive, Data Analyst","74":"Data & Rsk Dcsn Anlytcs Mgr (1011519)","75":"Senior Manager, MIS Data Analytics","76":"Data Engineer","77":"Mechanical Engineer (Data Center)","78":"Data Engineer","79":"Systems and Database Manager","80":"RWA Analytics Mgr (1011656)","81":"People Analytics Specialist","82":"Internship, Data Analytics","83":"Senior Solution Architect","84":"Staff Engineer, Test Engineering","85":"Senior Solution Lead","86":"Data Engineer - ETL","87":"Data Engineer for Big Data Solutions (Semiconductor)","88":"IT Business Analyst","89":"IT BUSINESS ANALYST","90":"Research Analyst (80010)","91":"Application Support Analyst","92":"Senior Data Engineer","93":"Senior Engineer - Machine Learning Operations","94":"Data Engineer","95":"Intern - Data Science","96":"R&D Scientist","97":"Staff Engineer, Data Analytics Engineering","98":"Data Engineer","99":"The Most Profitable AI Side Hustle in Asia -Affiliate\/Trainer- Managers & UGrads","100":"Data Scientist - SEEK Pass (Hybrid Working)","101":"Full Stack Data Scientist","102":"Senior AI Engineer","103":"Data Engineer","104":"Language Specialist","105":"Campus Hire 2024 - Algorithm Engineer","106":"Assct Data Insights Engineer (1011579)","107":"Senior Data Scientist","108":"Technical \/ Quantitative Analyst","109":"Machine Learning Engineer","110":"Data Scientist","111":"Internship for Data Analytics Students","112":"Data Analyst","113":"Data Scientist - Global Insurtech","114":"Data Governance Expert- Cloud","115":"Data Scientist","116":"Intermediate AI Engineer","117":"Senior Data Scientist","118":"IT Senior\/Engineer (Artificial Intelligence\/Machine Learning)","119":"Language Specialist - Chinese\/English","120":"System Analyst","121":"Senior AI Engineer","122":"Data Support Analyst","123":"BI & Data Analyst Executive","124":"System Analyst","125":"Campus Hire 2024 - Algorithm Engineer","126":"Big Data Engineer - Cloud","127":"Data Engineer","128":"Junior Data Engineer","129":"Big Data Engineer","130":"Data Analyst (Email Grader)","131":"Data Analyst (CRM)","132":"Senior Data Analyst","133":"Data Engineer Assistant","134":"Junior System Analyst (IT)","135":"Operations Research Scientist","136":"Senior Executive, Data Engineer","137":"System Analyst","138":"Business Analytics Executive","139":"Senior Data Engineer","140":"Programmer - Machine Learning","141":"Data Engineer - Leading Fintech Firm","142":"Data Engineer","143":"Engineer Information Technology - Production Data Warehouse","144":"Data Engineer (Junior to Mid level)","145":"Solution Analyst, Enterprise & Broadband Solutions (FTTH)","146":"Manager, Data Analytics","147":"Senior Data Engineer","148":"Data Engineer","149":"Data Analyst, 12 months extendable contract position","150":"Senior Executive, Research and Analytics","151":"Oracle Database administrator","152":"Data Scientist (Digital Technology Solutions)","153":"AI Specialist","154":"Artificial Intelligence (AI) Specialist","155":"Data Engineering and Analytics Specialist","156":"Senior Data Scientist (Analytics) - Ads","157":"Senior Staff Specialist Data Management","158":"BI Developer","159":"Executive, IT (BI)","160":"Database Engineer","161":"Data Center Project Engineer (Cloud BU)","162":"Machine Learning Engineer (Artificial Intelligence)","163":"Data Warehouse Engineer","164":"Data Scientist Manager","165":"Agronomist","166":"Data Analysis Specialist","167":"Internship - Digital Solutions Technology (IT) (Data Science\/AI)","168":"Data Scientist [up to 10k]","169":"Software Engineer (Data Support)","170":"Data Analyst","171":"Senior Machine Learning Engineer","172":"Data Scientist (Hybrid Working)","173":"SCM Data Scientist Analytics Team Lead (1-Yr-Contract)","174":"Executive, Data Analyst","175":"Data & Rsk Dcsn Anlytcs Mgr (1011519)","176":"Senior Manager, MIS Data Analytics","177":"Data Engineer","178":"Mechanical Engineer (Data Center)","179":"Data Engineer","180":"Systems and Database Manager","181":"RWA Analytics Mgr (1011656)","182":"People Analytics Specialist","183":"Internship, Data Analytics","184":"Senior Solution Architect","185":"Staff Engineer, Test Engineering","186":"Senior Solution Lead","187":"Data Engineer - ETL","188":"Data Engineer for Big Data Solutions (Semiconductor)","189":"IT Business Analyst","190":"IT BUSINESS ANALYST","191":"Research Analyst (80010)","192":"Application Support Analyst","193":"Senior Data Engineer","194":"Senior Engineer - Machine Learning Operations","195":"Data Engineer","196":"Intern - Data Science","197":"R&D Scientist","198":"Staff Engineer, Data Analytics Engineering","199":"Data Engineer","200":"The Most Profitable AI Side Hustle in Asia -Affiliate\/Trainer- Managers & UGrads","201":"Data Scientist - SEEK Pass (Hybrid Working)","202":"Full Stack Data Scientist","203":"Senior AI Engineer","204":"Data Engineer","205":"Language Specialist","206":"Campus Hire 2024 - Algorithm Engineer","207":"Assct Data Insights Engineer (1011579)","208":"Senior Data Scientist","209":"Technical \/ Quantitative Analyst","210":"Machine Learning Engineer","211":"Data Scientist","212":"Internship for Data Analytics Students","213":"Data Analyst","214":"Data Scientist - Global Insurtech","215":"Data Governance Expert- Cloud","216":"Data Scientist","217":"Intermediate AI Engineer","218":"Senior Data Scientist","219":"IT Senior\/Engineer (Artificial Intelligence\/Machine Learning)","220":"Language Specialist - Chinese\/English","221":"System Analyst","222":"Senior AI Engineer","223":"Data Support Analyst","224":"BI & Data Analyst Executive","225":"System Analyst","226":"Campus Hire 2024 - Algorithm Engineer","227":"Big Data Engineer - Cloud","228":"Data Engineer","229":"Junior Data Engineer","230":"Big Data Engineer","231":"Data Analyst (Email Grader)","232":"Data Analyst (CRM)","233":"Senior Data Analyst","234":"Data Engineer Assistant","235":"Junior System Analyst (IT)","236":"Operations Research Scientist","237":"Senior Executive, Data Engineer","238":"System Analyst","239":"Business Analytics Executive","240":"Senior Data Engineer","241":"Programmer - Machine Learning","242":"Data Engineer - Leading Fintech Firm","243":"Data Engineer","244":"Engineer Information Technology - Production Data Warehouse","245":"Data Engineer (Junior to Mid level)","246":"Solution Analyst, Enterprise & Broadband Solutions (FTTH)","247":"Manager, Data Analytics","248":"Senior Data Engineer","249":"Data Engineer","250":"Data Analyst, 12 months extendable contract position","251":"Senior Executive, Research and Analytics","252":"Oracle Database administrator","253":"Data Scientist (Digital Technology Solutions)","254":"AI Specialist","255":"Artificial Intelligence (AI) Specialist","256":"Data Engineering and Analytics Specialist","257":"Senior Data Scientist (Analytics) - Ads","258":"Senior Staff Specialist Data Management","259":"BI Developer","260":"Executive, IT (BI)","261":"Database Engineer","262":"Data Center Project Engineer (Cloud BU)","263":"Machine Learning Engineer (Artificial Intelligence)","264":"Data Warehouse Engineer","265":"Data Scientist Manager","266":"Agronomist","267":"Data Analysis Specialist","268":"Internship - Digital Solutions Technology (IT) (Data Science\/AI)","269":"Data Scientist [up to 10k]","270":"Software Engineer (Data Support)","271":"Data Analyst","272":"Senior Machine Learning Engineer","273":"Data Scientist (Hybrid Working)","274":"SCM Data Scientist Analytics Team Lead (1-Yr-Contract)","275":"Executive, Data Analyst","276":"Data & Rsk Dcsn Anlytcs Mgr (1011519)","277":"Senior Manager, MIS Data Analytics","278":"Data Engineer","279":"Mechanical Engineer (Data Center)","280":"Data Engineer","281":"Systems and Database Manager","282":"RWA Analytics Mgr (1011656)","283":"People Analytics Specialist","284":"Internship, Data Analytics","285":"Senior Solution Architect","286":"Staff Engineer, Test Engineering","287":"Senior Solution Lead","288":"Data Engineer - ETL","289":"Data Engineer for Big Data Solutions (Semiconductor)","290":"IT Business Analyst","291":"IT BUSINESS ANALYST","292":"Research Analyst (80010)","293":"Application Support Analyst","294":"Senior Data Engineer","295":"Senior Engineer - Machine Learning Operations","296":"Data Engineer","297":"Intern - Data Science","298":"R&D Scientist","299":"Staff Engineer, Data Analytics Engineering","300":"Data Engineer","301":"The Most Profitable AI Side Hustle in Asia -Affiliate\/Trainer- Managers & UGrads","302":"Data Scientist - SEEK Pass (Hybrid Working)"},"company":{"0":"ISJ TECHNOLOGY SDN. BHD.","1":"Phillip Securities Pte Ltd","2":"Dialog Group Bhd","3":"Ebit Co., Ltd","4":"Lenovo","5":"RHB Banking Group","6":"Carsome Sdn Bhd","7":"Capital Dynamics Asset Management Sdn Bhd","8":"Intel Technology Sdn. Bhd.","9":"Always Marketing (M) Sdn. Bhd.","10":"Boardroom Corporate Services Sdn Bhd","11":"Magnum 4D Berhad","12":"WilliamSELECT","13":"Private Advertiser","14":"Keysight Technologies Malaysia Sdn. Bhd.","15":"1TPLUS SDN. BHD.","16":"SEEK","17":"ASE Electronics (M) Sdn Bhd","18":"Ebit Co., Ltd","19":"Michael Page International (Malaysia) Sdn Bhd","20":"1TPLUS SDN. BHD.","21":"WPP SUCCESS ENTERPRISE","22":"Zurich Insurance Malaysia Berhad","23":"Hong Kong Sa Sa (M) Sdn Bhd","24":"Lenovo","25":"Private Advertiser","26":"INCHOI SUPPORT SERVICE SDN BHD","27":"ALOHA ASIA (MY)  SDN. BHD.","28":"Intel Technology Sdn. Bhd.","29":"CENTIFIC GLOBAL SOLUTIONS (M) SDN. BHD.","30":"MHA Consultancy Services Sdn Bhd","31":"MHA Consultancy Services Sdn Bhd","32":"DPO International Sdn Bhd","33":"Flash Express","34":"Dassault Systemes Innovation Technologies Malaysia Sdn. Bhd.","35":"WhiteCoat Technologies Malaysia Sdn.Bhd","36":"Ann Joo Steel Berhad","37":"Linde Material Handling (M) Sdn Bhd","38":"Agensi Pekerjaan Hays (Malaysia) Sdn Bhd","39":"ACGT Sdn Bhd","40":"Pinpoint Asia","41":"Optimum Solutions (S) Pte Ltd","42":"Infineon Technologies (Malaysia) Sdn Bhd","43":"Unison Consulting Pte. Ltd.","44":"U Mobile Sdn Bhd","45":"Hong Leong MSIG Takaful Berhad","46":"Software International Corporation (M) Sdn Bhd","47":"PERSOLKELLY Workforce Solutions Malaysia Sdn Bhd","48":"PERSOLKELLY Workforce Solutions Malaysia Sdn Bhd","49":"Pembangunan Sumber Manusia Berhad","50":"Atos Services (M) Sdn Bhd","51":"Sunway Berhad","52":"iTTG Consultancy Sdn. Bhd.","53":"iFAST Global Hub AI Sdn Bhd","54":"Tune Protect Group Berhad","55":"GRAB","56":"Infineon Technologies (Kulim) Sdn Bhd","57":"Agensi Pekerjaan Hays (Malaysia) Sdn Bhd","58":"Lam Soon Edible Oils Sdn Bhd","59":"Intel Technology Sdn. Bhd.","60":"Private Advertiser","61":"FootfallCam","62":"OLA TECHNOLOGIES SDN BHD","63":"AGENSI PEKERJAAN LEWIS TALENT CONSULTING SDN. BHD.","64":"ASB Management Sdn Bhd","65":"ServiceOne Solutions Malaysia Sdn Bhd","66":"Fraser & Neave (F&N)","67":"Agensi Pekerjaan Randstad Sdn Bhd - Professional","68":"iZeno Sdn Bhd","69":"XDEN SDN BHD","70":"GRAB","71":"SEEK","72":"HopeRun Software Singapore Pte Ltd","73":"Bank Pertanian Malaysia Berhad (Agrobank)","74":"RHB Banking Group","75":"Prudential BSN Takaful Berhad","76":"Agensi Pekerjaan Hays (Malaysia) Sdn Bhd","77":"Princeton Digital Group (Singapore) SG1 Pte Ltd","78":"DKSH Malaysia Sdn Bhd","79":"TDCX Malaysia","80":"RHB Banking Group","81":"VAT Manufacturing Malaysia Sdn Bhd","82":"Malaysian Communications and Multimedia Commission","83":"FPT Software Malaysia Sdn. Bhd.","84":"Western Digital","85":"ANHSIN TECHNOLOGY SDN BHD","86":"UST Global (M) Sdn Bhd","87":"Robert Bosch Semiconductor Manufacturing Penang Sdn. Bhd.","88":"Intradeco Sdn Bhd","89":"Flexi Versa Group Sdn. Bhd.","90":"Sunway University","91":"Compart Systems Technologies (Malaysia) Sdn. Bhd.","92":"DKSH Malaysia Sdn Bhd","93":"GlobalFoundries","94":"Agensi Pekerjaan Hays (Malaysia) Sdn Bhd","95":"Sunway Property","96":"Agilent Technologies LDA Malaysia Sdn. Bhd.","97":"Western Digital","98":"Encora Technologies Sdn Bhd","99":"AI University","100":"SEEK","101":"ISJ TECHNOLOGY SDN. BHD.","102":"Phillip Securities Pte Ltd","103":"Dialog Group Bhd","104":"Ebit Co., Ltd","105":"Lenovo","106":"RHB Banking Group","107":"Carsome Sdn Bhd","108":"Capital Dynamics Asset Management Sdn Bhd","109":"Intel Technology Sdn. Bhd.","110":"Always Marketing (M) Sdn. Bhd.","111":"Boardroom Corporate Services Sdn Bhd","112":"Magnum 4D Berhad","113":"WilliamSELECT","114":"Private Advertiser","115":"Keysight Technologies Malaysia Sdn. Bhd.","116":"1TPLUS SDN. BHD.","117":"SEEK","118":"ASE Electronics (M) Sdn Bhd","119":"Ebit Co., Ltd","120":"Michael Page International (Malaysia) Sdn Bhd","121":"1TPLUS SDN. BHD.","122":"WPP SUCCESS ENTERPRISE","123":"Zurich Insurance Malaysia Berhad","124":"Hong Kong Sa Sa (M) Sdn Bhd","125":"Lenovo","126":"Private Advertiser","127":"INCHOI SUPPORT SERVICE SDN BHD","128":"ALOHA ASIA (MY)  SDN. BHD.","129":"Intel Technology Sdn. Bhd.","130":"CENTIFIC GLOBAL SOLUTIONS (M) SDN. BHD.","131":"MHA Consultancy Services Sdn Bhd","132":"MHA Consultancy Services Sdn Bhd","133":"DPO International Sdn Bhd","134":"Flash Express","135":"Dassault Systemes Innovation Technologies Malaysia Sdn. Bhd.","136":"WhiteCoat Technologies Malaysia Sdn.Bhd","137":"Ann Joo Steel Berhad","138":"Linde Material Handling (M) Sdn Bhd","139":"Agensi Pekerjaan Hays (Malaysia) Sdn Bhd","140":"ACGT Sdn Bhd","141":"Pinpoint Asia","142":"Optimum Solutions (S) Pte Ltd","143":"Infineon Technologies (Malaysia) Sdn Bhd","144":"Unison Consulting Pte. Ltd.","145":"U Mobile Sdn Bhd","146":"Hong Leong MSIG Takaful Berhad","147":"Software International Corporation (M) Sdn Bhd","148":"PERSOLKELLY Workforce Solutions Malaysia Sdn Bhd","149":"PERSOLKELLY Workforce Solutions Malaysia Sdn Bhd","150":"Pembangunan Sumber Manusia Berhad","151":"Atos Services (M) Sdn Bhd","152":"Sunway Berhad","153":"iTTG Consultancy Sdn. Bhd.","154":"iFAST Global Hub AI Sdn Bhd","155":"Tune Protect Group Berhad","156":"GRAB","157":"Infineon Technologies (Kulim) Sdn Bhd","158":"Agensi Pekerjaan Hays (Malaysia) Sdn Bhd","159":"Lam Soon Edible Oils Sdn Bhd","160":"Intel Technology Sdn. Bhd.","161":"Private Advertiser","162":"FootfallCam","163":"OLA TECHNOLOGIES SDN BHD","164":"AGENSI PEKERJAAN LEWIS TALENT CONSULTING SDN. BHD.","165":"ASB Management Sdn Bhd","166":"ServiceOne Solutions Malaysia Sdn Bhd","167":"Fraser & Neave (F&N)","168":"Agensi Pekerjaan Randstad Sdn Bhd - Professional","169":"iZeno Sdn Bhd","170":"XDEN SDN BHD","171":"GRAB","172":"SEEK","173":"HopeRun Software Singapore Pte Ltd","174":"Bank Pertanian Malaysia Berhad (Agrobank)","175":"RHB Banking Group","176":"Prudential BSN Takaful Berhad","177":"Agensi Pekerjaan Hays (Malaysia) Sdn Bhd","178":"Princeton Digital Group (Singapore) SG1 Pte Ltd","179":"DKSH Malaysia Sdn Bhd","180":"TDCX Malaysia","181":"RHB Banking Group","182":"VAT Manufacturing Malaysia Sdn Bhd","183":"Malaysian Communications and Multimedia Commission","184":"FPT Software Malaysia Sdn. Bhd.","185":"Western Digital","186":"ANHSIN TECHNOLOGY SDN BHD","187":"UST Global (M) Sdn Bhd","188":"Robert Bosch Semiconductor Manufacturing Penang Sdn. Bhd.","189":"Intradeco Sdn Bhd","190":"Flexi Versa Group Sdn. Bhd.","191":"Sunway University","192":"Compart Systems Technologies (Malaysia) Sdn. Bhd.","193":"DKSH Malaysia Sdn Bhd","194":"GlobalFoundries","195":"Agensi Pekerjaan Hays (Malaysia) Sdn Bhd","196":"Sunway Property","197":"Agilent Technologies LDA Malaysia Sdn. Bhd.","198":"Western Digital","199":"Encora Technologies Sdn Bhd","200":"AI University","201":"SEEK","202":"ISJ TECHNOLOGY SDN. BHD.","203":"Phillip Securities Pte Ltd","204":"Dialog Group Bhd","205":"Ebit Co., Ltd","206":"Lenovo","207":"RHB Banking Group","208":"Carsome Sdn Bhd","209":"Capital Dynamics Asset Management Sdn Bhd","210":"Intel Technology Sdn. Bhd.","211":"Always Marketing (M) Sdn. Bhd.","212":"Boardroom Corporate Services Sdn Bhd","213":"Magnum 4D Berhad","214":"WilliamSELECT","215":"Private Advertiser","216":"Keysight Technologies Malaysia Sdn. Bhd.","217":"1TPLUS SDN. BHD.","218":"SEEK","219":"ASE Electronics (M) Sdn Bhd","220":"Ebit Co., Ltd","221":"Michael Page International (Malaysia) Sdn Bhd","222":"1TPLUS SDN. BHD.","223":"WPP SUCCESS ENTERPRISE","224":"Zurich Insurance Malaysia Berhad","225":"Hong Kong Sa Sa (M) Sdn Bhd","226":"Lenovo","227":"Private Advertiser","228":"INCHOI SUPPORT SERVICE SDN BHD","229":"ALOHA ASIA (MY)  SDN. BHD.","230":"Intel Technology Sdn. Bhd.","231":"CENTIFIC GLOBAL SOLUTIONS (M) SDN. BHD.","232":"MHA Consultancy Services Sdn Bhd","233":"MHA Consultancy Services Sdn Bhd","234":"DPO International Sdn Bhd","235":"Flash Express","236":"Dassault Systemes Innovation Technologies Malaysia Sdn. Bhd.","237":"WhiteCoat Technologies Malaysia Sdn.Bhd","238":"Ann Joo Steel Berhad","239":"Linde Material Handling (M) Sdn Bhd","240":"Agensi Pekerjaan Hays (Malaysia) Sdn Bhd","241":"ACGT Sdn Bhd","242":"Pinpoint Asia","243":"Optimum Solutions (S) Pte Ltd","244":"Infineon Technologies (Malaysia) Sdn Bhd","245":"Unison Consulting Pte. Ltd.","246":"U Mobile Sdn Bhd","247":"Hong Leong MSIG Takaful Berhad","248":"Software International Corporation (M) Sdn Bhd","249":"PERSOLKELLY Workforce Solutions Malaysia Sdn Bhd","250":"PERSOLKELLY Workforce Solutions Malaysia Sdn Bhd","251":"Pembangunan Sumber Manusia Berhad","252":"Atos Services (M) Sdn Bhd","253":"Sunway Berhad","254":"iTTG Consultancy Sdn. Bhd.","255":"iFAST Global Hub AI Sdn Bhd","256":"Tune Protect Group Berhad","257":"GRAB","258":"Infineon Technologies (Kulim) Sdn Bhd","259":"Agensi Pekerjaan Hays (Malaysia) Sdn Bhd","260":"Lam Soon Edible Oils Sdn Bhd","261":"Intel Technology Sdn. Bhd.","262":"Private Advertiser","263":"FootfallCam","264":"OLA TECHNOLOGIES SDN BHD","265":"AGENSI PEKERJAAN LEWIS TALENT CONSULTING SDN. BHD.","266":"ASB Management Sdn Bhd","267":"ServiceOne Solutions Malaysia Sdn Bhd","268":"Fraser & Neave (F&N)","269":"Agensi Pekerjaan Randstad Sdn Bhd - Professional","270":"iZeno Sdn Bhd","271":"XDEN SDN BHD","272":"GRAB","273":"SEEK","274":"HopeRun Software Singapore Pte Ltd","275":"Bank Pertanian Malaysia Berhad (Agrobank)","276":"RHB Banking Group","277":"Prudential BSN Takaful Berhad","278":"Agensi Pekerjaan Hays (Malaysia) Sdn Bhd","279":"Princeton Digital Group (Singapore) SG1 Pte Ltd","280":"DKSH Malaysia Sdn Bhd","281":"TDCX Malaysia","282":"RHB Banking Group","283":"VAT Manufacturing Malaysia Sdn Bhd","284":"Malaysian Communications and Multimedia Commission","285":"FPT Software Malaysia Sdn. Bhd.","286":"Western Digital","287":"ANHSIN TECHNOLOGY SDN BHD","288":"UST Global (M) Sdn Bhd","289":"Robert Bosch Semiconductor Manufacturing Penang Sdn. Bhd.","290":"Intradeco Sdn Bhd","291":"Flexi Versa Group Sdn. Bhd.","292":"Sunway University","293":"Compart Systems Technologies (Malaysia) Sdn. Bhd.","294":"DKSH Malaysia Sdn Bhd","295":"GlobalFoundries","296":"Agensi Pekerjaan Hays (Malaysia) Sdn Bhd","297":"Sunway Property","298":"Agilent Technologies LDA Malaysia Sdn. Bhd.","299":"Western Digital","300":"Encora Technologies Sdn Bhd","301":"AI University","302":"SEEK"},"descriptions":{"0":"Collect, clean, and preprocess data from various sources.\nDevelop, train, and deploy machine learning models to solve business problems.\nUtilize statistical analysis and data mining techniques to derive actionable insights.\nCommunicate findings to stakeholders through data visualization and presentations.\nCollaborate with the full-time data engineer to design and maintain data pipelines.\nEnsure data integrity and quality through robust validation and processing mechanisms.\nImplement data aggregation and enhancement processes to support analytics.\nContribute to the development of AI products.\nContinuously refine and optimize machine learning models for production use.\nMonitor and maintain deployed models to ensure optimal performance.\nCandidate must possess at least Diploma or Bachelor\u2019s or Master\u2019s degree in Data Science, Computer Science, Statistics, or a related field.\nAt least 3 year(s) \nof relevant experience in data science, machine learning, and data engineering.\nProficiency in programming languages such as Python and SQL.\nExperience with machine learning frameworks and libraries (e.g., Scikit-learn, TensorFlow, PyTorch).\nStrong understanding of statistical analysis and data modelling techniques.\nFamiliarity with data visualization tools (e.g., Tableau, Power BI) and data management systems.\nKnowledge of data engineering best practices and tools (e.g., Apache Spark, Hadoop).\nExcellent problem-solving and analytical skills.\nStrong communication skills, both written and verbal, with the ability to convey technical concepts to non-technical stakeholders.\nAbility to work independently and as part of a team in a fast-paced environment.\nStrong communication skills, both written and verbal in English. Fluency in Mandarin is a plus.\nThe Ascent @ Paradigm Mall\nMonday - Friday (Flexible working hours)\n13th month salary\nEPF \/ SOCSO \/ PCB.\nMedical, Dental and Optical benefits.\nFree-flow snacks and drinks in office pantry.\nSmart casual working attire.\nFull Attendance Allowance.\nFree Parking.\nYoung, vibrant and open work culture.\nHow many years' experience do you have as a data scientist?\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nHave you worked in a role which requires experience with machine learning?\nWhich of the following languages are you fluent in?\nHow much notice are you required to give your current employer?\nHow many years' experience do you have as a Data Engineer?","1":"Which of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as an Artificial Intelligence Engineer?\nWhich of the following programming languages are you experienced in?\nHave you worked in a role which requires experience with machine learning?\nHow many years' experience do you have as an Artificial Intelligence Specialist?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","2":"Design and development of data engineering, analytics and integration roadmap, aligned with our long-term business goals.\nPartner with business stakeholders to understand their data needs and translate them into actionable data strategies.\nDesign and implement a scalable data infrastructure, including data warehouses, data lakes, and data pipelines.\nSelect and implement appropriate data governance policies and procedures to ensure data quality, security, and compliance.\nChampion a culture of data literacy across the organization by establishing training programs and promoting best practices.\nStay current with emerging data technologies and trends, recommending solutions that optimize our data utilization.\nGather requirements and specifications during project development lifecycle from\u00a0 technical stakeholder\/users\nGather\u00a0technical stakeholder\/users expectations and limitations\nEvaluate existing systems and programs to recognize areas for improvement and integration.\nDevelop solutions based on the defined schedules and test plans, prepare analyst reports, and ensure adherence to project guidelines and objectives\nIdentify potential issues between systems and\u00a0 technical stakeholder\/users specifications and propose new solutions to work around these limitations.\nExamine technical stakeholder\/users\u2019s existing systems and configurations to ensure projects are uniform with enterprise-level systems.\nResolve issues regarding specifications and requirements\nInterface with technical stakeholder\/users to provide feedback and updates on development projects.\nGather information to prepare reports and presentations to update technical stakeholder\/users on development of projects\u00a0\nDegree in Computer Science, Information Technology, or a related field\nMinimum 3 years of experience as a Data Engineer or in a similar data-focused role\nProficient in data engineering tools and technologies such as SQL, Apache Spark, and cloud-based data platforms (e.g., AWS, Azure)\nStrong understanding of data modelling, ETL processes, and data warehousing principles.(Power BI experience is added advantage).\nExperience in building and maintaining reliable and scalable data pipelines\nExcellent problem-solving and analytical skills, with the ability to turn complex data into actionable insights\nHands-on experience with data security and privacy best practices\nExcellent communication and collaboration skills to work effectively with cross-functional teams\nCompetitive salary and performance-based bonuses\nComprehensive medical and insurance benefits\nOpportunities for career growth and professional development\nCollaborative and inclusive work culture\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Data Engineer?\nWhich of the following data analytics tools are you experienced with?","3":"Rating : Rate an AI generated response based on given criteria, and provide justification.\u00a0\nPrompt writing : Create a prompt following the instruction given.\nResponse writing : Create a model response for a given prompt\nWhich of the following languages are you fluent in?\nHow would you rate your English language skills?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","4":"Design and implement generative and analytical AI projects.\nAnalyze complex data sets to identify patterns, trends, and insights.\nCollaborate with cross-functional teams to integrate AI solutions across various applications.\nConduct research to remain at the forefront of advancements in AI technologies.\nProven expertise in AI development and deployment.\nStrong background in data feature analysis and machine learning algorithms.\nExperience with large datasets, developing models that yield actionable insights.\nProficiency in AI-related programming languages and tools, including Python, TensorFlow, and PyTorch.\nDegree or higher in Computer Science, Data Science, or a related field.\nWhich of the following statements best describes your right to work in Malaysia?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as an Algorithm Engineer?\nHave you worked in a role which requires experience with machine learning?\nWhich of the following languages are you fluent in?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","5":" \nAnalyze and interpret complex data, transforming it into actionable insights that can drive informed decision-making within organization.\u00a0\n \nInvolves in schema and architecture design, developing data pipelines, ensuring data quality, and using effective tools to extract meaningful patterns and trends from large datasets.\u00a0\n\n\n \nClearly communicate technical concepts and data insights to both technical and non-technical audiences, provide valuable information that helps to improve business strategies and outcomes.\n\n\n \nData Analysis: Analyzing large datasets to conduct in-depth data analysis to extract and derive meaningful insights and trends.\u00a0\n \nData Visualization: Creating clear and effective visualizations to communicate insights with business teams.\u00a0\n\n\n \nCreate metadata for datasets to facilitate data discovery and understanding by users.\u00a0\n\n\n \nCollaborate with business teams or management teams to establish business needs by recommending solutions and delivering insights to increase productivity.\u00a0\n\n\n \nCoordinate with cross-functional teams and stakeholders to understand business requirements, design and implement data products, and monitor outcomes to provide additional value to the organization.\u00a0\n\n\n \nDevelop and implement strategies to enhance data reliability and source ability.\u00a0\n\n\n \nA min. of 0-3 years experience (banking & insurance experience is a plus)\u00a0\n\n\n \nKnowledge of relational databases and a good command of SQL\u00a0\n\n\n \nUnderstanding of basic data pipeline design, including data extraction, transformation, and loading processes.\u00a0\n\n\n \nStrong analytical and problem-solving skills.\n\n\n \nProficiency in programming languages:\u202fSAS, Python,\u202fSQL etc.\u00a0\n\n\n \nBig Data Technologies:\u202fHands-on experience with Hadoop,\u202fSpark or similar technologies for large-scale data processing.\u00a0\n\n\n \nData Quality and Testing:\u202fUnderstanding of data quality checks,\u202fmonitoring,\u202fand testing procedures.\u00a0\n\n\n \nBasic knowledge of data visualization tools (e.g. Tableau, Power BI).\u00a0\n\n\n \nUnderstanding of statistical analysis, machine learning concepts, modeling conceptual ideas and database management.\u00a0\n\n","6":"Understand business processes deeply, identify opportunities where data science can add value, and solve problems using advanced statistical analyses or machine learning techniques as necessary, including prescriptive analytics and predictive modelling\nInitiate, design and lead projects to maximise business impact with the right data driven solution across business functions, including pricing and inventory (e.g. price prediction and optimization), operations (e.g. computer vision automation), customer conversion (e.g. recommendation and personalisation engine), etc.\nResponsible for ensuring successful end-to-end delivery and maintenance of machine learning, data science and AI initiatives, including measurement of model performance in action and monitoring for drifts over time\nWork with MLOps engineers in developing machine learning pipelines to streamline and automate the deployment of models. Ensure timely high standard delivery of output and documentation\nDesign and execute experiments iteratively to improve the performance of data science solutions deployed\nPropose framework and drive hypothesis validation, ensuring statistically sound decision making from proper A\/B test setups whenever feasible\nWork with Product & Tech teams across organisations to enhance data collection process as necessary\nInnately curious, highly analytical and enjoy distilling complex business problems into technical requirements and find answers in the data\nAt least 3 years of practical experience in data science, advanced business analytics, machine learning, AI or computer vision\nExperience in the complete modelling lifecycle, from ideation to deployment and continual monitoring and maintenance\nProficient in Python and\/or R. Preferably Python\nComfortable using SQL for data exploration, and analysis. Preferably familiar with Google BigQuery or similar\nResult-oriented and resourceful. You can cut to the core of a problem, identify what needs to be done, and work with the teams to make things happen\nConstructive communication of ideas, issues, and solutions in a team environment\nSelf-starter who is extremely motivated to continue learning and growing, able to pick up new skills quickly\nExperience in MLOps framework, cloud services by AWS\/ GCP, Tensorflow\/ Pytorch will be an advantage.\nExperience in the automotive or e-commerce industry\nExperience working at a tech startup or fast-growing organisation\nExperience in computer vision or AI research\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a data scientist?\nWhich of the following programming languages are you experienced in?\nHow many years' experience do you have using SQL queries?\nHave you worked in a role which requires experience with machine learning?","7":"\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","8":"\n\nExplore and path-find solutions to complex business problems, coordinate concept proving and pilot testing. Works closely with business stakeholder, observations to find patterns and relationships in data.\n\n\nInteracts with users and users leadership to define requirements and plans for breakthrough product\/solutions. In either research environments or specific product environments, utilizes current programming methodologies to translate machine learning models and data processing methods into software.\n\n\nBuilds machine learning workflows and infrastructure necessary to productize AI platforms, self-service AI solutions, or AI models and sustain them in production.\n\n\nResponsible for preparing data for ML models at scale, building appropriate inference interfaces for ML model consumption, enabling ML Ops for continuous delivery and automation of ML pipelines, and\/or building and sustaining AI production platforms.\n\n\nEnable MLOps for scaled\/POR integration, deployment, adoption and support.\n\n\n\n\nCandidate must have at least 5+ years of working experience.\n\n\nHas degree in Computer Science, Mathematics, Machine Learning, Al, Optimization, Operation Research, Statistics or equivalent.\n\n\nIndependent and self-driven individuals with a must have deep knowledge in machine learning algorithms and applying to solve problems in various disciplines. Deep expertise in Python, Tensorflow, Large Language Model, CNVRG, ELK, Kubernetes, KubeFlow, Scripting, SQL queries, and related software.\n\n\nAbility to build data ingestion libraries from heterogeneous data sources including Postgres SQL, MS SQL, Excel, Oracle, Json, Teradata, etc.\n\n\nExperience in AI or software solution architecture design, and development will be an added advantage.\n\n\nSkilled in programming, testing, debugging, documentation and\/or deployment of the solution\/products.\n\n\nHave strong understanding of manufacturing business segment stakeholders and possess strong written and communication skills. Project\/program management experience will have an added advantage.\n\n\nCuriosity and endless desire to learn, along with passion for solving intricate business problems using data science\n\n\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","9":"Work closely with our IT team to identify issues and use data to propose solutions for effective decision-making.\nAssess the effectiveness of data sources and data-gathering techniques and improve data collection methods.\nBuild algorithms and design experiments to merge, manage, interrogate and extract data to supply quality data for machine learning.\nUse machine learning tools and statistical techniques to produce solutions to problems.\nTest data mining models to select the most appropriate ones for use on a project.\nMaintain clear and coherent communication, both verbal and written, to understand data needs and report results.\nHorizon scan to stay up to date with the latest technology, techniques and methods.\nConduct research from which you'll develop prototypes and proof of concepts.\nExploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real world\nSupervising the data acquisition process. Establish new systems and processes and look for opportunities to improve the flow of data\nLook for opportunities to use insights\/datasets\/code\/models across other functions to provide strategic solutions\nStay curious and enthusiastic about using algorithms to solve problems and enthuse others to see the benefit of your work.\nStrong interest in latest Machine Learning Research\nExperience with Azure, AWS or Google Cloud\nExperience with computer vision, object detection and\/or multi-object tracking\nStrong analytical and problem-solving skills.\nExcellent interpersonal and communication skills.\nBachelor\u2019s degree in Data Science \/ Computer science \/ Information Technology or a related subject and\/or equivalent formal training or work experience.\nCareer growth & learning opportunities\nOutpatient, dental & optical, medical insurance\nSpecial leaves\nLong established company with headquarters in Shanghai & Hong Kong\nWhich of the following types of qualifications do you have?\nHave you worked in a role which requires experience with machine learning?","10":"Problem-solving and analytical understanding for statistics and data.\u00a0\nTechnical skills and competency in using data analytics software like Excel, Salesforce, others.\u00a0\nContinuously strive for ways to improve operational efficiency, develop reports, and maintain spreadsheets\/data metrics to monitor, track, and evaluate performance.\nSupport and provide technical assistance for inquiries and issues.\nOppo conversion knowledge will be added advantage.\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","11":"Analyze customer data to identify trends, patterns, and opportunities.\u00a0\nDevelop insights to guide customer acquisition, retention, and engagement strategies.\u00a0\nAlign data analysis with departmental objectives to support business growth.\u00a0\nDesign and develop analytical modules that streamline data processing and reporting for sales and campaign performances.\u00a0\nCollaborate with Tech team to implement and maintain these modules.\u00a0\nEnsure scalability and adaptability of modules for various business applications.\u00a0\u00a0\nExtract data from various sources including database, APIs and flat files.\u00a0\nCreate compelling data visualizations that communicate key insights effectively.\u00a0\nUtilize platforms such as Qlik Sense , Tableau, Power BI, Excel or similar tools to develop dashboards and reports.\u00a0\nContinuously refine visualization techniques for clarity and impact to all business units.\u00a0\nGenerate reports and presentations that summarizes key findings and suggests recommendations.\u00a0\nSupport strategic planning with data-driven insights and forecasts.\u00a0\nMonitor and report on KPIs to assess the effectiveness of customer strategies.\u00a0\nEnsure the integrity and security of data by following company\u2019s policies with regular check and audits.\u00a0\nMaintain comprehensive records and documentation on data sources, data processes, findings, assumptions.\u00a0\u00a0\nWork closely with cross-functional teams, including Operations, Digital Asset, Technology, and Product.\u00a0\nCommunicate complex data findings clearly to both technical and non-technical stakeholders.\u00a0\nProvide training and support on data analysis tools and best practices.\u00a0\nCollaborate with regional teams to understand customer needs, market trends, and the rollout of new technologies and services, providing strategic and tactical product recommendations with active discussions.\u00a0\nMaintain a close working relationship with HOD and team members plus other business unit stakeholders on all matters pertaining to, including but not limited to execution and reporting of the company\u2019s customer acquisition campaign.\u00a0\nExecutes departmental tasks and achieve targets set on departmental key result areas (KRAs) and key performance indexes (KPIs) with productive participation and support.\u00a0\nStay updated with the latest trends in data analysis, visualization, and customer strategy.\u00a0\nSeek continuous improvement in processes, tools, and methodologies.\u00a0\nParticipate in professional development to enhance skills and knowledge.\u00a0\nFollow the Company's code of conduct, policies, procedures, and lawful directions related to employment and duties.\u00a0\nPerform any additional tasks as directed by management from time to time.\u00a0\n3+ years of experience in data analysis, preferably in a customer-centric or strategic role.\u00a0\nStrong experience with data visualization tools (e.g., Qlik Sense, Tableau, Power BI).\u00a0\nProficiency in data analytic tools such as SQL, Python, R, or similar.\u00a0\nKnowledge of statistical analysis and predictive modelling techniques.\u00a0\nFamiliarity with CRM systems and customer data is an advantage.\u00a0","12":"Analyse Data:\n Extract insights from large datasets to inform business strategies\nDevelop Models:\n Create predictive models for risk assessments, customer behaviour, fraud detection, etc\nEnhance Personalization:\n Build algorithms to tailor insurance products to individual needs\nCollaboration: \nWork directly with cross- functional teams (Business and IT)\nAdvanced Python and SQL skills. \u00a0Python packages such as NumPy, pandas, matplotlib, scikit-learn, etc.\nCloud environment in either AWS or GCP\nSolid experience in GenAI and\/or MLOps is an advantage\n4+ years in data science\/ machine engineering working experience\nEducation in mathematics, statistics, data science or equivalent\nProven experience in handling end to end data science projects\nCollaborative and think outside of the box mindset\nLanguage in written and spoken English\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a data scientist?\nWhich of the following programming languages are you experienced in?\nDo you have experience with multi-variate and A\/B testing methodologies?","13":"Which of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","14":"End-to-end delivery of data analytics projects including project framework, analysis technique and implementation of data science models\nAnalyse and interpret large volume and complex datasets to extract insights, trends, and patterns, helping organizations make data-driven decisions.\nIntegrate external factor and global context into analytical models to enhance predictive accuracy and provide a broader context for decision making.\nApply various data science technologies: statistical analysis, machine learning and pattern recognition with subject-specific modelling to address opportunities in business performance and achieve supply chain efficiencies.\nDesign experiments and statistical tests to validate hypotheses.\nPresent findings to non-technical stakeholders in a clear and understandable manner\nA bachelor's degree in a quantitative field such as Data Science, Statistics, Mathematics, Physics, or related fields, with a \nminimum of 5 working years of experience.\nStrong background in statistics and probability theory is essential for analyzing and interpreting complex data.\nProficiency in programming languages commonly used in data science, such as Python or R. Familiarity with tools like SQL for database querying is also valuable.\nUnderstanding and practical experience with machine learning techniques and algorithms. This includes supervised and unsupervised learning, regression, classification, clustering, and more.\nAbility to create meaningful visualizations to communicate complex findings effectively. Familiarity with tools like Matplotlib, Seaborn, or Tableau can be beneficial.\nStrong communication skills to explain complex technical findings to non-technical stakeholders and decision-makers.\nHaving supply chain knowledge will be an added advantage.\nHow many years' experience do you have as a data scientist?\nDo you have a Bachelor Degree?","15":"Model Development:\n Design and implement AI models, such as LSTM, transformer-based architectures (LLaMA, GPT, etc.), or other relevant machine learning algorithms, tailored to trading systems and market analysis.\nAlgorithm Development:\n Implement and optimize algorithms that improve the speed and accuracy of trade decisions, focusing on high-performance, real-time models that can be deployed in production environments.\nData Analysis:\n Preprocess and analyze financial data, including historical market data, technical indicators, and other data sources to develop features and training datasets for AI models.\nTrade Decision Enhancement:\n Build models that assist in predicting market trends, identifying trading opportunities, and optimizing trade execution strategies, focusing on improving decision accuracy.\nBacktesting and Evaluation:\n Conduct backtesting of AI models using historical data, and continuously refine models based on performance metrics. Use tools like precision, recall, and confusion matrices to ensure model robustness.\nCollaboration with Trading Team:\n Work closely with traders and engineers to understand trading strategies and ensure seamless integration of AI solutions with the trading algorithms and systems.\nOptimization:\n Fine-tune and optimize models to ensure they are computationally efficient, accurate, and scalable to handle real-time data and decision-making processes.\nContinuous Learning:\n Stay updated with advancements in AI, machine learning, and financial technology, and incorporate cutting-edge techniques into the model development process.\nDocumentation:\n Maintain comprehensive documentation for AI models, data pipelines, and integration processes, ensuring clarity and reproducibility.\nEducational Background:\n Bachelor\u2019s Degree in Computer Science, Data Science, AI\/ML Engineering, or a related field (or equivalent work experience).\nExperience:\n Minimum of 2 years of experience working in AI\/ML model development, with hands-on experience in LSTM, transformers, or other deep learning architectures.\nTechnical Skills:\nProficiency in Python and machine learning frameworks such as TensorFlow, PyTorch, or Keras.\nExperience with \ntime-series analysis\n and \nsequence modeling\n (e.g., LSTM, GRU).\nFamiliarity with transformer-based models (e.g., \nLLaMA, GPT\n), and their applications in trade decision analysis.\nStrong knowledge of \ndata preprocessing\n, feature engineering, and model evaluation techniques.\nExperience with \nfinancial market data\n and \ntrading algorithms\n is a plus.\nFamiliarity with cloud platforms (AWS, GCP, etc.) for training and deploying AI models.\nProficiency in working with large datasets and database technologies (SQL, NoSQL).\nProficiency in Python and machine learning frameworks such as TensorFlow, PyTorch, or Keras.\nExperience with \ntime-series analysis\n and \nsequence modeling\n (e.g., LSTM, GRU).\nFamiliarity with transformer-based models (e.g., \nLLaMA, GPT\n), and their applications in trade decision analysis.\nStrong knowledge of \ndata preprocessing\n, feature engineering, and model evaluation techniques.\nExperience with \nfinancial market data\n and \ntrading algorithms\n is a plus.\nFamiliarity with cloud platforms (AWS, GCP, etc.) for training and deploying AI models.\nProficiency in working with large datasets and database technologies (SQL, NoSQL).\nAdditional Skills:\nUnderstanding of financial markets, technical analysis, and trading strategies.\nStrong mathematical and statistical foundation in probability, time-series modeling, and optimization techniques.\nExperience with tools for data visualization and performance tracking (e.g., Matplotlib, Plotly, MLFlow).\nKnowledge of \nmachine learning lifecycle management\n and MLOps practices.\nUnderstanding of financial markets, technical analysis, and trading strategies.\nStrong mathematical and statistical foundation in probability, time-series modeling, and optimization techniques.\nExperience with tools for data visualization and performance tracking (e.g., Matplotlib, Plotly, MLFlow).\nKnowledge of \nmachine learning lifecycle management\n and MLOps practices.\nStrong analytical and problem-solving skills, with the ability to work independently and deliver results.\nAbility to collaborate effectively with cross-functional teams, including traders, developers, and data engineers.\nA passion for learning new AI techniques and applying them to real-world financial problems.\nGood communication skills, with the ability to explain complex technical concepts to non-technical stakeholders.\nAttention to detail and a proactive attitude toward model refinement and improvement.\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as an Artificial Intelligence Engineer?\nWhich of the following programming languages are you experienced in?\nHave you worked in a role which requires experience with machine learning?\nHow many years' experience do you have using SQL queries?\nWhich of the following Relational Database Management Systems (RDBMS) are you experienced with?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","16":"Forming clear data addressable problem statements from current business problems\nResearch, build, deploy and maintain RecommendationsAI solutions integrated with recruitment products aiming to properly connect candidates to recruiters\nImprove the chances of matching (job placements) to leverage our AI platform to the next level\nCollaborate with Strategy, Product, Data Science and Software Development teams to address a variety of challenging business problems\nLead the formulation, development, deployment, and testing of new solutions\nExplore new methodologies and technologies to address R&D problems in a truly collaborative way\nA Bachelor, MSc or PhD qualification in Computer Science, Computational Physics, Mathematics, Statistics or a related field\nProfessional experience in one of the following programming languages:\nLarge scale development using Python, Go, C\/C++, or Java\nAbility to perform data exploratory analysis for proof of concepts and to communicate the results to a diverse audience\nGood communication and interpersonal skills\nLarge scale development using Python, Go, C\/C++, or Java\nStrong background in:\nAlgorithms and data structures\nInformation Retrieval\nMachine Learning\nPractice with\nSearch engine such as Elasticsearch or SOLR;\nRelational database such as MySQL or PostgreSQL;\nAmazon Web Services (e.g. EC2, ELB, S3, VPC, Route 53);\nDistributed processing framework such as Hadoop or Spark;\nContainer package such as Docker;\nKnowledge in:\nRecommender Systems\nData Mining\nNatural Language Processing\nOptimization\nDeep Learning\nAbility to adapt quickly and manage an environment of rapid change and development\nAlgorithms and data structures\nInformation Retrieval\nMachine Learning\nSearch engine such as Elasticsearch or SOLR;\nRelational database such as MySQL or PostgreSQL;\nAmazon Web Services (e.g. EC2, ELB, S3, VPC, Route 53);\nDistributed processing framework such as Hadoop or Spark;\nContainer package such as Docker;\nRecommender Systems\nData Mining\nNatural Language Processing\nOptimization\nDeep Learning\nAbility to adapt quickly and manage an environment of rapid change and development\nMature and collaborative work culture and environment\nHybrid work mode\nExtended employee benefits","17":"Work with stakeholders to define the scope, requirements, processes and procedures to ensure the success of artificial intelligence and machine learning (AI\/ML) projects.\nCreate and deliver data-driven solutions that add business value using statistical models, machine learning algorithms, data mining and visualization techniques.\nCollect, organize and analyze large complex, structured\/unstructured, diverse big data.\nDevelop scripts to automate processes to cleanse, integrate and evaluate large datasets from disparate data sources.\nIdentify data trends, patterns and insights through statistical analysis and machine learning techniques.\nDesign, develop and implement statistical models and machine learning algorithms.\nDevelop predictive models to solve complex business problems.\nContinuously evaluate and improve the performance of existing models and algorithms.\nMaster or Bachelor Degree in Computer Science, Data Science, Mathematics, Statistics\/Operations Research or related qualification.\nProven work experience as a Data Scientist\/Data Analyst or similar role.\nProficient in Python programming and SQL languages.\nProficient in open-source software libraries for machine learning and artificial intelligence such as TensorFlow and Keras, open-source message broker software such as RabbitMQ, distributed event store and stream-processing platform such as Apache Kafka.\nProficient in Apache HBase open-source non-relational distributed database and Apache Hadoop Distributed File System (HDFS).\nExperience with data visualization tools such as Power BI, QlikView or Splunk.\nStay up-to-date with the latest advancements in data science, artificial intelligence and machine learning.\nDetailed, strong technical and analytical skills.\nGood communication, decision making and presentation skills.","18":"Which of the following languages are you fluent in?\nHow would you rate your English language skills?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","19":"Responsible for requirement study, testing, deployment, and support\/enhancement of in-house systems, mobile applications, and reporting.\nWork closely with the helpdesk functional team, peers, and business users on system requirement studies and issue clarification.\nAssist in solution architecture, application design, and database design based on task requirements.\nManage developers in designing and developing architecture for data warehousing components (e.g., tool integration strategy, data staging, movement and aggregation, information and analytics delivery, and data quality strategy).\nDesign and implement standard reporting and dashboards using SSIS, SSAS, SSRS, Microsoft SQL stored procedures, and Microsoft Excel Pivot.\nPerform technical specification writing and documentation.\nExhibit strong collaboration and communication skills, a positive attitude, and take responsibility for assigned tasks.\nWork independently, be detail-oriented, and demonstrate strong problem-solving skills.\nWork on bug fixes and fine-tune application performance.\nBe a fast learner and capable of working in a fast-paced environment with tight deadlines.\nBachelor's degree in a related field.\nA minimum of 5 years of experience in web and software development.\nExperience in the retail industry is an added advantage.\nDemonstrated knowledge of web\/mobile languages\/technologies such as JavaScript, ASP.NET, HTML, CSS, PHP, AngularJS, Node.js, MVC, jQuery, AJAX, Bootstrap, etc.\nDemonstrated knowledge of backend languages\/technologies such as C#, MS SQL Server, MySQL, web services, VBA, etc.\nDemonstrated knowledge of software components and third-party programs, such as API (JSON, REST, XML).\nDemonstrated knowledge of source control management, such as GitHub.\nExperience with Windows Server and Linux.\nOpportunity to work with a leading cosmetics retailer, gaining experience in a fast-paced, dynamic industry.\nExposure to a diverse range of international and local beauty brands.\nAccess to professional development within a large, well-established company.\nBe part of a collaborative, innovative team focused on delivering exceptional customer experiences.\nBenefit from growth opportunities in both e-commerce and physical retail sectors.","20":"AI Strategy & Leadership:\n Take full ownership of the AI roadmap for trade decision analysis, defining the model architecture, training, and evaluation methodologies. Lead the team\u2019s AI efforts and independently drive technical direction.\nAdvanced Model Development:\n Design and build state-of-the-art machine learning models, including \nLSTM\n, \ntransformer-based models\n (e.g., \nLLaMA\n, \nGPT\n), or other relevant architectures to analyze time-series data and predict market movements.\nAlgorithm Development:\n Implement and optimize algorithms that improve the speed and accuracy of trade decisions, focusing on high-performance, real-time models that can be deployed in production environments.\nEnd-to-End Model Lifecycle:\n Own the end-to-end development cycle for AI models, including \ndata preprocessing\n, model training, validation, testing, and deployment. Ensure models are production-ready and robust under varying market conditions.\nBacktesting & Performance Evaluation:\n Perform extensive backtesting of AI models using historical market data, develop benchmarks, and continually refine models for improved performance. Lead model tuning for accuracy, speed, and reliability.\nIntegration with Trading Systems:\n Collaborate closely with trading and engineering teams to ensure that AI models seamlessly integrate into the trading platform. Provide technical expertise to align models with existing trade execution frameworks.\nScalability & Optimization:\n Build scalable AI solutions capable of handling high-frequency data streams and vast amounts of market data. Ensure the efficiency of AI models in real-time systems with minimal latency.\nAI Infrastructure & MLOps:\n Establish and maintain AI pipelines, automation, and infrastructure for model training, testing, deployment, and monitoring. Lead efforts in \nMLOps\n to optimize model lifecycles.\nResearch & Innovation:\n Keep up with the latest research in AI, machine learning, and financial modeling. Innovate by applying cutting-edge techniques, including transfer learning, reinforcement learning, or other novel AI approaches.\nTechnical Leadership:\n Provide mentorship and technical guidance to junior and intermediate AI engineers. Lead code reviews, contribute to defining coding standards, and ensure best practices across the AI team.\nDocumentation & Standards:\n Create comprehensive technical documentation and ensure that AI systems are built following industry standards for maintainability and scalability.\nEducational Background:\n Master\u2019s or Ph.D. in Computer Science, Data Science, AI\/ML Engineering, or related fields, or equivalent work experience.\nExperience:\n Minimum of 5 years of hands-on experience in AI\/ML development, with a strong track record of deploying models in production. Proven experience in time-series forecasting and financial market applications is a plus.\nTechnical Skills:\nExpertise in \nmachine learning frameworks\n like \nTensorFlow\n, \nPyTorch\n, or \nKeras\n.\nStrong proficiency in \nLSTM\n, \nGRU\n, and \ntransformer-based models\n (e.g., \nLLaMA\n, \nBERT\n, \nGPT\n).\nSolid experience in \ntime-series analysis\n, feature engineering, and building prediction models for financial data.\nDeep understanding of \ntrading systems\n, market microstructure, and execution algorithms.\nExperience with \ncloud platforms\n (e.g., AWS, GCP) and distributed computing to train large-scale models.\nProficiency in building \nreal-time machine learning pipelines\n, handling streaming data, and ensuring low-latency responses.\nExperience in \nbacktesting\n, hyperparameter tuning, and model optimization for high accuracy.\nProficiency in \nMLOps\n tools for model lifecycle management (e.g., MLFlow, Kubeflow).\nStrong skills in \nSQL\n, \nNoSQL\n, and managing large datasets.\nExpertise in \nmachine learning frameworks\n like \nTensorFlow\n, \nPyTorch\n, or \nKeras\n.\nStrong proficiency in \nLSTM\n, \nGRU\n, and \ntransformer-based models\n (e.g., \nLLaMA\n, \nBERT\n, \nGPT\n).\nSolid experience in \ntime-series analysis\n, feature engineering, and building prediction models for financial data.\nDeep understanding of \ntrading systems\n, market microstructure, and execution algorithms.\nExperience with \ncloud platforms\n (e.g., AWS, GCP) and distributed computing to train large-scale models.\nProficiency in building \nreal-time machine learning pipelines\n, handling streaming data, and ensuring low-latency responses.\nExperience in \nbacktesting\n, hyperparameter tuning, and model optimization for high accuracy.\nProficiency in \nMLOps\n tools for model lifecycle management (e.g., MLFlow, Kubeflow).\nStrong skills in \nSQL\n, \nNoSQL\n, and managing large datasets.\nAdditional Skills:\nExpertise in \nfinancial markets\n, \nalgorithmic trading\n, and developing AI solutions for real-time decision-making.\nFamiliarity with \nreinforcement learning\n, \ndeep learning\n, and \ntransfer learning\n for financial applications.\nExperience with \ndistributed computing frameworks\n (e.g., Spark, Dask) to process large-scale datasets.\nKnowledge of \ndata visualization\n tools and methods for presenting insights and model performance.\nExpertise in \nfinancial markets\n, \nalgorithmic trading\n, and developing AI solutions for real-time decision-making.\nFamiliarity with \nreinforcement learning\n, \ndeep learning\n, and \ntransfer learning\n for financial applications.\nExperience with \ndistributed computing frameworks\n (e.g., Spark, Dask) to process large-scale datasets.\nKnowledge of \ndata visualization\n tools and methods for presenting insights and model performance.\nStrong leadership and \ntechnical mentorship\n skills, with a proven ability to drive projects from ideation to deployment.\nExcellent problem-solving skills, with a track record of resolving complex AI and data science challenges.\nAbility to work independently, make informed technical decisions, and take ownership of large-scale AI projects.\nStrong communication skills, with the ability to explain complex AI concepts to non-technical stakeholders.\nA passion for continuously improving AI systems and staying ahead of the curve in new AI\/ML techniques.\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as an Artificial Intelligence Engineer?\nHow many years' experience do you have using SQL queries?\nHave you worked in a role which requires experience with machine learning?\nWhich of the following programming languages are you experienced in?\nWhich of the following Relational Database Management Systems (RDBMS) are you experienced with?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","21":"\n\nLead the business analysis function, contributing to the development of data-driven strategies. \n\n\nImplement and share innovative ideas for data utilization and analysis. \n\n\nTake a proactive approach in identifying opportunities for data-driven improvements. \n\n\nShowcase advanced proficiency in Excel or Google sheet formulas for detailed business analysis and modeling. \n\n\nUtilize Excel for in-depth insights into complex datasets. \n\n\nDevelop and implement interactive dashboards for effective data communication. \n\n\nApply experience and knowledge in analyzing call center, customer services, sales, or telemarketing data. \n\n\nProvide actionable insights to improve performance and efficiency. \n\n\nImplement and maintain data governance practices to ensure data accuracy and integrity. \n\n\nCollaborate with cross-functional teams to streamline data processes. \n\n\nCollaborate effectively with teams to understand data needs and requirements. \n\n\nCommunicate complex data insights in a clear and accessible manner. \n\n\nStay updated on industry trends, emerging technologies, and best practices in business analysis. \n\n\nProactively integrate new tools and methodologies for improved business analysis.\n\n\n\n\nBachelor's degree in Data Science, Data Analysis, Business Analysis Statistics, Computer Science, Business Administration or a related field (fresh graduates are welcomed). \n\n\nGood proficiency in \nExcel Analysis\n or other \nData analysis tools\n. \n\n\nAbility to speak in Mandarin is highly preferred to deal with Chinese stakeholders. \n\n\nExperience in call center, customer services, sales, or telemarketing analysis is highly preferred. \n\n\nExperience with programming languages and \nBI Tools\n such as Python, R, Power BI, Tableau is added advantage.\n\n\nWhat is your expected monthly basic salary (RM) ?\nWhat is the notice period required by your current employer? (Months)\nList down the data analytics tools you are experienced with. \n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","22":"\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","23":"Responsible for requirement study, testing, deployment, and support\/enhancement of the in-house systems, mobile applications, and reporting.\nWork closely with the helpdesk functional team, peers, and business users on system requirement studies and issue clarification.\nAssist in solution architecture, application design, and database design based on task requirements.\nManage developers in designing and developing the architecture for data warehousing components (e.g., tool integration strategy, data staging, movement and aggregation, information and analytics delivery, and data quality strategy).\nDesign and implement standard reporting and dashboards using SSIS, SSAS, SSRS, Microsoft SQL stored procedures, and Microsoft Excel Pivot.\nPerform technical specification writing and documentation.\nExhibit good collaboration and communication skills, a positive attitude, and responsibility for assigned tasks.\nWork independently, be detail-oriented, and possess strong problem-solving skills.\nWork on bug fixing and fine-tuning application performance.\nBe a fast learner and able to work in a fast-paced environment with tight deadlines.\nBachelor\u2019s degree in a related field.\nMinimum of 5 years of experience in web and software development.\nWorking experience in the retail industry is an added advantage.\nDemonstrated knowledge of web\/mobile languages\/technologies, such as JavaScript, ASP.NET, HTML, CSS, PHP, Angular JS, Node.js, MVC, jQuery, AJAX, Bootstrap, etc.\nDemonstrated knowledge of backend languages\/technologies, such as C#, MS SQL Server, MySQL, web services, VBA, etc.\nDemonstrated knowledge of software components and third-party programs such as API (JSON, REST, XML).\nDemonstrated knowledge of source control management such as GitHub.\nExperience with Windows Server and Linux.\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a systems analyst?\nWhich of the following programming languages are you experienced in?","24":"\n\nDesign and implement generative and analytical AI projects.\n\n\nAnalyze complex data sets to identify patterns, trends, and insights.\n\n\nCollaborate with cross-functional teams to integrate AI solutions across various applications.\n\n\nConduct research to remain at the forefront of advancements in AI technologies.\n\n\n\n\nProven expertise in AI development and deployment.\n\n\nStrong background in data feature analysis and machine learning algorithms.\n\n\nExperience with large datasets, developing models that yield actionable insights.\n\n\nProficiency in AI-related programming languages and tools, including Python, TensorFlow, and PyTorch.\n\n\nMaster\u2019s degree or higher in Computer Science, Data Science, or a related field.\nRelevant experience in Computer Science, Data Science, or a similar discipline.\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","25":"Which of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following languages are you fluent in?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","26":"What's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Data Engineer?\nHow many years' experience do you have using SQL queries?\nWhich of the following programming languages are you experienced in?\nWhich of the following data analytics tools are you experienced with?\nHow many years' experience do you have in a DevOps role?","27":"Implement, troubleshoot, and test data products and services using standard techniques and tools.\nHelp building data solutions which are scalable, resilient, and future proof.\nUnderstand typical problems in databases, data processes, data products and services. You understand and can apply typical solutions to those problems.\nImplement, troubleshoot, and test pipelines, Web APIs, services, or scripts.\nWork in an Agile and cross-functional team\nDegree in Computer Science, Information Technology or a related field\n1-2 years of experience in data engineering or a similar role\nAgile methodologies. You know about agile methodologies and the ways you can apply the principles in practice. You can take an open-minded approach; you know why iteration is important. You know how agile processes can be used to validate ideas with users.\nData development process. You can design, build and test data products based on feeds from multiple systems using a range of different data exchange, storage and access technologies. You can create testable, repeatable and reusable products.\nData technology. You can apply data models using database technology. You understand and apply appropriate data design principles to achieve performant and secure databases. You are aware of general trends in data technology.\nTechnical understanding (data engineering). You understand core technical concepts like data normalisation, modelling, performance of data intensive solutions. You understand basic software development concepts.\nGood command of written and spoken English and Chinese; Cantonese is an advantage\nCompetitive salary and performance-based bonuses\nComprehensive health and wellness benefits\nOpportunities for professional development and career growth\nFlexible work arrangements and a dynamic, collaborative work culture\nTeam-building activities and social events to foster connections\nWhich of the following statements best describes your right to work in Malaysia?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Data Engineer?\nHow many years' experience do you have working in an agile environment?","28":"Create and maintain optimal data architecture\u00a0\nAssemble large, complex data sets that meet functional and non-functional business requirements\u00a0\nIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\u00a0\nBuild the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources\u00a0\nWork with stakeholders including the users, cross functional teams to assist with data-related technical issues and support their data infrastructure needs.\u00a0\nStandard process to keep data secure with right access and authorization\u00a0\nFocus on automated testing and robust monitoring\nExcellent problem solving and interpersonal communication skills\u00a0\nStrong desire to learn and share knowledge with others.\u00a0\nBe inquisitive, innovative, and a team player with a strong focus on quality workmanship.\u00a0\nTroubleshooting skills and root cause analysis for performance issues\u00a0\nAbility to lean, adopt and implement new skills to drive innovation and excellence.\u00a0\nAbility to work with cross functional teams in dynamic environment\nA bachelor's with 5+ years of experience in CS\/CE or a related field\u00a0\nExperience building and optimizing big data pipelines\u00a0\nExperience with skills pf handling unstructured data\u00a0\nExperience with data transformations, structures, metadata, workload management\u00a0\nExperience with big data tools: Spark, Kafka, NIFI. ADF etc.\u00a0\nExperience with at least programming languages: Python, C#, .NET\u00a0\nExperience with relational SQL and NOSQL DBs\u00a0\nExperience in leveraging open-source packages\u00a0\nExperience in cloud native skills such as Docker, Kubernetes, Rancher etc. Good to have skills:\u00a0\nExperience with semiconductor manufacturing\u00a0\nExperience of data engineering on cloud\u00a0\nExperience in developing AI\/ML Solutions \u00a0\nWhich of the following statements best describes your right to work in Malaysia?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Big Data Engineer?\nWhich of the following programming languages are you experienced in?\nHow many years' experience do you have using SQL queries?\nHow would you rate your English language skills?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","29":"Email Annotation\n: Annotate emails for AI filters machine learning.\nEmail Examination\n: Review various email elements, including appearance, headers, links, and attachments. Analyze online resources related to internet domain and IP address reputations to determine email categories.\nMalicious URL Identification\n: Detect and block malicious URLs and phishing attempts to protect recipients and maintain email security.\nData Labeling\n: Label a diverse pool of data, including emails, messages, and statements, for use in training and improving AI and machine learning models.\nProcess Adherence\n: Ensure all operational sections adhere to established processes and procedures to maintain consistency and quality.\nKPI Management\n: Monitor and ensure that all key performance indicators (KPIs) are met. Propose and implement initiatives or improvement plans as needed to address any shortfalls.\nProject Support\n: Assist the Project Manager with day-to-day service operations and departmental administration as required.\nCandidate must possess at least a Diploma or Advanced Diploma\nPreferably 1 year(s) & above of working experience in the related field\nAbility to work 24\/7 rotational shift, including the ability to work nights, weekends and public holidays\nExperience in IT, security or systems support, or network administrator positions will be added advantage\nFluent English in speaking and writing\nGood communication and problem-solving skills\nResponsible, meticulous and a team player\nSelf-motivated, proactive, well organized\nFresh graduates are welcome to apply\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nAre you available for shift work?\nHow many years' experience do you have in the IT industry?\nWhich of the following types of qualifications do you have?","30":"Gather and analyze customer data to map and plan the customer journey, identifying trends and patterns to optimize the CRM strategy.\nConduct A\/B testing on promotional and marketing campaigns to evaluate their effectiveness and make recommendations for improvements.\nCollaborate with stakeholders to help them make data-driven decisions that enhance customer engagement and retention strategies.\nPrepare comprehensive reports on CRM and loyalty campaign performance, providing actionable insights and recommendations for continuous improvement.\nProvide in-depth analysis of customer behavior to identify growth opportunities and improve customer journey experiences.\nFluent in written and spoken \nEnglish\n and \nMandarin\n.\nBachelor's degree in Data Science, Marketing, Business Analytics, International Business, Public Relations, or Media Studies.\u00a0\nProven experience as a Data Analyst, preferably within Sales, Customer Behavior, Business Development or Marketing.\nProficiency in data analysis tools such as \nExcel\n, \nSQL\n, and data visualization tools (e.g., Tableau, Power BI).\nStrong knowledge of A\/B testing methodologies and experience in campaign optimization.\nExcellent analytical and problem-solving skills, with the ability to present complex data in a clear and concise manner.\nStrong communication skills to effectively collaborate with stakeholders and present insights.\nHybrid Work Mode: \nWork from Home every Monday and Friday.\nAccessible Location:\n Office is within walking distance from the MRT.\nMonthly Performance Bonus: \nUp to 4 digits monetary reward, get paid for your hard work.\u00a0\nProfessional Development:\n Sponsorship for professional training and workshops.\nAnnual Leave Encashment:\n Get paid for unused leave.\nWork Assets Provided:\n All necessary work tools and equipment are supplied.\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a data analyst?\nWhich of the following data analytics tools are you experienced with?\nHow many years' experience do you have using SQL queries?\nWhich of the following languages are you fluent in?","31":"Conduct in-depth research on industry trends, competitors, and customer needs.\nIdentify operational and market opportunities and recommend actions.\nCollaborate with cross-functional teams to develop strategic growth plans.\nLead meetings and presentations to share insights and ideas.\nPrepare data reports for management\/stakeholders\/client company.\nProvide data-driven recommendations to optimize business strategies, customer acquisition, and retention.\nFocus on achieving revenue targets and business milestones.\nBachelor\u2019s degree \/ Diploma\n in Risk Management, Mathematics, Statistics, Actuarial Science, Business, Computational Science\/Information Technology, Data Science, or equivalent.\nMinimum of \n3 to 5 years\n of relevant work experience\nExperience in \nMarketing, Finance, Economics, Business\n, or related fields \nis a plus\n.\nFluency in \nEnglish \nand\n Mandarin\n is compulsory, as dealing with Mandarin-speaking clients is required.\nMust have a strong knowledge of SQL\n and relevant work experience, particularly in using SQL to initiate and manage projects.\nProficient in\n Excel VBA, Power Query, Power BI \nis a plus.\nAble to lead, influence, and motivate teams to achieve high performance.\nComfortable working in a fast-paced environment with high workloads and deadline-driven projects.\nWilling to travel overseas when required.\nHybrid Work Mode:\n Rotational, work in the office 1 week per month.\nAccessible Location:\n Office is within walking distance from the MRT.\nMonthly Performance Bonus\n: Up to 4 digits monetary reward, get paid for your hard work.\nProfessional Development:\n Sponsorship for professional training and workshops.\nAnnual Leave Encashment:\n Get paid for unused leave.\nTeam Bonding:\n Monthly team bonding activities based on your preference.\nWork Assets Provided:\n All necessary work tools and equipment are supplied.\nWhich of the following types of qualifications do you have?\nWhat's your expected monthly basic salary?\nWhich of the following statements best describes your right to work in Malaysia?\nHow many years' experience do you have as a data analyst?\nWhich of the following languages are you fluent in?\nHow many years' experience do you have using SQL queries?\nHow much notice are you required to give your current employer?\nHow many years' experience do you have as a SQL Analyst?","32":"Carry out data entry work with accurate information on daily basis.\nEnsuring data registered are valid.\nUpdate and maintain existing data as well as metadata management.\nAssist in design database structure and pipeline.\u00a0\nReport writing and demonstrate the understanding of relationships among each data.\u00a0\nDesign and prepare reports in a timely manner for different stakeholders.\nHousekeeping and maintenance of the database.\nUndertake any ad-hoc duties as assigned.\u00a0\nAt least a diploma in Computer Science\/ Data Science\/ any other related qualification that is equivalent.\nDetail oriented.\nStrong analytical mind and good communication skills.\nAble to work independently, responsible, self-motivated.\nProficient in MS Office (MS Excel, MS Word, MS Power Point), SQL, and Data Management.\nAble to complete tasks within given timelines with minimal supervision.\nExcellent interpersonal skills and able to work in fast-paced environment.\nSkills in programming language, data analytics and MS Power BI is a strong advantage.\nWilling to work on site office in Taman Melawati, WPKL.\u00a0\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nHow would you rate your English language skills?\nHow much notice are you required to give your current employer?\nWhich of the following programming languages are you experienced in?\nHow far are you willing to travel for work?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","33":"Understanding the whole company product line, function, and feature\nContact, coordinate and collect the needs of department. Analyse and propose a suitable system development plan for department head. Meet business needs and support transportation to achieve maximum efficiency and effectiveness.\u00a0\nReport, outlining the operation and progress of system development. Advise the department and supervisor correct control system development to meet demand and complete on time.\u00a0\nResearch and follow up new technologies and knowledge in the system and related business areas. And effectively apply to operation and bring maximum benefits to the company.\u00a0\nHaving a clear understanding of the business issues and using communication to help solve organizational problems and achieve organizational objective. And Turn business conceptualization into Software Solution.\u00a0\nWorking with business users to identify opportunities for improvement in business operations and processes.\u00a0\nSupporting test cycles particularly User Accept Test (UAT).\nProficiency in \nMandarin \nwould be preferrable.\u00a0\nAt least 1-2 years of related working experience would be added advantage.\u00a0\nWilling to work on \nMonday to Friday and alternative Saturdays.\u00a0\nPlus point if familiar with UAT and API.\u00a0\nUnderstand basic Excel functions: VLOOKUP, HLOOKUP, Pivot Table.\nWhat's your expected monthly basic salary?\nHow would you rate your Mandarin language skills?\nHow much notice are you required to give your current employer?","34":"Work with some of the best optimization minds in the world to contribute to the ongoing improvements of our optimization technologies and methodologies\nWork with Quintiq Business Consultants to design planning solutions that incorporate optimization\nDesigning and implementing the right optimization solution to solve our customers\u2019 puzzles\nParticipate in optimization research projects to come up with potential improvement ideas for our optimization solutions\nComes with 3-5 years of working experience\nDegree in Computer Science, Operations Research, Mathematics, or Artificial intelligence\nKnowledge of optimization techniques in operations research and artificial intelligence (linear programming, genetic algorithms, heuristic search techniques, constraint programming, etc.)\nExperience with object-oriented modeling (UML)\nHigh abstraction level and superior analytical skills\nWork for the one of the biggest software company in Europe\nGain exposure to a wide variety of industry experiences and IT technologies\nAn international work environment with brilliant colleagues around the globe\nA conducive and supportive environment for personal and career growth\nOpportunity to work on challenging projects\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","35":"Architect and design data infrastructure on cloud\nDesign and build resilient and efficient data pipelines for both batch and real-time streaming data\nAssemble and collect data sets that meet functional and non-functional business requirements\nIdentify, design & implement internal process improvements, automating manual processes optimizing data delivery, infrastructure for greater scalability\nBuild the infrastructure required for optimal extraction, transformation and loading of data from a variety of sources using SQL, APIs and cloud services technologies\nBuild tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics\nBuild tools for analytics and data team member that assist in building and optimizing the product into an innovative leader\nWork with data and analytics experts to strive for greater functionality in our data lake, systems and ML\/Feature Engineering for AI solutions\nWork with cross-functional departments to understand their data needs and requirements and build tools to assist them with their analytics tools\nAdditional responsibilities and tasks assigned by management from time to time\nMinimum 3 years of\u00a0relevant experience\nBachelor's or Master's degree in Data Science, Computer Science, Statistics, or a related field\nProficiency in programming languages such as Python, Java, or SQL\nExperience with data processing frameworks and technologies\nStrong understanding of database concepts and experience with relational\nKnowledge of data modeling and familiarity with cloud platforms and services\nExcellent problem-solving skills, attention to detail, and ability to work independently as well as part of a team\nStrong communication and interpersonal skills, with the ability to explain technical concepts to non-technical stakeholders\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Data Engineer?\nWhich of the following programming languages are you experienced in?\nHow many years' experience do you have using SQL queries?\nHave you worked in a role which requires experience with machine learning?","36":"To conduct user requirement analysis for the development\/ implementation of new systems and enhancements to existing systems.\nTo responsible for multiple platform applications design, development, testing, implementation, integration, documentation, maintenance and enhancement using multiple frameworks and languages.\nTo support & troubleshoot for Business Application System.\nImplement and follow coding standards and adhere to best practices and security guidelines.\nTo develops technical documents and handbooks to accurately represent the design and code of new applications.\nTo design and create report.\nTo plan and coordinate training for any system implementations or enhancements.\u00a0\nTo supervise, coach and train analyst programmers.\nAssess system capabilities and undertake feasibility studies that include financial considerations and timelines.\nOther ad-hoc duties.\u00a0\nCandidate must possess at least a Bachelor's Degree, Post Graduate Diploma, Professional Degree, Computer Science\/Information Technology or equivalent\n5 year(s) and above of relevant working experience\nSkills required: Java Technologies, C#, Visual Studio, Reporting Tools, HTML, CSS, jQuery, Vue.js, OOP, JDBC, jsp, servlet, Database Design Technologies with SQL Server and DB2\nExposure in ERP manufacturing environment and experience in data automation\nVariable Allowances\/Incentive (Handphone, Stay-Back\/Call-Back, Transport Allowance, etc)\nEmployee Education Assistance Program (For further studies)\nMedical & Dental Benefits\nInsurance\nFree Parking\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a systems analyst?\nHow many years' experience do you have as an Information Technology Executive?\nHow many years' experience do you have as an Analyst Manager?\nWhich of the following languages are you fluent in?","37":"Bachelor\u2019s degree in Business, Finance, Statistics, or a related field.\nProven 1 to 2 years\u2019 experience in data analysis, reporting, or a similar role.\nProficiency in data management and visualization tools (e.g., Excel, Power BI, Power Point).\nStrong analytical and problem-solving skills.\nExcellent attention to detail and accuracy.\nAbility to communicate complex data insights in a clear and concise manner.\nStrong organizational and time management skills.\nAbility to work independently and as part of a team.\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Business Analytics Executive?\nWhich of the following Microsoft Office products are you experienced with?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","38":"Develop and maintain scalable data pipelines on cloud platforms.\nImplement data validation, cleansing, transformation, and storage solutions in cloud and data lake environments.\nBuild ETL\/ELT processes to prepare datasets that empower data analysts and other users.\nDesign and implement cloud-native solutions for data ingestion, processing, and analytics.\n5+ years in Data Engineering, preferably in a vendor environment.\nExperienced with cloud data infrastructure such as Microsoft Azure, Google Cloud Platform, Amazon Web Services and Huawei Cloud.\nStrong background in Python, SQL, and big data tools like Hadoop, Spark, PySpark, and Delta Lake.\nOpen to local applicants only.\nCompetitive remuneration based on experience.\nSteep learning opportunity with leadership from an industry expert.\nExcellent career support and leadership training.","39":"Design and implement cloud solutions and CICD pipelines, build MLOps on Azure platform.\nRun code refactoring and optimization, containerization, deployment, versioning and monitoring of its quality.\u00a0\nWork with the data science team to research, develop, evaluate and optimize various models using different machine learning algorithms for problem solving or process optimisation.\u00a0\nExecute projects involving machine learning algorithm for computer vision applications using learners such as neural networks, clustering, segmentation, object detection, tracking.\u00a0\nDesign the self-running applications and software that makes use of that data and automates predictive models.\nBSc. or MSc. or Ph.D. in Mathematics, Computer Science, Data Science, Machine Learning, Artificial Intelligence or related fields provided they have a strong technical knowledge and experience in machine learning.\nExperience in design and implement Azure cloud-based solution and services.\nProficient in programming and scripting skills (Python and R).\nProficient in machine learning framework such as scikit-learn, pandas, TensorFlow or Keras.\nExperience in Geo-spatial analytical skills and GIS python library (GDAL, ArcPy, Geopandas, etc.) is a plus.\u00a0\nExcellent interpersonal skills, team player, resourceful and has strong analytical skills.\u00a0\nGood communication and written in English.\nWhich of the following statements best describes your right to work in Malaysia?\nHave you worked in a role which requires experience with machine learning?\nWhat's your expected monthly basic salary?\nHow many years' experience do you have as a Programmer?\nWhich of the following programming languages are you experienced in?\nHow much notice are you required to give your current employer?\nWhich of the following data analytics tools are you experienced with?","40":"Collaborate with various teams to understand and communicate business requirements\nDesign and build end-to-end ETL pipelines ensuring high reliability and security\nCreate and optimize data models for efficient data processing\nDevelop and maintain business data products\nStay up-to-date with the latest technologies and tools in the data engineering field\nProficient in creating and maintaining end-to-end ETL pipelines with a focus on reliability and security\nExperience with distributed computing agents such as Hive, Spark, Hadoop or Airflow\nStrong knowledge of data warehouse concepts and experience in data modeling and design is a must.\nStrong logical thinking and excellent verbal communication skills\nFluent in English, Mandarin language skills are necessary since some stakeholders are located in China\nCandidates with relevant data engineering experience will only be considered.\nKnowledge of big data architecture design, including data governance and compliance, is a plus","41":"Which of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Data Engineer?\nHow many years' experience do you have using SQL queries?\nWhich of the following programming languages are you experienced in?","42":"Define, design, build, and enhance business intelligence solutions.\nProvide 2nd level support on PDWH for Backend \/ Frontend DWH, Global PDWH, Production Data Marts, and iPRISM operations globally.\nProvide operational support for production data warehousing & BIA Solutions in the manufacturing domain.\nEnsure the Local\/Global Production Data Warehouse is running at a stable and high-performance level as per SLA.\nEnsure that systems, processes, and methodologies as specified are followed to ensure effective monitoring, control, and support of service delivery.\nDrive continuous improvement initiatives within the operations support area (e.g. automation of monitoring and internal controls) and control costs as per budget.\nSupport in the development and release of change requests.\nPromote transfer of knowledge and awareness to those in closely related areas, such as colleagues, and clients\/users.\nSupport in documentation and written procedures for routine and non-routine tasks.\nAble to work on AP & EU business hours during critical period.\nOn-call for critical operation support.\nBachelor's Degree in Computer Science \/ Information Technology or any relevant course.\nKnowledge in SQL and PL\/SQL in Oracle and know-how in MS SQL Database.\nUnderstanding of Data Warehousing \/ ETL techniques.\nGood analytical troubleshooting and problem-solving skills.\nStrong in service support operations & experienced in ticketing tracking systems.\nGood communication skills and a proactive team player.\nAble to work independently with minimal supervision.\nExperienced in data warehousing projects is an added advantage.\nFamiliar with business processes in the Semiconductor manufacturing industry.\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","43":"Which of the following statements best describes your right to work in Malaysia?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Data Engineer?\nHow many years' experience do you have using SQL queries?\nWhich of the following programming languages are you experienced in?\nWhich of the following Relational Database Management Systems (RDBMS) are you experienced with?","44":"Support root cause analysis to identify underlying operational issues addressable by system solutions.\nIdentify potential requirements for system design and explore new system capabilities to meet business needs.\nTranslate system capabilities into innovative solutions and lead technical solutioning for small projects with low complexity.\nUnderstand business requirements and application capabilities, managing low complexity change requests (CRs) and application enhancements to realize business needs.\nConduct thorough root cause analysis to understand requirement problem statements and propose appropriate system solutions.\nEvaluate and define potential requirements for systems design, ensuring documented requirements include associated metrics and testing procedures.\nPropose solution options and workarounds to meet business expectations while considering cost implications.\nManage CR delivery according to established processes, governing individual CR solutions and timelines.\nChampion a \"Shift Left\" mindset through the CR process, ensuring prompt tracking and updates in JIRA.\nCollaborate effectively with business stakeholders, product managers\/owners, vendors, and internal team members to prioritize and deliver against agreed-upon objectives.\nUndertake any other duties\/functions as assigned by SA Leadership.\nDegree in Computer Science \/ IT \/ Electrical & Electronic \/ Telecommunication or equivalent\nMinimum 3-4 years of relevant working experience in Telco Area\nStrong understanding of system boundaries, interfaces, and business context for frequently used applications.\nAbility to support and guide business in requirement review processes and document requirements effectively.\nProficiency in designing and developing ISD architecture solutions to support business agendas.\nAptitude for combining established methodologies with innovative techniques to address business challenges effectively.\nSkill in integrating end-user needs, technical possibilities, and business requirements to solve basic to slightly complex problems.\nExperience in leveraging established governance mechanisms to mediate conflicts, mitigate risks, and resolve issues.\nDemonstrated ability to deliver high-quality presentations and content.\nEffective stakeholder management skills and problem-solving techniques.\nAdoption of Agile and DevOps principles\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Solutions Analyst?\nWhich of the following issue and bug tracking software do you have experience with?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","45":"Provides tactical marketing and analysis support to internal customers including: customer profiling, segmentation, customer lifetime value analysis, attrition models, machine learning models, and local market opportunity analysis.\nUsing analytical and visualization software to access, transform integrate, analyze and visualize data to help solve real problems and provide business insight.\nMine data from primary and secondary sources. Clean and prune data to discard irrelevant information. Introduce new data source to improve machine learning models.\nIdentify customers for campaign targeting based on their needs and eligibility, and conduct in depth post implementation review for continues improvement and learning.\nWork closely with client to identify business requirements and translating data into informative insights and report to help solve real problems and provide business insight. Design key metrics to track business performance and identify business issue and challenges.\nSupport the campaign management from leads identification, interim tracking, and fulfillment.\nAnalyze and interpret results using standard statistical tools and techniques.\nPinpoint trends, correlations and patterns in complicated data sets\nMentoring and coaching others to improve their analytical skills.\nExperience in analyzing data trends and recommend solutions\/campaigns to create revenue or improve efficiency.\nExperience in data visualization.\nAnalytical, creative and innovative approach in solving problems\nExperience in building statistical model.\nExperience in insurance or financial services industry is preferred\nAt least 5 years of business intelligence and analytic experience in the financial industry is preferred. Candidate with supervisory experience is preferred.\nSAS\/ SQL, Tableau\/ Power BI and other analytics software (e.g. Python and R).\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nHow many years' experience do you have as a Data Analytics Manager?\nWhich of the following programming languages are you experienced in?\nHave you worked in a role which requires a sound understanding of business intelligence (BI) best practices?\nWhich of the following web analytics tools are you experienced with?\nHow many years' experience do you have using SQL queries?\nHave you worked in a role which requires experience with statistical modelling?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","46":"Designing, building, and maintaining data pipelines to collect, process, and store large datasets from various sources.\nDevelop, optimize, support, and maintain Extract, Transform, Load (ETL) processes to ensure data quality and integrity.\nMonitor and troubleshoot ETL processes to identify and resolve issues promptly, ensuring smooth operation and minimal downtime.\nIntegrate data from different sources into a cohesive and accessible data warehouse.\nMaintain clear and concise documentation for data pipelines, processes, and systems.\nWork under the close direction and supervision of senior team members to support clients' applications.\nBe responsible and accountable for task tracking, reporting, and meeting deadlines.\u00a0\nApply, maintain, and recommend improvements to development procedures and standards.\nAccept ownership for accomplishing new and different requests for personal and professional growth.\nExplore opportunities to add value to job accomplishments and contribute to team success.\nDatabase \u2013 DB2 (Preferred), Oracle (Preferred), IBM Netezza\nETL\/ELT data workflows \u2013 Data Stage (Preferred), SAP BI\nData warehouse, Data mart \u2013 including analysis of business\/users requirements, solutioning\nData design and data model\nIndependent with initiative.\nAbility to adapt to changes.\nEnjoy being challenged and to solve complex problems.\nPositive attitude with a great drive to deliver.\nPossess great sense of ownership to issues and problems.\nAptitude to grasp concepts quickly and ability to apply.\nPossess strong analysis abilities with acute sense of data analytics.\nMultiple years of experience in a professional environment performing analysis, design and development tasks on multiple platforms.\nFamiliar with data analytics, data mining concepts and machine learning algorithms.\nProficient in data design, data architecture, robust ETL\/ELT data workflows.\nWhich of the following statements best describes your right to work in Malaysia?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Data Engineer?\nWhich of the following Relational Database Management Systems (RDBMS) are you experienced with?\nHow many years' experience do you have using SQL queries?","47":"Which of the following types of qualifications do you have?\nWhich of the following statements best describes your right to work in Malaysia?\nHow many years' experience do you have as a Data Engineer?","48":"","49":"Develop a comprehensive understanding of HRD Corp\u2019s business requirements and the national-level training and development landscape to ensure data initiatives align with organisational goals.\nFormulate structured analytical frameworks and methodologies to support economic research programmes, contributing to the organisation\u2019s strategic knowledge base.\nDevelop, manage and configure advanced and predictive analytics models using various statistical techniques and specialised software tools, while driving innovation and predictive accuracy for high quality and comprehensive data.\nInterpret complex data sets and conduct comprehensive data analysis using statistical techniques and tools, such as Python, SAS, Tableau, SQL etc., depending on the requirement to optimise the efficiency and quality of reports for the consumption of the organisation and management in ensuring accurate and insightful data-driven decision-making.\nConduct in-depth data analysis and select relevant information to analyse key themes and trends using primary\/secondary\/multiple data sources and business intelligence tools, providing valuable insights for strategic decision-making.\nProduce organisational-level reports to management by in-depth data analysis and\ninterpretation that provide insights for strategic decisions and organisational performance improvement.\nDesign and visualise reports and dashboards using tools like Tableau and PowerBI to clearly and concisely communicate data findings to stakeholders, facilitating informed decision-making.\nMaintain data integrity by verifying the accuracy and consistency of data throughout the process, ensuring that all data used in analysis is reliable and valid, thereby supporting the credibility of research findings.\nContinuously improve data analysis processes and analytics models by implementing advanced analytics programming techniques, ensuring that the methodologies used are up-to-date and effective in delivering high-quality insights.\nBachelor\u2019s degree in data science, Computer Science, Statistics, Mathematics, or a related field, backed with relevant years of working experience.\nMaster\u2019s degree in above or advanced certifications in data science, machine learning, or related fields would be an added advantage.\no SAS (Statistical Analysis System) Certified Data Scientist\no SAS Certified Advanced Analytics Professional\no Open Certified Data Scientist\u00a0\no Microsoft Azure AI Fundamentals\u00a0\no IBM Data Science Professional Certificate\no CAP (Certified Analytics Professional)\u00a0\no DASCA (Data Science Council of America)\nMinimum 5-7 years of relevant working experience in conducting research and analytics function.\nRequires advanced proficiency in programming languages such as Python and other relevant statistical tools.\nProven ability in using exploratory analysis and preparing unstructured data to draw conclusions.\u00a0\nAbility to lead machine learning projects and modeling initiatives.\nExperience with data visualisation tools like Tableau and PowerBI.\nStrong analytical, critical thinking and problem-solving skills are a must.\nProficiency in data models and data sets, data cleaning methods, and handling\u00a0\nmultiple data sources.\nAbility to derive insights from complex data sets and present them clearly and concisely.\nKnowledge of additional programming languages or analytics tools is an advantage.\nRelevant experience in conducting research and analytics function would be an added advantage.\nWilling to work in\u00a0the \nHQ Office at Damansara Heights.\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nWhich of the following languages are you fluent in?\nAre you willing to undergo a pre-employment background check?\nHow much notice are you required to give your current employer?\nHow many years' experience do you have as a Research and Development Analytical Executive?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","50":"Having experience of 7+ years as senior oracle DBA\nArchitect HA and DR Solutions for PAAS services like Exadata, Autonomous Databases (ATP,ADW), RAC & Dataguard)\nInstallation and upgrade of Oracle and RAC on 10g\/11g\/12c\/18c\/19c version under Linux\/AIX platforms\nMust have oracle ASM\/ACFS implementation experience\nGood scripting skills to automate regular DBA admin tasks \u2022 Strong experience on backup utilities or tools like RMAN & EXPDP\/IMPDP, CRSCTL, SRVCTL, NetBackup, Networker\nApplying grid and DB PSU patch in standalone and multi-node RAC cluster servers\nShould have good command over speaking and writing.\nStrong experience on database and SQL queries tuning for Oracle and RAC databases\nShould have knowledge of oracle OEM 12C\/13C\nHe will be customer facing for all operational issues and activities\nStrong experience on configure and troubleshoot physical standby database using dataguard broker\nStrong experience on configure and troubleshoot golden gate replication components\nGood Grip over Tables fine tuning and troubleshooting\nImplement backup and recovery of Oracle databases for various scenarios\nAdministration over DB Objects including Tables , Clusters , Views , Procedures etc.\nGood in Impact Analysis of DB Change \/ DB Design Change etc.\nIn-depth understanding of Advanced Architectures (Multi-Node, RAC, ASM)\nGood understanding of core support processes and change management, maintain documentation standards\nMust have experience in Database tuning including I\/O, Load Analysis, ADDR, AWR, SQL Profiling etc\nResponsible for installation, upgrades (Database and RAC), patches, SR support, database tuning, concurrent manager administration, cloning\nAble to work in 24\/7 Support\nCandidate must possess at least a bachelor\u2019s degree, Post Graduate Diploma, Professional Degree (MCA \/ BE \/ BSC or SC computer science)\nOracle 10g\/11g\/12c\/18c\/19c OCP certification is a must\nHaving oracle RAC certification will be added advantage\nHaving previous banking BAU support will be added advantage\nHaving experience on additional database technologies MSSQL or DB2 or Sybase will be added advantage\nAt least 7 year(s) of working experience in the related field is required for this position.\nPreferably Senior Executives specializing in IT\/Computer \u2013 Network \/ System\/ Database Admin or equivalent.\nWhich of the following statements best describes your right to work in Malaysia?\nWhich of the following Relational Database Management Systems (RDBMS) are you experienced with?\nHow many years' experience do you have using SQL queries?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","51":"Collaborate closely with business stakeholders, including executives, managers, and subject matter experts, to understand their challenges, objectives, and opportunities for leveraging data science solutions.\u00a0\nProactively identify and define potential business use cases where data science techniques and models can provide valuable insights and drive impactful outcomes.\u00a0\nConduct in-depth discussions with business users to capture and document detailed requirements, ensuring a clear understanding of desired outcomes and deliverables.\u00a0\nUtilize advanced analytical techniques to explore and analyze relevant data sets, uncover patterns, correlations, and trends that can inform the development of effective data science solutions.\u00a0\nCreate visually compelling dashboards, reports, and presentations to communicate data-driven insights to stakeholders in a clear and understandable manner.\u00a0\nLead the design and development of data science models, algorithms, and prototypes to address identified business use cases, considering scalability, feasibility, and technical constraints.\u00a0\nCollaborate with data engineers and software developers to implement and operationalize data science models into production environments, ensuring smooth integration with existing systems and processes.\u00a0\nConduct rigorous evaluation and testing of implemented models to ensure accuracy, reliability, and alignment with business requirements. Make necessary refinements and optimizations as needed.\u00a0\nDrive the adoption of data science solutions by working closely with business users, providing training, support, and guidance on using and interpreting the outputs of implemented models.\u00a0\nA degree in Engineering, Statistics, Data Science, Applied Mathematics, Computer Science, Business Analytics or related technical field.\u00a0\nMinimum of 2 \u2013 4 years of relevant experience.\u00a0\nProficiency in statistical analysis, machine learning techniques, programming languages such as Python or R, and Deep Learning framework such as TensorFlow, PyTorch. Familiarity with data visualization tools and SQL is desirable.\u00a0\nStrong business understanding and the ability to translate business requirements into data science solutions effectively.\u00a0\nExcellent interpersonal, verbal, and written communication skills to engage with business users, explain technical concepts, and build rapport with stakeholders at all levels of the organization.\u00a0\nStrong analytical thinking and problem-solving abilities, with the capability to transform complex business challenges into actionable data science use cases.\u00a0\nProven experience in managing end-to-end data science projects, including requirements gathering, solution design, implementation, and post-deployment support.\u00a0\nLeaves: Annual Leave, Medical Leave, Hospitalization Leave, Special Leave.\u00a0\nMedical Benefits \u2013 Sunway Medical Insurance for Outpatient & Inpatient inclusive for dependents.\u00a0\nDental and Optical benefits.\u00a0\nGroup Term Life & Personal Accident Insurance Scheme.\u00a0\nExecutive Health Screening for confirmed executive.\u00a0\nFlexible Working Arrangement\/Hybrid Working Arrangement\u00a0\nSalary increment based on individual performance.\u00a0\nBonus based on company & individual performance.\u00a0\nCareer Development: Training and certification sponsored by the company, Annual Talent Review, Career Planning.\u00a0\nRewards and recognition: Long Service Award.\u00a0\nAdditional Benefits: Staff Discount (i.e. ThemePark, Hospitality, Education, Property, Medical, Retail, Food & Beverages), Sports and Recreational, Family Day, Annual Dinner, Flexible Working Arrangement for working mothers.\u00a0\nOpen communication. Young, energetic and fun working environment.\u00a0\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nHow many years' experience do you have as a data scientist?","52":"Design and develop AI models to enhance ERP functionalities.\nIntegrate AI solutions with ERP using its API.\nCollaborate with internal stakeholders to gather requirements and deliver customized solutions.\nTrain and support users in leveraging AI features.\nStay updated with the latest advancements in AI and ERP technologies.\nAI and Machine Learning:\nProficiency in machine learning algorithms and deep learning frameworks.\nExperience with NLP and predictive analytics.\nProgramming and Development:\nStrong skills in Python, R, SQL, and RESTful API development.\nExperience with data integration and ETL processes.\nData Management and Analysis:\nSkills in data preprocessing and database management.\nFamiliarity with big data technologies.\nSoftware Engineering:\nExperience with version control systems and SDLC.\nSkills in testing and validating AI models.\nAnalytical and Problem-Solving Skills:\nStrong analytical thinking and problem-solving abilities.\nCommunication and Collaboration:\nAbility to engage with stakeholders and provide training and support.\nStrong documentation skills.\nProficiency in machine learning algorithms and deep learning frameworks.\nExperience with NLP and predictive analytics.\nStrong skills in Python, R, SQL, and RESTful API development.\nExperience with data integration and ETL processes.\nSkills in data preprocessing and database management.\nFamiliarity with big data technologies.\nExperience with version control systems and SDLC.\nSkills in testing and validating AI models.\nStrong analytical thinking and problem-solving abilities.\nAbility to engage with stakeholders and provide training and support.\nStrong documentation skills.\nBachelor\u2019s or Master\u2019s degree in Computer Science, Data Science, or related field.\nRelevant certifications in AI, data science, or ERP systems.\nProven experience in AI development and ERP integration.\nFamiliarity with cloud computing platforms and DevOps practices.\nWhat's your expected monthly basic salary?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","53":"Design, develop, and deploy AI models and algorithms for various financial applications.\nCollaborate with cross-functional teams to gather and analyze data, identify opportunities for AI integration, and provide data-driven insights.\nImplement Generative AI, predictive analytics, and other AI techniques to develop advanced financial tools.\nStay up-to-date with the latest AI and machine learning trends and technologies and assess their potential applications in the Fintech industry.\nOptimize AI models for performance, scalability, and reliability.\nCreate and maintain documentation for AI solutions, including model architecture, data pipelines, and processes.\nParticipate in code reviews and provide guidance on best practices for AI development.\nBe part of building up MLOps ecosystem.\nBachelor's or Master's degree in Computer Science, Artificial Intelligence, Data Science, or a related field.\nHaving final year project or any working experience related to AI would be an advantage.\nExcellent problem-solving and analytical skills.\nEffective communication and teamwork abilities.\nQualifications\nSkills\nWorking Experience\nExpected Salary\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nHow much notice are you required to give your current employer?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","54":"Which of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as an Analytics Specialist?\nWhich of the following Relational Database Management Systems (RDBMS) are you experienced with?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","55":"You will understand our requirements and outcomes to ensure data-driven decision-making.\nYou will conduct tailored analysis for specific products and operations, define critical business metrics, track them rigorously, and recommend continuous improvements.\nYou will frame business scenarios and propose features that impact critical business processes and decisions.\nYou will transform requirements into concise insights through reports, presentations, and dashboards, and consolidate data from multiple sources to create comprehensive views for decision-making.\nYou will develop data pipelines and custom data science models to solve identified problems.\nYou will launch A\/B tests, analyse the results, and provide recommendations based on your findings.\nYou have at least 4 years of experience in data-related or quantitative fields such as Analytics, Science, Statistics, or Mathematics.\nYou are fluent with SQL, Python, R or other scripting\/programming languages.\nYou are experienced in handling large datasets and maintaining complex Extract, Transform and Load (ETL) processes.\nYou have solid statistical knowledge and hands-on experience running and analysing controlled experiments.\nYou are proficient in creating dashboards using Tableau, PowerBI or other visualisation tools.\nWe have your back with \nTerm Life Insurance \nand comprehensive \nMedical Insurance.\nWith \nGrabFlex, \ncreate a benefits package that suits your needs and aspirations.\nCelebrate moments that matter in life with loved ones through \nParental\n and \nBirthday leave\n, and give back to your communities through \nLove-all-Serve-all (LASA)\n volunteering leave\nWe have a confidential \nGrabber Assistance Programme\n to guide and uplift you and your loved ones through life's challenges.","56":"Cross-site leading role on enabling and sustain Equipment basic data with latest defined coupling\nLead team and actively maintain, provide consultancy for assigned data assets and responsible for defined data sets quality management\nInterface to FI\/IT on Equipment basic data specification\nKey user and expert for basic data system and planning model andensure high accuracy for purpose of business\nExpert and implement data governance for assigned data assets\nLead team and implement automation to improve basic data application\nAccountable for the implementation of global process and guideline. Close collaboration with cross-function and cross-site stakeholders to ensure standardization and implementation\n3- 5 years working experience in semiconductor or related field\nDegree in Computer science, Data science, Manufacturing engineering,Mathematics or other technical studies\nKnowledge of Oracle, SQL, Python, APF\/RTD, Tableau, Confluence,Outsystem\nExperience in data extract, transform, load solutions and dataanalytics solutions in industry (preferable semiconductor)\nProfound in communications and presentation of complex technical solutions to different stakeholders\nFluent in German and English\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","57":"Analyse and understand the business data requirements and translate it into a reporting solution.\nResponsible for creating an insight data\/ reporting \/ dashboard and presenting it to the respective stakeholders.\nParticipate in their current migration project from Tableau to PowerBI\nWill be supporting all global regions (global products with different business needs)\nCollaborate with data analysts, data engineers, and business stakeholders to gather requirements and ensure reports meet business needs.\n3 - 5 years of working experience\nHighly proficient in Power BI\nAble to understand, clean, transform, and prepare data from various sources to ensure it is suitable for reporting and analysis - visualisations\nAttractive remuneration package\nOpportunity for global business exposure\nDynamic working environment with career growth opportunities\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","58":"Provide leadership and guidance to the team to ensure alignment with management expectations.\nResponsible and oversee the implementation of all BI projects until Go Live.\nEnsure all projects are properly documented in accordance to the organization\u2019s project management methodology and templates.\nEnsure regular review with team on all BI projects and provide progress updates to the management.\nEnsure that the BI Servers and Datamart are in tiptop condition and able to support the smooth operation requirements.\nUp-to-date in BI Solution and market progress and provide continuous BI improvement to the organization.\nStrategize effective contingency plan to ensure information\/reporting downtime are kept to the minimum.\nSet and constant review the team\u2019s KPI and achievement.\nIdentify and plan for the team\u2019s learning\/training requirements to prepare for future goals.\nPerform relevant tasks as assigned by Management from time to time.\nAt least a Diploma in Computer related studies.\nMSSQL and Database Management certification is an added\nadvantage.\nGood communication and problem-solving skills.\nGood analytical skills to identify issues and bottlenecks.\nStrong problem-solving and analytical abilities in interpreting data.\nGood comprehension on Pivot table functionalities.\nGood team player.\nAbility to solve problems effectively, think creatively and deliver\nquality outputs in a timely manner.\nAbility to make decisions independently in a fast-paced environment.\nGood attention to detail.\nGood organizational, prioritization and time management skills.\nFast and keen learner \u2013 able to work individually and in a team.\nT-SQL Scripting\nDemonstrate proficiencies in office productivity tools (Excel, Words, Power Point).\nAt least 2 years of relevant working experience in Microsoft SQL\nenvironment, T-SQL development role.\nEnhance, refine or repurpose existing in-house data warehouse ETL\nprocess (MS SSIS).\nOptimize SQL queries, stored procedures, and database structures\nfor improved efficiency.\nStrong skills in SQL programming tasks including creating view,\nprocedures, function and packages.\nGather stakeholder requirements, translate into Business\nRequirements & Functional Requirements Documents, and\ntransform into System Design Documents.\nDesign, develop and implement innovative dashboards and analytic\nreports based on business stakeholder requirements.\nManage reporting issues and tickets reported by stakeholders by\nidentifying the potential root cause and able to coordinate and\ncommunicate with different parties to get the issues resolved.\nHave good knowledge in operational processes is an added\nadvantage.\nMonitor and maintain database health and performance using SQL\nServer Management Studio (SSMS) and other tools.\nIdentify and resolve performance bottlenecks and database-related\nissues.\nWhich of the following statements best describes your right to work in Malaysia?\nWhich of the following types of qualifications do you have?\nWhich of the following Relational Database Management Systems (RDBMS) are you experienced with?\nHow many years' experience do you have as an Information Technology Executive?\nHow many years' experience do you have using SQL queries?","59":"\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","60":"","61":"Design, develop, and deploy machine learning models and algorithms for complex and unique datasets, using various techniques such as mathematical modeling, scikit-learn, NLP, CNN, RNN, DL, RL, Transformers, GAN, LLM, RAG, prompt engineering, GPT.\nCollaborate with cross-functional teams to extract insights, identify business opportunities and provide data-driven recommendations\nStay up-to-date with the latest machine learning and AI techniques and tools\nCommunicate complex technical concepts to non-technical stakeholders in an easy-to-understand manner\nBachelor's degree or higher in Computer Science, Mathematics, Statistics, Actuarial Science, Informatics, Information Science or related fields\nStrong analytical skills and attention to detail\nParticipation in Kaggle, Mathematics Olympiad or similar competitions is a plus\nExcellent programming skills in Python, R, Java, or C++\nFamiliar with ML frameworks such as Tensorflow, Keras, PyTorch, MLFlow, AutoML, TensorRT, CUDA\nExcellent communication and collaboration skills\nExperience with designing, training, and deploying machine learning models\nCustomer centric and committed to deliver the best AI results to customers\nWhat's your expected monthly basic salary?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","62":"Responsible for the company's enterprise big data platform, building a hierarchical, flexible, and scalable enterprise big data platform.\nUnderstand business analysis requirements, design and develop corresponding data warehouses\/data marts, ETL development, and optimization work, to complete the construction of a structured, flexible, and scalable data warehouse.\nResponsible for data warehouse model design, report development, and maintenance.\nResponsible for the performance of the data warehouse system, model performance design, and optimization.\nWork together with the data product manager to solve technical problems related to business data analysis, data reporting, and data anomalies.\nDeeply understand business models, data models, and system models to improve system productivity.\nBachelor's degree or above in computer science, mathematics, or statistics; familiar with the internet industry, with over 3 years of experience in DW\/ETL\/BI work; proficient in at least one mainstream ETL\/BI solution.\nProficient in data warehouse architecture and principles, with experience in designing large-scale data warehouse architecture, model design, and performance tuning; proficient in SQL\/Hive, with good experience in SQL performance tuning, candidates with Java\/Python development experience are preferred.\nAble to proficiently use one or more mainstream databases (such as Oracle, MySQL, etc.), candidates with database design experience are preferred.\nExperience in developing big data distributed computing platforms, familiar with the principles and applications of Hadoop, Hive ecosystem products.\nSerious, responsible, and careful at work, with a good team spirit, good analytical skills, and communication skills.\nWhat's your expected monthly basic salary?\nHow many years' experience do you have as a Data Warehouse Engineer?\nWhich of the following languages are you fluent in?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","63":"Team Leadership: \nLead, mentor, and inspire a team of data scientists. Provide guidance on project priorities, technical challenges, and professional development. Foster a culture of innovation and continuous improvement within the team.\u00a0\nProject Management:\n Oversee end-to-end data science projects, ensuring timely and accurate delivery of advanced analytics and strategic insights. Coordinate with stakeholders to understand project requirements.\u00a0\nPredictive Modeling:\n Drive the development and implementation of predictive models using advanced statistical and machine learning techniques to solve complex business problems.\u00a0\nData Exploration and Preparation: \nGuide the team in exploring and preprocessing large datasets to extract meaningful features and insights.\u00a0\nCollaboration with Stakeholders: \nWork closely with cross-functional teams to understand business objectives, align data science initiatives, and communicate insights to both technical and non-technical stakeholders.\u00a0\nContinuous Improvement: \nDrive continuous improvement initiatives within the team, staying updated on the latest advancements in data science and contributing to the improvement of data science methodologies.\nLeadership Skills:\n Proven ability to lead and inspire a team of data scientists. Foster a collaborative and innovative team culture.\u00a0\nProject Management:\n Strong project management skills, including the ability to prioritize tasks, allocate resources, and meet deadlines.\u00a0\nAdvanced Analytical Skills:\n Proficient in analyzing large, complex datasets and extracting meaningful insights.\u00a0\nStatistical and Machine Learning Expertise:\n Experience in applying advanced statistical and machine learning techniques to solve real-world problems.\u00a0\nProgramming Skills: \nProficient in programming languages such as Python or R for data analysis and modeling.\u00a0\nCommunication Skills: \nExcellent communication skills to convey complex findings and insights effectively.\nEducational Background:\n Master's or Ph.D. in Data Science, Statistics, Computer Science, or a related field.\u00a0\nExperience:\n Proven experience as a Data Scientist, with a strong portfolio showcasing successful data science projects. Previous leadership or management experience is essential.\u00a0\nProgramming Proficiency: \nProficient in programming languages such as Python or R, and experience with relevant libraries and frameworks.\u00a0\nMachine Learning: \nSolid understanding and experience in applying machine learning algorithms to real-world problems.\u00a0\nCommunication Skills:\n Strong interpersonal and communication skills for effective collaboration with cross-functional teams.\u00a0\nContinuous Learning: \nStay updated with industry trends, data science techniques, and relevant tools. Attend training and development programs as needed.\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a data scientist?\nWhich of the following programming languages are you experienced in?","64":"What's your expected monthly basic salary?\nHow many years' experience do you have as an Agronomist?\nAre you willing to travel for this role when required?","65":"Build up call centre\u2019s data, analyse data indicators, and continuously optimize all data indicators;\nResponsible for setting and tracking operation targets (SLAs), analyzing abnormal data or weak links, giving early warning and improvement suggestions;\nDeeply understand the industry, improve the data analysis system, and promote the team's data analysis ability;\nAny ad-hoc duties as assigned by the Company from time to time.\nAt least 3 to 5 years of data analysis experience, large volume data analysis experience in call centre or related service industry is highly preferred;\nStrong knowledge of PowerBI and EXCEL functions for data analysis is an advantage;\nGood presentation ability to interpret and present statistical analysis (text, data and charts);\nGood at interpersonal communication, rigorous logical thinking, strong organization and coordination skills;\nIndependent, proactive, self-motivated, and able to meet tight deadline with minimal supervision.\nWhich of the following types of qualifications do you have?\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nHow many years' experience do you have as a Data Analytics Specialist?\nHow many years' experience do you have as a Power BI Developer?\nHow many years' experience do you have as an Excel Analyst?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","66":"Academic Qualification: Pursuing Bachelor's or Master's degree in Computer Science, Business Analytics, Statistics, Data Science, or any related field.\nExperience: Experience or coursework in Machine Learning, Natural Language Processing (NLP), Data Science or Analytics project.\nIT Literacy Able to work in an Agile environment with excellent time management skills.\nPersonality A positive attitude and a vibrant, creative personality.\nWhich of the following types of qualifications do you have?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","67":"create, train, and deploy machine learning models to address business challenges.\napply statistical analysis and data mining techniques to extract actionable insights.\nwork with data engineer(s) to design and maintain data pipelines.\nensure data integrity and quality through rigorous validation and processing methods.\nimplement data aggregation and enhancement processes to support analytics.\nassist in the development of AI products.\ncontinuously improve and optimize machine learning models for production use.\nbachelor's or master's degree in data science, computer science, statistics, or a related discipline\nminimum of 3 years of hands-on experience in data field\nstrong proficiency in Python and SQL\nskilled in machine learning tools like Scikit-learn, TensorFlow, PyTorch, etc\nsolid background in statistical analysis and data modeling\nexperience with data visualization platforms such as Tableau or Power BI\nfamiliar with data engineering tools like Apache Spark and Hadoop","68":"An exciting job with latest technology\nContinuous training & development of soft and hard skills\nA competitive salary, inline with your profile\nA package of benefits including healthcare insurance\nAn awesome team of colleagues & regular team building activities\nThe ability to work with the world\u2019s leading companies in technology and innovation\nAn environment where we embrace openness, transparency and grab every opportunity to have fun, while always doing what is right for our customers and partners.\nWhich of the following statements best describes your right to work in Malaysia?","69":"\u6570\u636e\u7ba1\u7406\u4e0e\u5206\u6790\uff1a\n \u4f7f\u7528 Excel \u7ba1\u7406\u548c\u5904\u7406\u5927\u578b\u6570\u636e\u96c6\uff0c\u8fdb\u884c\u6570\u636e\u6e05\u7406\uff0c\u5e76\u786e\u4fdd\u6570\u636e\u8d28\u91cf\u3002\n\u6570\u636e\u63d0\u53d6\u4e0e\u62a5\u544a\u66f4\u65b0\uff1a\n \u4ece\u5404\u79cd\u6765\u6e90\u63d0\u53d6\u6570\u636e\uff0c\u5305\u62ec\u6570\u636e\u5e93\uff0c\u5e76\u5b9a\u671f\u66f4\u65b0\u62a5\u544a\uff0c\u4ee5\u53cd\u6620\u6700\u65b0\u548c\u6700\u51c6\u786e\u7684\u89c1\u89e3\u3002\n\u62a5\u544a\u751f\u6210\uff1a\n \u5728 Excel \u4e2d\u521b\u5efa\u5e76\u81ea\u52a8\u751f\u6210\u7efc\u5408\u62a5\u544a\uff0c\u4ee5\u603b\u7ed3\u5173\u952e\u4e1a\u52a1\u6307\u6807\u548c\u8d8b\u52bf\u3002\n\u6570\u636e\u63d0\u53d6\uff1a\n \u4f7f\u7528 SQL \u4ece\u6570\u636e\u4ed3\u5e93\u4e2d\u63d0\u53d6\u548c\u5206\u6790\u6570\u636e\uff0c\u4ee5\u652f\u6301\u5404\u79cd\u4e1a\u52a1\u529f\u80fd\u548c\u62a5\u544a\u3002\n\u4eea\u8868\u677f\u521b\u5efa\uff1a\n \u8bbe\u8ba1\u548c\u7ef4\u62a4 Power BI \u4ea4\u4e92\u5f0f\u4eea\u8868\u677f\uff0c\u4ee5\u53ef\u89c6\u5316\u6570\u636e\u5e76\u5411\u5229\u76ca\u76f8\u5173\u8005\u63d0\u4f9b\u89c1\u89e3\u3002\n\u81ea\u52a8\u5316\uff1a\n \u4f7f\u7528 Python \u6216\u5176\u4ed6\u76f8\u5173\u5de5\u5177\u521b\u5efa\u5e76\u5b9e\u65bd\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u5904\u7406\u91cd\u590d\u6027\u4efb\u52a1\u3002\n\u903b\u8f91\u4e0e\u5206\u6790\u601d\u7ef4\uff1a\n \u8fd0\u7528\u5f3a\u5927\u7684\u903b\u8f91\u4e0e\u5206\u6790\u601d\u7ef4\u7406\u89e3\u5e76\u5904\u7406\u590d\u6742\u7684\u6570\u636e\u5173\u7cfb\uff0c\u786e\u4fdd\u89c1\u89e3\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002\n\u95ee\u9898\u89e3\u51b3\u4e0e\u4f18\u5316\uff1a\n \u8fd0\u7528\u521b\u9020\u6027\u548c\u6279\u5224\u6027\u601d\u7ef4\u8bc6\u522b\u73b0\u6709\u6d41\u7a0b\u4e2d\u7684\u8d8b\u52bf\u3001\u5f02\u5e38\u548c\u6539\u8fdb\u673a\u4f1a\u3002\n\u534f\u4f5c\uff1a\n \u4e0e\u8de8\u804c\u80fd\u56e2\u961f\u5bc6\u5207\u5408\u4f5c\uff0c\u4e86\u89e3\u6570\u636e\u9700\u6c42\uff0c\u5e76\u57fa\u4e8e\u5206\u6790\u63d0\u4f9b\u53ef\u884c\u7684\u5efa\u8bae\u3002\n\u5229\u76ca\u76f8\u5173\u8005\u6c9f\u901a\uff1a\n \u5411\u6280\u672f\u548c\u975e\u6280\u672f\u5229\u76ca\u76f8\u5173\u8005\u6e05\u6670\u6709\u6548\u5730\u5c55\u793a\u6570\u636e\u89c1\u89e3\u3001\u62a5\u544a\u548c\u5efa\u8bae\u3002\n\u6301\u7eed\u5b66\u4e60\uff1a\n \u5173\u6ce8\u884c\u4e1a\u8d8b\u52bf\u548c\u5206\u6790\u5de5\u5177\u7684\u8fdb\u5c55\uff0c\u6301\u7eed\u63d0\u5347\u6280\u672f\u548c\u8f6f\u6280\u80fd\u3002\nExcel\uff1a\n \u9ad8\u7ea7\u6280\u80fd\uff0c\u719f\u7ec3\u4f7f\u7528\u516c\u5f0f\u3001\u6570\u636e\u900f\u89c6\u8868\u548c\u6570\u636e\u53ef\u89c6\u5316\u3002\nSQL\uff1a\n \u57fa\u672c\u5230\u4e2d\u7ea7\u7684 SQL \u67e5\u8be2\u7f16\u5199\u77e5\u8bc6\uff0c\u8fdb\u884c\u6570\u636e\u63d0\u53d6\u548c\u5206\u6790\u3002\nPower BI\uff1a\n \u6709\u6570\u636e\u53ef\u89c6\u5316\u548c\u521b\u5efa\u4ea4\u4e92\u5f0f\u4eea\u8868\u677f\u7684\u7ecf\u9a8c\uff08\u4f18\u5148\u8003\u8651\uff09\u3002\nPython\uff1a\n \u719f\u6089\u4f7f\u7528 Python \u81ea\u52a8\u5316\u6570\u636e\u5904\u7406\uff08\u4f18\u5148\u8003\u8651\uff09\u3002\nOKR \u4efb\u52a1\u7ba1\u7406\uff1a\n \u719f\u6089 OKR \u6846\u67b6\uff0c\u4ee5\u4fbf\u5c06\u6570\u636e\u4efb\u52a1\u4e0e\u4e1a\u52a1\u76ee\u6807\u5bf9\u9f50\uff08\u4f18\u5148\u8003\u8651\uff09\u3002\n\u7ecf\u9a8c\uff1a\n \u81f3\u5c11 2 \u5e74\u6570\u636e\u5206\u6790\u6216\u76f8\u5173\u9886\u57df\u7684\u5de5\u4f5c\u7ecf\u9a8c\u3002\nData Management & Analysis:\u00a0\nUse Excel to manage and manipulate large datasets, perform data cleaning, and ensure data quality.\nData Extraction & Report Updates:\u00a0\nExtract data from various sources, including databases, and update reports regularly to reflect the most accurate and up-to-date insights.\nReport Generation:\u00a0\nCreate and automate comprehensive reports in Excel to summarize key business metrics and trends.\nData Extraction\n: Extract and analyze data from the data warehouse using SQL to support various business functions and reports.\nDashboard Creation:\u00a0\nDesign and maintain interactive dashboards in Power BI to visualize data and provide insights to stakeholders.\nAutomation: \u00a0\nCreate and implement automated solutions for repetitive tasks using Python or other relevant tools.\nLogical & Analytical Thinking:\u00a0\nApply strong logical and analytical thinking to understand and handle complex data relationships, ensuring the accuracy and reliability of insights.\nProblem Solving & Optimization:\u00a0\nUse creative and critical thinking to identify trends, anomalies, and opportunities for improvement in existing processes.\nCollaboration: \u00a0\nWork closely with cross-functional teams to understand data needs and provide actionable recommendations based on analysis.\nStakeholder Communication:\u00a0\nPresent data insights, reports, and recommendations clearly and effectively to both technical and non-technical stakeholders.\nContinuous Learning:\u00a0\nStay up to date with industry trends and advancements in analytics tools, continuously enhancing both technical and soft skills.\nExcel\n: Advanced proficiency with formulas, pivot tables, and data visualization.\nSQL\n: Basic to intermediate knowledge in writing SQL queries for data extraction and analysis.\nPower BI\n: Experience with data visualization and creating interactive dashboards (preferred).\nPython\n: Familiarity with automating data processes using Python (preferred).\nOKR Task Management\n: Familiarity with OKR frameworks for aligning data tasks with business objectives (preferred).\nExperience\n: At least \n2 years\n of experience in a data analysis role or a related field.\nWe are seeking candidates proficient in Mandarin to better serve our Mandarin-speaking customers.\nWhat's your expected monthly basic salary?\nHow many years' experience do you have as a data analyst?\nWhich of the following data analytics tools are you experienced with?","70":"You will understand business problems and convert them to ML problem space. Work with the business teams to understand workflows and requirements, and analyze data to identify patterns, trends, and anomalies that can inform automation projects and provide insights to stakeholders.\nYou will collaborate with the Data Science and Software Engineering teams to identify areas of automation and optimization within our systems, with a focus on operational efficiency and reducing manual interventions.\nYou will design, develop, and implement automation solutions that improve the efficiency of different processes, using your expertise in data analysis, machine learning, and engineering knowledge.\nYou will lead automation projects aimed at complex system fine-tuning with real market change, applying data-driven techniques to bring growth in the automated system.\nYou will use machine learning techniques to improve automation resilience and improve system performance.\nYou will work with stakeholders to define project goals and deliverables, ensuring that the automation projects align with the goals.\nAt least 3 years of experience in software engineering or data science, and experience in writing production code.\nProficiency in SQL, Python and at least one backend language like Go, Scala, Java, C++, or others.\nProficiency in data processing frameworks such as Spark or Flink.\nProficiency in ML and DL frameworks such as XGBoost or Pytorch.\nExperience in ETL pipelines for data processing, model training and serving.\nUnderstanding of optimization concepts and techniques, with experience in applying optimization methods to improve system performance.\nExperience with large-scale systems and DevOps best practices such as CI\/CD.\nWe have your back with Term Life Insurance and comprehensive Medical Insurance.\nWith GrabFlex, create a benefits package that suits your needs and aspirations.\nCelebrate moments that matter in life with loved ones through Parental and Birthday leave, and give back to your communities through Love-all-Serve-all (LASA) volunteering leave\nWe have a confidential Grabber Assistance Programme to guide and uplift you and your loved ones through life's challenges.\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","71":"Forming clear data addressable problem statements from current business problems\nGathering, validating and understanding data relevant to the problem statement\nDesigning and building data transformation pipelines and machine learning algorithms to solve the business problem\nWorking with product management and other business stakeholders to review and iterate data products to fit emerging market trends\nEvangelising appropriate ML methods and explaining them, and their associated benefits and limitations to team members from Engineering and Strategy.\nPost graduate qualification in a quantitative field (e.g. Physics, Mathematics, Bioinformatics, Computer Science)\nAdvanced data extraction and processing skills using SQL, Spark, etc\nFamiliarity with S3, EC2 and\/or EMR in AWS.\nDeep knowledge of machine learning algorithms and efficient data structures, ensembling and model performance tuning\nExperience with NLP\nConfident working at the command line in a *nix environment\nAble to write serviceable code (e.g. Scala, Go, Python, Ruby) and comfortable working with and around a professional software development teams\nGood communication and interpersonal skills with the ability to communicate with business key decision makers and product owners\nAbility to adapt quickly and thrive in an ambiguous and rapidly changing environment\nExperience with Deep Learning (particularly CNNs and RNNs)\nTrack record in working independently within an agile team environment, scoping work, making and keeping commitments to deliver against a shared agenda\nExperience working with datasets which do not fit within memory on a single machine\nHybrid working mode\nPermanent position\nMature and collaborative working culture\nExtensive employee benefits","72":"Which of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a data scientist?\nWhich of the following languages are you fluent in?","73":"Manage cost savings and efficiencies against department budget by set up specific goals in reducing cost.\nHow many years' experience do you have as a data analyst?\nWhich of the following Microsoft Office products are you experienced with?","74":" \nPrepare model performance monitoring reports and accountable for accurate, timely reporting to the management committee.\u00a0 The monitoring report served to provide insights to ensure correct use of model and facilitate critical decision making related to model recalibration or refinement.\n\n\n \nReview and on-going improvement in model performance monitoring process and automation.\n\n\n \nKnowledge of scripting particularly in SAS, Python, data savvy and able to work with huge datasets to ensure on-going model monitoring in accordance to Basel and MFRS requirements. \n\n\n \nDrill down into data\/trend identified from the data.\u00a0 Presents and discusses analysis, model monitoring results i.e. identify area of concern and its thought\/rational.\u00a0 \n\n\n \nRecommend and establish standards, guidelines and processes that improve model monitoring approaches.\n\n\n \nComprehensive awareness of the business, regulatory environment, technology and trends and ensure these are reflected in the models monitoring in timely and accurate manner. \n\n\n \nStrong communication skills.\u00a0 Ability to communicate model monitoring result through compelling narratives within the team as well as to different business leaders and provide value added input to make data driven business decision as well as model enhancement initiatives.\u00a0 \n\n\n \nSocialize with business expert to gather business insight in the respective area of model monitoring and data analytics.\n\n\n \nCollaboration within the team and related parties correspondence to data related activities i.e. data derivation rules etc. \n\n\n \nGood knowledge of relevant regulatory requirements on risk models and risk parameters.\n \nGood understanding on the respective area\u2019s business products and operations.\n \nGood analytical skills.\n \nGood statistical modeling knowledge.\n \nGood understanding of relational databases and data models.\n \nGood programming skills in data handling and statistical modeling.\n\n\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","75":"To produce regular experience analysis reports granularity for Accident and Health plans, in support of the Company\u2019s medical claim management strategy.\nTo produce regular mortality and morbidity claim experience analysis.\nTo work closely with the business and operation teams (ie. claim, underwriting, agency, marketing, etc.) to understand business requirements and to formulate an analytical work plan based on the stated objectives.\nExecute the analytical work plan end-to-end from producing data requirements, extracting data to completing the analysis and presenting the results\/analytic insights to business user.\nDevelop deep understanding of operational and business data and continuously improve existing workflow.\nPreparing reports for the management stating trends, patterns, and predictions using relevant data.\nAnalyzing local, national, and global trends that impact both the organization and the industry\nUsing statistical tools to identify, analyze, and interpret patterns and trends in complex data sets could be helpful for the diagnosis and prediction.\nA bachelor\u2019s degree in Actuarial Science, Computer Science, Information Management, IT, Applied Statistics, Finance, Accounting, Data Analytics or any related discipline.\nMinimum 6 years\u2019 experience in relevant fields (Domain knowledge: Insurance\/Takaful operations, Claims, NBUW etc)\nProficient in both written and spoken English and Bahasa.\u00a0\nProficient in Microsoft Office applications and analysis tool (SQL, Power BI, Qlik Sense, SAS, Python, Oracle DB etc)\nAbility to work with minimum supervision, flexible and agile in ways of working.\u00a0\nAnalytical skills and strong organizational abilities.\nGood presentation skills, ability to interpret and present to senior management.\nA team player with good communication skills being key in managing stakeholders.\nBackground in market research and project management skills will be an added advantage.\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following languages are you fluent in?","76":"Min 3 years working experience\nProficient in SQL, Python, Snowflake \/ Azure \/ AWS \/ GCP\nExpert in ETL processes, Data Transformation, Pipeline Development, Database Management and Data Warehousing\nCompetitive salary and benefits package\nInnovation Solutions but using cutting-edge technologies","77":"Manage critical technical maintenance activities associated with all mechanical systems to reduce operational risk and in accordance with the MOP.\u00a0\nResponsible for developing the SOP, EOP and MOP for all the critical facility equipment and activities\nProvide technical support during the construction phase, responding to RFIs and addressing any issues that arise.\nWork with the Shift team on incident investigation, follow up actions and the submission of the interim and final report to Senior management for review.\u00a0\nTo identify the parameters to be trend in the BMS\/DCIM system data and focusing on data analysis to identify opportunities to improve the reliability\/efficiency of the Critical equipment or processes.\nTo support in the Green Mark DC Certification and ensure that the existing Chiller Plant is compliance to the Green Mark requirement.\nParticipate in perform drill \/ Tabletop exercise \/ dry run-on equipment failure in developing the Emergency Operating Procedures.\nTo support and coordinate in Major activities like Annual Shutdown, Overhaul etc\u00a0\nCoordinating with multiple disciplines to ensure that projects are delivered within budget and on schedule while managing the mechanical team including HVAC, fire protection, plumbing.\nKeep abreast of changes in codes and technologies appropriate to the mechanical, plumbing and fire protection disciplines.\nAnalyse and evaluate mechanical system performance, identifying areas for improvement and making recommendations for upgrades.\nEvaluate and recommend new technologies and equipment to enhance system performance and reduce operational costs.\nCollaborate with cross-functional teams, including electrical and mechanical engineers, to ensure seamless integration of the chiller systems with other data centre infrastructure.\nAnalyse energy usage, identifying opportunities for optimization and cost savings.\nDiploma\/ degree in Mechanical Engineering\/ Building Services or equivalent.\n5 years of working experience in data center or critical infrastructure industry\u00a0like refinery or oil and gas\nFamiliar with Microsoft Excel and Word, BMS, CMMS\/ DCIM, ERP and Microsoft BI.\nExcellent in problem solving and root cause analysis.\nAbility to articulate and explain technical concepts to non-technical trained stakeholder\nWhich of the following statements best describes your right to work in Malaysia?\nHow many years' experience do you have as a mechanical engineer?","78":"\n\nDesign, develop, document and implement end-to-end data pipelines and data integration processes, both batch and real-time. This includes data analysis, data profiling, data cleansing, data lineage, data mapping, data transformation, developing ETL \/ ELT jobs and workflows, and deployment of data solutions.\n\n\nMonitor, recommend, develop and implement ways to improve data quality including reliability, efficiency and cleanliness, and to optimize and fine-tune ETL \/ ELT processes.\n\n\nRecommend, execute and deliver best practices in data management and data lifecycle processes, including modular development of ETL \/ ELT processes, coding and configuration standards, error handling and notification standards, auditing standards, and data archival standards.\n\n\nEnsure development adheres to guidelines and governance policies on data and business intelligence platform.\n\n\nCollaborate with IT team members, SMEs, vendors and internal business stakeholders, to understand data needs, gather requirements and implement data solutions to deliver business goals.\n\n\nBAU supports any data issues and change requests, documents all investigations, findings, recommendations and resolutions.\n\n\nSupport daily operation incidents and service requests.\n\n\n\n\nHands-on experience on Azure Data Solution such as Azure Synapse Spark, Synapse DB, Data Factory, Databricks, Azure Lake Storage and Power BI.\n\n\nExperience with various ETL\/ELT frameworks, data warehousing concepts, data management framework and data lifecycle processes.\n\n\nExperienced in handling and processing different types of data (structured, semi-structured and unstructured).\n\n\nUtilized Azure DevOps to implement CI\/CD workflows and deployment of ETL jobs across multiple environments.\n\n\nStrong knowledge in various database technologies (RDBMS, NoSQL and columnar).\n\n\nProficient in ETL programming languages like Python, PySpark and SQL.\n\n\nExperience with Microsoft Fabric is an added advantage.\n\n\nAbility to communicate and present technical information in a clear and unambiguous manner.\n\n\nStrong ability to work independently and cooperate with diverse teams in a multiple stakeholder environment.\n\n\nStrong sense of work ownership, high affinity with any data and a desire for constant improvements.\n\n\nExperience with SAP data sources preferred.\n\n","79":" \nAttractive remuneration, great perks, and performance incentives\n \nComprehensive medical, insurance, or social security coverage\n \nWorld-class workspaces\n \nEngaging activities and recognition programs\n \nStrong learning and development plans for your career growth\n \nPositive culture for you to #BeMore at work\n \nEasy to locate area with direct access to public transport\n \nFlexible working arrangements\n \nBe coached and mentored by experts in your field\n \nJoin a global company, winner of hundreds of industry awards\n \n \nData Architecture Design: \n \nDesign and implement effective data architecture, solutions and models to store, retrieve, cleanse, process company data that would fit the dynamic nature of our clients' data systems and analytics needs\n \nExamine and identify data architectural and processes necessities by evaluating client operations, applications, and programming.\n \nAssess data architecture implementation procedures to ensure they comply with internal and external regulations.\n \n \n \nData Governance and Quality: \n \nLead data governance initiatives to ensure data accuracy, completeness, security, and regulatory compliance.\n \nMonitor data quality, identify data inconsistencies, and implement corrective strategies to address short and long terms challenges.\n \n \n \nData Strategy and Policy Development: \n \nDevelop and implement comprehensive data management policies and procedures to ensure the integrity, availability, and confidentiality of data.\n \nCollaborate with IT security to implement robust data security measures.\n \n \n \nData Integration and Migration: \n \nPlan and execute data migration between systems, ensuring data integrity and minimal impact on ongoing business, data and development operations.\n \nOversee the integration of new data management technologies and software engineering tools into the existing system.\n \n \n \nTeam Leadership & Project Management: \n \nOversee data-related projects from inception to completion, ensuring they meet deadlines, budgets, and quality standards.\n \nManage and lead the data management team, setting clear objectives and evaluating performance.\n \nCollaborate with other departments to identify and meet data requirements, ensuring that data is accessible and useful across the organization.\n \nPrioritize and allocate resources effectively to manage multiple projects simultaneously. Any other duties and responsibilities that may be assigned to you by the management from time to time, within your category of employment in the organization.\n \n \n \n \nDesign and implement effective data architecture, solutions and models to store, retrieve, cleanse, process company data that would fit the dynamic nature of our clients' data systems and analytics needs\n \nExamine and identify data architectural and processes necessities by evaluating client operations, applications, and programming.\n \nAssess data architecture implementation procedures to ensure they comply with internal and external regulations.\n \n \nLead data governance initiatives to ensure data accuracy, completeness, security, and regulatory compliance.\n \nMonitor data quality, identify data inconsistencies, and implement corrective strategies to address short and long terms challenges.\n \n \nDevelop and implement comprehensive data management policies and procedures to ensure the integrity, availability, and confidentiality of data.\n \nCollaborate with IT security to implement robust data security measures.\n \n \nPlan and execute data migration between systems, ensuring data integrity and minimal impact on ongoing business, data and development operations.\n \nOversee the integration of new data management technologies and software engineering tools into the existing system.\n \n \nOversee data-related projects from inception to completion, ensuring they meet deadlines, budgets, and quality standards.\n \nManage and lead the data management team, setting clear objectives and evaluating performance.\n \nCollaborate with other departments to identify and meet data requirements, ensuring that data is accessible and useful across the organization.\n \nPrioritize and allocate resources effectively to manage multiple projects simultaneously. Any other duties and responsibilities that may be assigned to you by the management from time to time, within your category of employment in the organization.\n \n \nBachelor's or master's degree in Data Science, Computer Science, Information Management, or a related field.\n \nProven experience (7-10 years' experience) in data management, data governance, and significant experience in data architecture or a similar role.\n \nStrong understanding of databases, data analysis procedures, and data administration.\n \nIn-depth knowledge of data architecture design and deployment, database management, and data modeling tools.\n \nExperience with data management software and tools.\n \nExcellent leadership and team management skills.\n \nStrong communication and interpersonal abilities.\n \nHands-on approach, getting things done fast and ability to work without continual guidance.\n \nKnowledge of data privacy laws and compliance requirements.\n \nCertification in data management (e.g., CDMP) and data architecture (e.g., TOGAF, CDA) is preferred.\n \nExperience in data development & management on Cloud platforms like AWS, GCP, Azure, with basic familiarity of BI software i,e., Power BI, Looker Studio or Tableau is preferred.\n \nGood to have experience with Workflow Management i.e. Airflow and Jenkins, and CI\/CD tools such as Git and JIRA.\n \nCreative thinker with agile mind and ability to recognize inefficiencies and challenge the status quo.\n \nAttention to detail.\n \nExcellent presentation skills.\n \nWorks well in ambiguity and embraces the adventure!\n \n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","80":"\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","81":"Develop and implement data-driven strategies for workforce planning, including forecasting talent needs, succession planning, and identifying skill gaps.\nUtilize predictive analytics to anticipate future workforce trends, such as attrition, hiring needs, and capability shifts.\nDesign and implement dashboards for ongoing workforce tracking, enabling proactive decisions around hiring, promotions, and internal mobility.\nCreate comprehensive reports and visualizations that communicate actionable insights to HR leadership and business stakeholders, and prepare standard reporting capabilities.\nAutomate reporting processes and integrate various data sources to provide cohesive reporting capabilities.\nPresent data insights to non-technical stakeholders in a clear, concise manner, ensuring understanding across diverse business units.\nBuild and maintain dynamic, real-time dashboards using Power BI, providing leadership with key insights into HR metrics.\nWork closely with HR, finance, and business leaders to understand their data needs and deliver customized solutions.\nSupport the HR function in transforming data into insights that inform talent acquisition, retention, and development strategies.\u00a0\nLead and support projects focused on improving HR processes and outcomes through data-driven strategies.\nStay updated on industry trends and best practices in people analytics, incorporating them into the company's HR strategy.\nEnsure compliance with data protection laws and regulations (e.g., GDPR) when handling employee data.\nMaintain the highest level of integrity and confidentiality when dealing with sensitive employee data.\nBachelor\u2019s or Master\u2019s degree in Data Science, Statistics, or Business Administration, or a related field.\n5 years of experience in data analytics, preferably within an HR context.\nExperience with SAP SuccessFactors Reporting\nStrong experience in data-driven approaches to anticipate future workforce needs\nProven track record of delivering actionable insights that positively impact business outcomes.\nProficiency in statistical analysis software (e.g., R, Python) and Excel for complex data analyses.\nAdvanced Power BI skills, including the ability to create dynamic, user-friendly dashboards.\nStrong problem-solving and critical-thinking abilities, especially in interpreting HR data.\nExcellent communication skills, with the ability to present data to non-technical stakeholders.\nStrong project management and organizational skills, capable of managing multiple initiatives simultaneously.\nStrong attention to detail and a commitment to data accuracy.\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","82":"Which of the following statements best describes your right to work in Malaysia?\nWhich of the following types of qualifications do you have?\nWhich of the following languages are you fluent in?\nWhat is your degree CGPA range?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","83":"Architect and Design Solutions:\n\u00a0Lead the design and architecture of scalable, secure, and resilient cloud solutions across multiple cloud platforms (AWS, Azure, Google Cloud).\nData and AI Integration:\n\u00a0Develop and implement data strategies, including data lakes, data warehouses, and real-time data processing. Integrate AI and machine learning models to enhance business processes and decision-making.\nTechnical Leadership:\n\u00a0Provide technical leadership and guidance to development teams, ensuring best practices in cloud architecture, data management, and AI implementation.\nStakeholder Collaboration:\n\u00a0Collaborate with business stakeholders to understand requirements and translate them into technical solutions. Communicate complex technical concepts to non-technical stakeholders.\nInnovation and Strategy:\n\u00a0Stay updated with the latest trends and technologies in cloud computing, data, and AI. Drive innovation and strategic initiatives to enhance our technology stack.\nSecurity and Compliance:\n\u00a0Ensure that all solutions adhere to security best practices and compliance requirements. Implement robust security measures to protect data and applications.\nPerformance Optimization:\n\u00a0Monitor and optimize the performance of cloud-based applications and data systems. Identify and resolve performance bottlenecks.\nDocumentation and Training:\n\u00a0Create comprehensive documentation for designed solutions. Provide training and support to internal teams and clients.\nEducation:\n\u00a0Bachelor\u2019s or Master\u2019s degree in Computer Science, Information Technology, or a related field.\nExperience:\n\u00a0Minimum of 8 years of experience in solution architecture, with a focus on cloud computing, data management, and AI.\nCloud Expertise:\n\u00a0Proficiency in multiple cloud platforms (AWS, Azure, Google Cloud). Certification in one or more cloud platforms is a plus.\nData Management:\n\u00a0Strong experience with data architecture, data lakes, data warehouses, and real-time data processing.\nAI and Machine Learning:\n\u00a0Hands-on experience with AI and machine learning frameworks and tools (e.g., TensorFlow, PyTorch, Azure ML, AWS SageMaker).\nTechnical Skills:\n\u00a0Proficiency in programming languages such as Python, Java, or C#. Experience with containerization (Docker, Kubernetes) and CI\/CD pipelines.\nSoft Skills:\n\u00a0Excellent communication, problem-solving, and leadership skills. Ability to work collaboratively in a fast-paced environment.\nCertifications:\n\u00a0Relevant certifications in cloud computing, data management, and AI are highly desirable.\nWhich of the following types of qualifications do you have?\nWhich of the following statements best describes your right to work in Malaysia?\nWhich of the following programming languages are you experienced in?\nWhat's your expected monthly basic salary?\nHave you worked in a role which requires experience with machine learning?\nHow many years' experience do you have as a solutions architect?\nHow many years' experience do you have as an Artificial Intelligence Specialist?","84":"\n\nCollaborate with cross-functional teams to analyze and drive actions to improve End to End Yield.\n\n\nDevelop and implement algorithms and methodologies to identify and address yield issues.\n\n\nDesign and maintain web services for data analysis and visualization.\n\n\nUtilize coding skills to automate data collection, analysis, and reporting processes.\n\n\nImplement AI Techniques to develop predictive yield models and optimize production & Test performance.\n\n\nWork closely with engineering teams to optimize manufacturing processes and reduce scraps.\n\n\nMonitor and analyze production data to identify trends and potential areas for improvement.\n\n\nDrive continuous improvement initiatives to enhance yield performance and product quality.\n\n\nProvide regular reports and updates on yield metrics and performance.\n\n\nAble to sustain existing process systems will be added advantage.\n\n\n\n\nBachelor\u2019s degree in electrical engineering, Computer Engineering, or related field.\n\n\nAt least 4 years\u2019 experience in yield engineering or semiconductor manufacturing.\n\n\nStrong coding skills, with proficiency in languages such as Python, SQL, Java, or C++.\n\n\nStrong data analysis and statistical techniques.\n\n\nKnowledge of database systems and data management.\n\n\nKnowledge on AI and machine learning algorithms will be added advantage.\n\n\nFamiliarity with semiconductor assembly process and test methodology.\u00a0\n\n\nExperience in web service development and maintenance.\n\n\nExcellent communication and collaboration skills.\n\n\nAbility to work effectively in a fast-paced, dynamic environment.\n\n\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","85":"Develop, maintain, and improve dashboards to monitor and assess chatbot performance.\u00a0\nExperience with conversational design principles and best practices for chatbot user interfaces would be an advantages.\u00a0\nConduct market research to stay abreast of industry trends, competitor offerings, and emerging technologies in AI and chatbots.\nAssist in creating and maintaining product roadmaps that align with business goals and user needs.\nCommunicate product features, updates, and user feedback to both technical and non-technical stakeholders.\nContribute to the continuous improvement of our \nAI models \nand natural language processing\u00a0capabilities.\nBachelor's degree in Computer Science or a related technical field.\n5~8 years of experience in product management\n, preferably in AI, chatbots, or related technologies.\nStrong understanding of AI and Machine Learning concepts, particularly in \nnatural language processing (NLP)\n and Gen AI.\nProficiency in data analysis and interpretation, with experience using tools such as R, SQL, or Python.\nExcellent problem-solving skills with the ability to translate data insights into actionable product improvements.\nStrong project management skills.\nOutstanding communication and collaboration skills, with the ability to work effectively in cross-functional teams.\nDemonstrated ability to manage priorities and drive product outcomes.\nKnowledge of regulations related to \ndata privacy and protection\n as they apply to AI and chatbots.\nTechnical leadership and guidance in the evaluation, selection and integration of software and cloud-based technologies.\n\u00a0\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Solution Lead?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","86":"The individual will be responsible to provide ETL (extract-transfer-load) solutions and deployment of these solutions thus involve in various BI and Big Data Analytics related projects.\nThe individual will also be responsible in building necessary automation data feeds (ETL\/ELT) mechanisms for data transfer from various source applications to target applications. Perform data integration - administration, optimization of performance evaluation & monitoring to the data feeds.\nSupport existing production portfolio and troubleshoot issues in providing fixes and solutions.\nParticipate in all aspects of software product development life cycle (SDLC) including requirement gathering, work flow architecture design, development, testing, demo, training and documentation. Plan, prepare and lead User Acceptance Test (UAT) for releases and ensure testing completeness.\nThe individual should demonstrate hi-energy and desire for data mining, scripting, problem solving and data analysis.\nWork collaboratively with DBAs, infrastructure, network, data enablement teams and application BA analysts.\nCollaborate improvements in data governance, methodologies and processes. Demonstrate a deep interest and understanding of big data, data modelling, data structures, data catalogue and how to manipulate data in an efficient manner. Quick in formulating quality, feasible and practical solution fit to big data application\nAble to perform knowledge sharing of theoretical and practical.\nKnack of exploring and try out new things related to Data Analytics world.\nTraining will be provided on needed basis.\nSomeone with minimum 5 years of IT working experience especially into Business Intelligence or Data Analytics related job.\nPossess at least a Degree in Computer Science, Information Technology, Engineering or related courses.\nData integration (ETL), mining, analytics \nexperiences is A MUST. \nExperience in manipulating and analyzing complex, high-volume, high-dimensionality data from varying sources and perform ETL (extract transfer load) scripts.\nDevelopment\u00a0experience in Data Lake solutions such as Data Bricks, Azure DataLake, Fabric, AWS, Snowflake, Cloudera or Data Fabric such as Atlan, cinchy, IBM for \nBig Data solution is preferred.\nHave experience in development in Hadoop environment is an added advantage and understand components the applications in Hadoop eco-system using ETL framework components such as Nifi, Kafka, Pentaho, Spark, Datalake Insights etc.\nCloud environment \ndevelopment\u00a0 experience is y preferred. HCIA\/HCIP\/HCIE certificate in cloud computing, or equivalent certificates in the industry preferred, ep: \nAWS, Azure, GCP cloud certificates\n. Familiarity with AWS particularly services S3, Lambda, EMR, EC2 is added advantage.\nSQL \nexperience a MUST\n. Perform SQL as daily routine job. Working experiences in development database (such as MSSQL Server, Teradata or Oracle).\nHave working experience or exposure with Business Intelligence tools is highly recommended. Preferably: \nTableau, Power Query, Power BI Desktop etc\n.\nComing from manufacturing background (but not essential).\nOther preferred software skill(s): \nPHP, Python, Java, Javascript is an added advantage\n.\nStrong visualization capability and passionate in quantitative analysis \u2013 statistics, math, modeling, design etc.\nStrong written and verbal communication skills. Good communication background. Good command in English speaking, listening and writing is highly desired. Important as this needed to work will multi organization manufacturing and enterprise within the company\nMust be result oriented with strong analytical, troubleshooting & problem-solving skills with minimal supervision.\nKnowledge of Project Management and Safe Agile process is an added advantage.\nExtremely passionate with data from source to end solution\nExperienced working in a virtual team environment is a plus.\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Data Engineer?\nHow many years' experience do you have using SQL queries?\nWhich of the following programming languages are you experienced in?\nWhich of the following data analytics tools are you experienced with?\nHow much notice are you required to give your current employer?\nHow many years' experience do you have as a Data Integration Engineer?","87":"As a Data Engineer for Big Data Solutions\u00a0you will actively collaborate in the development of IT pipelines to transfer data between different systems in the international semiconductor operations network (SO)\nThis includes working on ETL (Extract \u2013 Transfer \u2013 Load) development for Hadoop ecosystem, SQL and other related technologies\nSupport in developing and programming a custom ETL framework in Python\nWork with customer departments and senior management to understand business objectives and requirements of the organization and develop solutions\nCollaborate with IT departments from different plants worldwide to roll out our developed solutions to the semiconductor IPN\nBe part of an agile development team and take responsibility for tasks defined by the product owner\nUniversity Degree (Bachelor\/Master) in Information Technology or comparable qualifications\nCandidate posses 3-5 years similar work experience in the same field\nGood communication skills (Verbal and Written) especially in meetings and reviews with all levels and departments\nAble to work in an intercultural team\nStrong interest in modern technologies, agile mindset and ability to work under pressure\nReliability and flexibility to work in a pioneer team\nKnowledge of programming language like Python, Java, C++\nExperience with working in a Hadoop Ecosystem (eg. PySpark, Airflow, Kafka)\nStructured and independent way of working, analytical skills to grasp complex interrelationships\nWillingness to take over responsibility\nExperience with project management tools and processes\nTechnical background within semiconductor business\nFluent in English (written and spoken), German skills are a plus\u00a0\nLeave Entitlement e.g: Annual Leave, Medical Leave and etc\nCompany Insurances and etc","88":"What's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as an Information Technology Business Analyst?\nWhich of the following languages are you fluent in?\nHave you worked in a role which requires a sound understanding of the software development lifecycle?\nHow would you rate your English language skills?\nWhich of the following Microsoft Office products are you experienced with?\nHow many years' experience do you have using SQL queries?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","89":"Act as the Level 1 & Level 2 Application Support for applications like ERP\nProvide training to end users.\nInvolve in analyzing problems escalated from Level 1 and finding solutions.\nInvolve in working and communicating with the vendor whenever a problem cannot be resolved locally.\nSupport local application development and support across the product supply and commercial processes\nUnderstanding in the areas of application programming, database, and system design.\nUse Excel to create a required dashboard.\nUpdate website info as and when needed\nDegree in Computer Science, Information Technology, or any relevant discipline.\nAt least 2 years of experience in supporting and delivering IT applications, preferably prior experience working on ERP system\nExperience in Epicor will be an added advantage.\nAdvanced knowledge of Excel is preferred.\nAssists in the enforcement of project deadlines and schedules.\nAd-hoc tasks assigned by superior\nProficiency in English, Bahasa Malaysia, and Mandarin in both written and oral.\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as an Information Technology Business Analyst?\nHow would you rate your English language skills?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","90":"Conduct research on strategic and competitiveness issues, including macroeconomics, microeconomics, sustainable development, societal well-being, planetary health and climate, health and well-being, future of work, poverty and inequality, justice and equity, emerging science, technology and innovation, foresight exercises, etc.\nContribute to consulting projects based on project requirements.\nAssist in designing and implementing research outputs, including policy briefs, working papers, conference presentations, and peer-reviewed journal articles.\nUndertake data collection and ensure ethical practices in collection, storage, sharing, and dissemination.\nPerform data analysis using appropriate methods. Quantitative work may involve modelling and statistical analysis with R, EViews, STATA, or Python, while qualitative work may include focus groups, interviews, and thematic analysis with NVivo or ATLAS.ti.\nDerive and deliver key insights for final project deliverables such as slides and reports.\nConduct workshops and training for the Institute and University.\nBachelor's degree with a focus on empirical analysis (Fresh graduates are welcome to apply).\nPossesses a good understanding of policies, programmes, and theoretical foundations of strategy competitiveness across Sunway IGSC\u2019s three primary work domains: Economy, Society, and Environment.\nProficient in English (fluency in Bahasa Malaysia or an additional language is an added advantage).\nStrong critical thinking and problem-solving skills.\nProficient in the latest data analysis methods, with a solid understanding of data structures and processing techniques.\u00a0\nStrong interest and capability in both quantitative and qualitative research methodologies.\nExceptional written and verbal communication skills, with the ability to engage and collaborate effectively with a diverse range of stakeholders.\nProven track record as a valuable team member, combined with the ability to exercise sound judgement, initiative, and independence in various tasks.\nStrong organizational abilities, including effective prioritization, time management, and planning skills to consistently meet tight deadlines.","91":"Provides on-going training and technical support of our Epicor ERP system and in-house developed MES system, and tooling management system.\nDevelop dashboards and reports to support department and business needs\nPerforms routine maintenance, patch updates, and day-to-day maintenance work on all ERP and integration platforms.\nWork closely with corporate IT in China to ensure all the IT policies, procedures and standards are in consistence in place.\u00a0\nCustomize and configure Epicor ERP modules to align with the organization's specific business needs.\nAssist with implementing, maintaining, supporting, and troubleshooting application systems as assigned.\nFacilitates training of end users and testing of business applications\nPerform other duties as assigned.\nBS in Computer Science\/Information Systems or equivalent technical experience preferred\nExperience with ERP systems is highly desirable, Minimum 2+ years' experience in ERP support & development area required. Prior consulting experience in ERP implementation is a plus\nStrong analytical and problem-solving skills\nGood verbal, presentation and written communication skills\u00a0\nExperience in Systems Analysis & troubleshooting\nBusiness Intelligence tool skills, e.g. QlikView is an added advantage\nWhich of the following types of qualifications do you have?\nWhich of the following statements best describes your right to work in Malaysia?\nHave you worked in a role which requires a sound understanding of business intelligence (BI) best practices?\nWhat's your expected monthly basic salary?\nHave you worked in a role which requires Qlikview development experience?\nHow many years' experience do you have as an Application Suport Analyst?\nHow many years' experience do you have in an application support function?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","92":"\n\nDesign, develop, document and implement end-to-end data pipelines and data integration processes, both batch and real-time. This includes data analysis, data profiling, data cleansing, data lineage, data mapping, data transformation, developing ETL \/ ELT jobs and workflows, and deployment of data solutions.\n\n\nMonitor, recommend, develop and implement ways to improve data quality including reliability, efficiency and cleanliness, and to optimize and fine-tune ETL \/ ELT processes.Recommend, execute and deliver best practices in data management and data lifecycle processes, including modular development of ETL \/ ELT processes, coding and configuration standards, error handling and notification standards, auditing standards, and data archival standards.\n\n\nEnsure development adheres to guidelines and governance policies on data and business intelligence platform.\n\n\nCollaborate with IT team members, SMEs, vendors and internal business stakeholders, to understand data needs, gather requirements and implement data solutions to deliver business goals.\n\n\nBAU supports any data issues and change requests, documents all investigations, findings, recommendations and resolutions.\n\n\nSupport daily operation incidents and service requests.\n\n\n\n\nHands-on experience on Azure Data Solution such as Azure Synapse Spark, Synapse DB, Data Factory, Databricks, Azure Lake Storage and Power BI.\n\n\nExperience with various ETL\/ELT frameworks, data warehousing concepts, data management framework and data lifecycle processes.\n\n\nExperienced in handling and processing different types of data (structured, semi-structured and unstructured).\n\n\nUtilized Azure DevOps to implement CI\/CD workflows and deployment of ETL jobs across multiple environments.\n\n\nStrong knowledge in various database technologies (RDBMS, NoSQL and columnar).\n\n\nProficient in ETL programming languages like Python, PySpark and SQL.\n\n\nExperience with Microsoft Fabric is an added advantage.\n\n\nAbility to communicate and present technical information in a clear and unambiguous manner.\n\n\nStrong ability to work independently and cooperate with diverse teams in a multiple stakeholder environment.\n\n\nStrong sense of work ownership, high affinity with any data and a desire for constant improvements.\n\n\nExperience with SAP data sources preferred.\n\n","93":"Take ML models\/algorithms from conception to production, by designing and implementing ML microservices and pipelines in production environment.\u00a0\nDevelop pipelines for continuous operation, feedback and monitoring of ML models leveraging best practices from the CI\/CD vertical within the MLOps domain.\u00a0\u00a0\nThis can include monitoring for data drift, triggering model retraining and setting up rollbacks.\u00a0\nMaintain and continuously optimize live productive ML services with a focus on scalability, availability, and reliability.\u00a0\nStrive for automation and cloud operation readiness.\u00a0\nCollaborate with data scientists and data engineers to deliver ML models in productive services.\u00a0\nStay updated with the latest trends and technologies in AI\/ML, GenAI and MLOps to drive innovation and system enhancements.\u00a0\nBachelor's degree in computer science or equivalent. A minimum of 4 years' experience in software engineering or machine learning engineering is preferred.\u00a0\nStrong programming skills in Python, Java and SQL variants, with knowledge of design patterns, code optimization, and object-oriented design.\u00a0\nProficiency in ML operationalization and orchestration (MLOps) tools, techniques and platforms. This includes scaling delivery of models, managing and governing ML Models, and managing and scaling AI platforms\u00a0\nFamiliar with Kubernetes and Docker, including installation, deployment, configuration and optimization.\u00a0\nGood understanding of ML frameworks such as TensorFlow, Keras, PyTorch.\u00a0\nExperience in web development skills such as HTML, Javascript, CSS is a big plus.\u00a0\nKnowledge of AWS cloud platform would be an advantage.\u00a0\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Machine Learning Engineer?\nWhich of the following programming languages are you experienced in?\nHave you worked in a role which requires experience with machine learning?\nHow many years' experience do you have using SQL queries?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","94":"Min 3 years working experience\nProficient in SQL, Python, and cloud platforms like AWS, Azure, Snowflake, GCP\nFamiliar with BI Tools like Power BI and Tableau\nCompetitive salary and benefits package\nHybrid and supportive working culture\nInnovation Solutions but using cutting-edge technologies","95":"Work with property develop and construction-related datasets in regards to sustainability.\nConduct exploratory data analysis to uncover methods of data extraction, uncover insights and patterns throught data visualisation.\n.Implement prompt engineering and python to extract data from source files\nCreate informative data visualizations using Power BI and Autodesk tools to communicate findings effectively .\nCreate dashboards which are able to effectively monitor project's data.\nWork closely with cross-functional teams to build and communicate usage of the dashboards.\nDocument code, methodologies, and results to allow continuity of work.\nCover sustainability implementation in the organisation assigned.\nCandidates currently pursuing a Bachelor's in Computer Science, or a related field.\nHave basic understanding of prompt engineering and\u00a0 Power BI.\nAbility to process and analyse large volume of data and information.\u00a0\nPossess an excellent command of the English language (written & oral), strong communication, negotiation, and analytical skills.\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","96":"Bachelor or Master or PhD in Science (Biochemistry, Molecular Biology, Biotechnology, Biology, Biomedical Science) or equivalent.\nTypically, >4 years of relevant experience or >1 year of direct experience in NGS and qPCR applications.\nStrong understanding of molecular biology, analytical chemistry and laboratory equipment and procedures.\nRequires in-depth knowledge and experience in related field and ability to work independently.\nRequires having good teamwork with other competency such as instrument hardware\/software engineers.\nRequires basic knowledge in statistical analysis software (e.g., R, Python, SAS, Minitab), experimental design principles, hypothesis testing, and other statistical methods.\nRequires basic knowledge on data analytics and visualization (e.g. Macro, VBA, Power BI, Power Apps). Any relevant or similar data analytics and visualization could be considered.\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","97":"\n\nDesign and develop software applications for data collection, processing, analysis, and visualization.\n\n\nIntegrate various manufacturing and testing equipment with our data systems to automate data capture.\n\n\n\n\nImplement algorithms to process and analyze large datasets to identify trends, anomalies, and efficiency opportunities.\n\n\nDevelop machine learning models to predict machine failures and optimize manufacturing processes.\n\n\n\n\nWork closely with manufacturing engineers to understand their data needs and provide technical solutions.\n\n\nContinuously explore new technologies and methodologies to improve existing systems and processes.\n\n\n\n\nCreate dashboards and reports to visualize key manufacturing metrics and insights.\n\n\nEnsure accurate and timely delivery of data to stakeholders.\n\n\n\n\nEnsure the integrity and reliability of data analytics software.\n\n\nDocument code, processes, and methodologies for knowledge sharing.\n\n\n\n\nCollaborate with IT and operational teams to integrate software solutions into the broader company ecosystem.\n\n\nParticipate in cross-functional teams to support broader organizational goals.\n\n\n\n\nBachelor's\/Master\u2019s degree in Computer Science\/Engineering, data science or related field\n\n\n2-5 years of experience in software development\u00a0\n\n\nExperience in programming language (python, R) and database (SQL) to perform data mining and analysis.\n\n\nKnowledge of statistical techniques in data science (regression, properties of distribution)\n\n\nKnowledge in machine learning techniques (neural network, machine learning)\n\n\nStrong analytic skills and problem-solving skills.\n\n\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","98":"\n\nAnalyze and organize raw data\u00a0\n\n\nBuild data systems and pipelines\n\n\nEvaluate business needs and objectives\n\n\nInterpret trends and patterns\n\n\nConduct complex data analysis and report on results\u00a0\n\n\nPrepare data for prescriptive and predictive modeling\n\n\nBuild algorithms and prototypes\n\n\nCombine raw information from different sources\n\n\nExplore ways to enhance data quality and reliability\n\n\nIdentify opportunities for data acquisition\n\n\nDevelop analytical tools and programs\n\n\nCollaborate with data scientists and architects on several projects\n\n\n\n\nProficiency in Oracle PL\/SQL and MS SQL.\n\n\nExperience with data replication, change data capture, and performance tuning.\n\n\nFamiliarity with data warehousing concepts and ETL processes.\n\n\n(Good to have) Knowledge of Kafka and Debezium.\n\n","99":"","100":"Propose new solutions and evolve existing ones to be used by product features that relies on AI.\nDesign and conduct online and offline evaluations to compare variants of AI-based product features.\nAssist the team in delivering AI projects that help the business to achieve their strategic priorities.\nBreak-down the problems and propose directions to overcome obstacles.\nResearch, build, deploy and maintain integrated AI solutions.\nWork with Strategy, Product, Operation, Commercial and Software Development teams to address a variety of challenging business problems.\nCollaborate with teams from Asia and Pacific partners.\nStrengthen secure coding practises and tooling within team.\nForm clear data addressable problem statements from current business problems.\nGather, validate, and understand data relevant to the problem statement.\nDesign and build data transformation pipelines and machine learning algorithms to solve the business problem.\nWork with product management and other business partners to review and iterate data products to fit emerging market trends.\nActively communicate with others in an effective, timely manner with empathy.\nContribute to the safety, work-life balance, and well-being of other team members.\nHelp creates a safe space for sharing of different opinions\/feedback.\nImprove your abilities through tutoring and set example behaviour.\nActively seek out learning opportunities for self and others through inviting and providing regular feedback.\nContributor to the data science community at SEEK Pass and SEEK (e.g., Open-source projects, Mentoring, Guilds).\nImproves self and others through inviting and providing regular feedback.\nA MSc or PhD qualification in Computer Science, Computational Physics, Mathematics, Statistics, or a related field.\n3 years of experience in Data Science.\nConsistently write effective, testable, readable, and secure code in one of the following programming languages: Python, Go, Scala, C\/C++, or Java\nSound experience using modern data science practices.\nExperience with Data Modeling and Machine Learning algorithms.\nExperience applying continuous integration and continuous deployment (CI\/CD).\nCommercial experience with agile methodologies (e.g., Kanban, Lean, Scrum).\nCommercial experience working in multi-functional technology teams.\nProactively manages professional growth and identifies learning opportunities.\nExperience giving and receiving effective feedback and contributing to others\u2019 learning.\nAbility to perform data exploratory analysis for proof of concepts and to Communicate the results to a diverse audience.\nPractice with:\nComputer Vision processing libraries (e.g., OpenCV, YOLO, Rekognition)\nRelational database such as MySQL or PostgreSQL.\nAmazon Web Services (e.g. EC2, S3, VPC, SQS, SageMaker).\nDistributed processing framework such as Hadoop or Spark.\nContainer package such as Docker.\nDeployment tools, such as Ansible, Terraform and Chef.\nUses data to support decision-making.\nKnowledge in:\nComputer Vision\nDeep Learning\nNatural Language Processing\nOptimisation\nAbility to adapt quickly and manage an environment of rapid change and development.\nComfortable in a start-up environment with ambiguity, minimum viable products, and rapid iteration & learning\nExperience integrating with third-party systems.\nExperience working with encrypted and highly sensitive data.\nSupport of flexible working, including a mix of office and work from home days depending on your role.\nThe opportunity to work from anywhere for up to 4 weeks per financial year\nCasual dress \u2013 every day","101":"Collect, clean, and preprocess data from various sources.\nDevelop, train, and deploy machine learning models to solve business problems.\nUtilize statistical analysis and data mining techniques to derive actionable insights.\nCommunicate findings to stakeholders through data visualization and presentations.\nCollaborate with the full-time data engineer to design and maintain data pipelines.\nEnsure data integrity and quality through robust validation and processing mechanisms.\nImplement data aggregation and enhancement processes to support analytics.\nContribute to the development of AI products.\nContinuously refine and optimize machine learning models for production use.\nMonitor and maintain deployed models to ensure optimal performance.\nCandidate must possess at least Diploma or Bachelor\u2019s or Master\u2019s degree in Data Science, Computer Science, Statistics, or a related field.\nAt least 3 year(s) \nof relevant experience in data science, machine learning, and data engineering.\nProficiency in programming languages such as Python and SQL.\nExperience with machine learning frameworks and libraries (e.g., Scikit-learn, TensorFlow, PyTorch).\nStrong understanding of statistical analysis and data modelling techniques.\nFamiliarity with data visualization tools (e.g., Tableau, Power BI) and data management systems.\nKnowledge of data engineering best practices and tools (e.g., Apache Spark, Hadoop).\nExcellent problem-solving and analytical skills.\nStrong communication skills, both written and verbal, with the ability to convey technical concepts to non-technical stakeholders.\nAbility to work independently and as part of a team in a fast-paced environment.\nStrong communication skills, both written and verbal in English. Fluency in Mandarin is a plus.\nThe Ascent @ Paradigm Mall\nMonday - Friday (Flexible working hours)\n13th month salary\nEPF \/ SOCSO \/ PCB.\nMedical, Dental and Optical benefits.\nFree-flow snacks and drinks in office pantry.\nSmart casual working attire.\nFull Attendance Allowance.\nFree Parking.\nYoung, vibrant and open work culture.\nHow many years' experience do you have as a data scientist?\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nHave you worked in a role which requires experience with machine learning?\nWhich of the following languages are you fluent in?\nHow much notice are you required to give your current employer?\nHow many years' experience do you have as a Data Engineer?","102":"Which of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as an Artificial Intelligence Engineer?\nWhich of the following programming languages are you experienced in?\nHave you worked in a role which requires experience with machine learning?\nHow many years' experience do you have as an Artificial Intelligence Specialist?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","103":"Design and development of data engineering, analytics and integration roadmap, aligned with our long-term business goals.\nPartner with business stakeholders to understand their data needs and translate them into actionable data strategies.\nDesign and implement a scalable data infrastructure, including data warehouses, data lakes, and data pipelines.\nSelect and implement appropriate data governance policies and procedures to ensure data quality, security, and compliance.\nChampion a culture of data literacy across the organization by establishing training programs and promoting best practices.\nStay current with emerging data technologies and trends, recommending solutions that optimize our data utilization.\nGather requirements and specifications during project development lifecycle from\u00a0 technical stakeholder\/users\nGather\u00a0technical stakeholder\/users expectations and limitations\nEvaluate existing systems and programs to recognize areas for improvement and integration.\nDevelop solutions based on the defined schedules and test plans, prepare analyst reports, and ensure adherence to project guidelines and objectives\nIdentify potential issues between systems and\u00a0 technical stakeholder\/users specifications and propose new solutions to work around these limitations.\nExamine technical stakeholder\/users\u2019s existing systems and configurations to ensure projects are uniform with enterprise-level systems.\nResolve issues regarding specifications and requirements\nInterface with technical stakeholder\/users to provide feedback and updates on development projects.\nGather information to prepare reports and presentations to update technical stakeholder\/users on development of projects\u00a0\nDegree in Computer Science, Information Technology, or a related field\nMinimum 3 years of experience as a Data Engineer or in a similar data-focused role\nProficient in data engineering tools and technologies such as SQL, Apache Spark, and cloud-based data platforms (e.g., AWS, Azure)\nStrong understanding of data modelling, ETL processes, and data warehousing principles.(Power BI experience is added advantage).\nExperience in building and maintaining reliable and scalable data pipelines\nExcellent problem-solving and analytical skills, with the ability to turn complex data into actionable insights\nHands-on experience with data security and privacy best practices\nExcellent communication and collaboration skills to work effectively with cross-functional teams\nCompetitive salary and performance-based bonuses\nComprehensive medical and insurance benefits\nOpportunities for career growth and professional development\nCollaborative and inclusive work culture\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Data Engineer?\nWhich of the following data analytics tools are you experienced with?","104":"Rating : Rate an AI generated response based on given criteria, and provide justification.\u00a0\nPrompt writing : Create a prompt following the instruction given.\nResponse writing : Create a model response for a given prompt\nWhich of the following languages are you fluent in?\nHow would you rate your English language skills?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","105":"Design and implement generative and analytical AI projects.\nAnalyze complex data sets to identify patterns, trends, and insights.\nCollaborate with cross-functional teams to integrate AI solutions across various applications.\nConduct research to remain at the forefront of advancements in AI technologies.\nProven expertise in AI development and deployment.\nStrong background in data feature analysis and machine learning algorithms.\nExperience with large datasets, developing models that yield actionable insights.\nProficiency in AI-related programming languages and tools, including Python, TensorFlow, and PyTorch.\nDegree or higher in Computer Science, Data Science, or a related field.\nWhich of the following statements best describes your right to work in Malaysia?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as an Algorithm Engineer?\nHave you worked in a role which requires experience with machine learning?\nWhich of the following languages are you fluent in?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","106":" \nAnalyze and interpret complex data, transforming it into actionable insights that can drive informed decision-making within organization.\u00a0\n \nInvolves in schema and architecture design, developing data pipelines, ensuring data quality, and using effective tools to extract meaningful patterns and trends from large datasets.\u00a0\n\n\n \nClearly communicate technical concepts and data insights to both technical and non-technical audiences, provide valuable information that helps to improve business strategies and outcomes.\n\n\n \nData Analysis: Analyzing large datasets to conduct in-depth data analysis to extract and derive meaningful insights and trends.\u00a0\n \nData Visualization: Creating clear and effective visualizations to communicate insights with business teams.\u00a0\n\n\n \nCreate metadata for datasets to facilitate data discovery and understanding by users.\u00a0\n\n\n \nCollaborate with business teams or management teams to establish business needs by recommending solutions and delivering insights to increase productivity.\u00a0\n\n\n \nCoordinate with cross-functional teams and stakeholders to understand business requirements, design and implement data products, and monitor outcomes to provide additional value to the organization.\u00a0\n\n\n \nDevelop and implement strategies to enhance data reliability and source ability.\u00a0\n\n\n \nA min. of 0-3 years experience (banking & insurance experience is a plus)\u00a0\n\n\n \nKnowledge of relational databases and a good command of SQL\u00a0\n\n\n \nUnderstanding of basic data pipeline design, including data extraction, transformation, and loading processes.\u00a0\n\n\n \nStrong analytical and problem-solving skills.\n\n\n \nProficiency in programming languages:\u202fSAS, Python,\u202fSQL etc.\u00a0\n\n\n \nBig Data Technologies:\u202fHands-on experience with Hadoop,\u202fSpark or similar technologies for large-scale data processing.\u00a0\n\n\n \nData Quality and Testing:\u202fUnderstanding of data quality checks,\u202fmonitoring,\u202fand testing procedures.\u00a0\n\n\n \nBasic knowledge of data visualization tools (e.g. Tableau, Power BI).\u00a0\n\n\n \nUnderstanding of statistical analysis, machine learning concepts, modeling conceptual ideas and database management.\u00a0\n\n","107":"Understand business processes deeply, identify opportunities where data science can add value, and solve problems using advanced statistical analyses or machine learning techniques as necessary, including prescriptive analytics and predictive modelling\nInitiate, design and lead projects to maximise business impact with the right data driven solution across business functions, including pricing and inventory (e.g. price prediction and optimization), operations (e.g. computer vision automation), customer conversion (e.g. recommendation and personalisation engine), etc.\nResponsible for ensuring successful end-to-end delivery and maintenance of machine learning, data science and AI initiatives, including measurement of model performance in action and monitoring for drifts over time\nWork with MLOps engineers in developing machine learning pipelines to streamline and automate the deployment of models. Ensure timely high standard delivery of output and documentation\nDesign and execute experiments iteratively to improve the performance of data science solutions deployed\nPropose framework and drive hypothesis validation, ensuring statistically sound decision making from proper A\/B test setups whenever feasible\nWork with Product & Tech teams across organisations to enhance data collection process as necessary\nInnately curious, highly analytical and enjoy distilling complex business problems into technical requirements and find answers in the data\nAt least 3 years of practical experience in data science, advanced business analytics, machine learning, AI or computer vision\nExperience in the complete modelling lifecycle, from ideation to deployment and continual monitoring and maintenance\nProficient in Python and\/or R. Preferably Python\nComfortable using SQL for data exploration, and analysis. Preferably familiar with Google BigQuery or similar\nResult-oriented and resourceful. You can cut to the core of a problem, identify what needs to be done, and work with the teams to make things happen\nConstructive communication of ideas, issues, and solutions in a team environment\nSelf-starter who is extremely motivated to continue learning and growing, able to pick up new skills quickly\nExperience in MLOps framework, cloud services by AWS\/ GCP, Tensorflow\/ Pytorch will be an advantage.\nExperience in the automotive or e-commerce industry\nExperience working at a tech startup or fast-growing organisation\nExperience in computer vision or AI research\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a data scientist?\nWhich of the following programming languages are you experienced in?\nHow many years' experience do you have using SQL queries?\nHave you worked in a role which requires experience with machine learning?","108":"\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","109":"\n\nExplore and path-find solutions to complex business problems, coordinate concept proving and pilot testing. Works closely with business stakeholder, observations to find patterns and relationships in data.\n\n\nInteracts with users and users leadership to define requirements and plans for breakthrough product\/solutions. In either research environments or specific product environments, utilizes current programming methodologies to translate machine learning models and data processing methods into software.\n\n\nBuilds machine learning workflows and infrastructure necessary to productize AI platforms, self-service AI solutions, or AI models and sustain them in production.\n\n\nResponsible for preparing data for ML models at scale, building appropriate inference interfaces for ML model consumption, enabling ML Ops for continuous delivery and automation of ML pipelines, and\/or building and sustaining AI production platforms.\n\n\nEnable MLOps for scaled\/POR integration, deployment, adoption and support.\n\n\n\n\nCandidate must have at least 5+ years of working experience.\n\n\nHas degree in Computer Science, Mathematics, Machine Learning, Al, Optimization, Operation Research, Statistics or equivalent.\n\n\nIndependent and self-driven individuals with a must have deep knowledge in machine learning algorithms and applying to solve problems in various disciplines. Deep expertise in Python, Tensorflow, Large Language Model, CNVRG, ELK, Kubernetes, KubeFlow, Scripting, SQL queries, and related software.\n\n\nAbility to build data ingestion libraries from heterogeneous data sources including Postgres SQL, MS SQL, Excel, Oracle, Json, Teradata, etc.\n\n\nExperience in AI or software solution architecture design, and development will be an added advantage.\n\n\nSkilled in programming, testing, debugging, documentation and\/or deployment of the solution\/products.\n\n\nHave strong understanding of manufacturing business segment stakeholders and possess strong written and communication skills. Project\/program management experience will have an added advantage.\n\n\nCuriosity and endless desire to learn, along with passion for solving intricate business problems using data science\n\n\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","110":"Work closely with our IT team to identify issues and use data to propose solutions for effective decision-making.\nAssess the effectiveness of data sources and data-gathering techniques and improve data collection methods.\nBuild algorithms and design experiments to merge, manage, interrogate and extract data to supply quality data for machine learning.\nUse machine learning tools and statistical techniques to produce solutions to problems.\nTest data mining models to select the most appropriate ones for use on a project.\nMaintain clear and coherent communication, both verbal and written, to understand data needs and report results.\nHorizon scan to stay up to date with the latest technology, techniques and methods.\nConduct research from which you'll develop prototypes and proof of concepts.\nExploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real world\nSupervising the data acquisition process. Establish new systems and processes and look for opportunities to improve the flow of data\nLook for opportunities to use insights\/datasets\/code\/models across other functions to provide strategic solutions\nStay curious and enthusiastic about using algorithms to solve problems and enthuse others to see the benefit of your work.\nStrong interest in latest Machine Learning Research\nExperience with Azure, AWS or Google Cloud\nExperience with computer vision, object detection and\/or multi-object tracking\nStrong analytical and problem-solving skills.\nExcellent interpersonal and communication skills.\nBachelor\u2019s degree in Data Science \/ Computer science \/ Information Technology or a related subject and\/or equivalent formal training or work experience.\nCareer growth & learning opportunities\nOutpatient, dental & optical, medical insurance\nSpecial leaves\nLong established company with headquarters in Shanghai & Hong Kong\nWhich of the following types of qualifications do you have?\nHave you worked in a role which requires experience with machine learning?","111":"Problem-solving and analytical understanding for statistics and data.\u00a0\nTechnical skills and competency in using data analytics software like Excel, Salesforce, others.\u00a0\nContinuously strive for ways to improve operational efficiency, develop reports, and maintain spreadsheets\/data metrics to monitor, track, and evaluate performance.\nSupport and provide technical assistance for inquiries and issues.\nOppo conversion knowledge will be added advantage.\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","112":"Analyze customer data to identify trends, patterns, and opportunities.\u00a0\nDevelop insights to guide customer acquisition, retention, and engagement strategies.\u00a0\nAlign data analysis with departmental objectives to support business growth.\u00a0\nDesign and develop analytical modules that streamline data processing and reporting for sales and campaign performances.\u00a0\nCollaborate with Tech team to implement and maintain these modules.\u00a0\nEnsure scalability and adaptability of modules for various business applications.\u00a0\u00a0\nExtract data from various sources including database, APIs and flat files.\u00a0\nCreate compelling data visualizations that communicate key insights effectively.\u00a0\nUtilize platforms such as Qlik Sense , Tableau, Power BI, Excel or similar tools to develop dashboards and reports.\u00a0\nContinuously refine visualization techniques for clarity and impact to all business units.\u00a0\nGenerate reports and presentations that summarizes key findings and suggests recommendations.\u00a0\nSupport strategic planning with data-driven insights and forecasts.\u00a0\nMonitor and report on KPIs to assess the effectiveness of customer strategies.\u00a0\nEnsure the integrity and security of data by following company\u2019s policies with regular check and audits.\u00a0\nMaintain comprehensive records and documentation on data sources, data processes, findings, assumptions.\u00a0\u00a0\nWork closely with cross-functional teams, including Operations, Digital Asset, Technology, and Product.\u00a0\nCommunicate complex data findings clearly to both technical and non-technical stakeholders.\u00a0\nProvide training and support on data analysis tools and best practices.\u00a0\nCollaborate with regional teams to understand customer needs, market trends, and the rollout of new technologies and services, providing strategic and tactical product recommendations with active discussions.\u00a0\nMaintain a close working relationship with HOD and team members plus other business unit stakeholders on all matters pertaining to, including but not limited to execution and reporting of the company\u2019s customer acquisition campaign.\u00a0\nExecutes departmental tasks and achieve targets set on departmental key result areas (KRAs) and key performance indexes (KPIs) with productive participation and support.\u00a0\nStay updated with the latest trends in data analysis, visualization, and customer strategy.\u00a0\nSeek continuous improvement in processes, tools, and methodologies.\u00a0\nParticipate in professional development to enhance skills and knowledge.\u00a0\nFollow the Company's code of conduct, policies, procedures, and lawful directions related to employment and duties.\u00a0\nPerform any additional tasks as directed by management from time to time.\u00a0\n3+ years of experience in data analysis, preferably in a customer-centric or strategic role.\u00a0\nStrong experience with data visualization tools (e.g., Qlik Sense, Tableau, Power BI).\u00a0\nProficiency in data analytic tools such as SQL, Python, R, or similar.\u00a0\nKnowledge of statistical analysis and predictive modelling techniques.\u00a0\nFamiliarity with CRM systems and customer data is an advantage.\u00a0","113":"Analyse Data:\n Extract insights from large datasets to inform business strategies\nDevelop Models:\n Create predictive models for risk assessments, customer behaviour, fraud detection, etc\nEnhance Personalization:\n Build algorithms to tailor insurance products to individual needs\nCollaboration: \nWork directly with cross- functional teams (Business and IT)\nAdvanced Python and SQL skills. \u00a0Python packages such as NumPy, pandas, matplotlib, scikit-learn, etc.\nCloud environment in either AWS or GCP\nSolid experience in GenAI and\/or MLOps is an advantage\n4+ years in data science\/ machine engineering working experience\nEducation in mathematics, statistics, data science or equivalent\nProven experience in handling end to end data science projects\nCollaborative and think outside of the box mindset\nLanguage in written and spoken English\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a data scientist?\nWhich of the following programming languages are you experienced in?\nDo you have experience with multi-variate and A\/B testing methodologies?","114":"Which of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","115":"End-to-end delivery of data analytics projects including project framework, analysis technique and implementation of data science models\nAnalyse and interpret large volume and complex datasets to extract insights, trends, and patterns, helping organizations make data-driven decisions.\nIntegrate external factor and global context into analytical models to enhance predictive accuracy and provide a broader context for decision making.\nApply various data science technologies: statistical analysis, machine learning and pattern recognition with subject-specific modelling to address opportunities in business performance and achieve supply chain efficiencies.\nDesign experiments and statistical tests to validate hypotheses.\nPresent findings to non-technical stakeholders in a clear and understandable manner\nA bachelor's degree in a quantitative field such as Data Science, Statistics, Mathematics, Physics, or related fields, with a \nminimum of 5 working years of experience.\nStrong background in statistics and probability theory is essential for analyzing and interpreting complex data.\nProficiency in programming languages commonly used in data science, such as Python or R. Familiarity with tools like SQL for database querying is also valuable.\nUnderstanding and practical experience with machine learning techniques and algorithms. This includes supervised and unsupervised learning, regression, classification, clustering, and more.\nAbility to create meaningful visualizations to communicate complex findings effectively. Familiarity with tools like Matplotlib, Seaborn, or Tableau can be beneficial.\nStrong communication skills to explain complex technical findings to non-technical stakeholders and decision-makers.\nHaving supply chain knowledge will be an added advantage.\nHow many years' experience do you have as a data scientist?\nDo you have a Bachelor Degree?","116":"Model Development:\n Design and implement AI models, such as LSTM, transformer-based architectures (LLaMA, GPT, etc.), or other relevant machine learning algorithms, tailored to trading systems and market analysis.\nAlgorithm Development:\n Implement and optimize algorithms that improve the speed and accuracy of trade decisions, focusing on high-performance, real-time models that can be deployed in production environments.\nData Analysis:\n Preprocess and analyze financial data, including historical market data, technical indicators, and other data sources to develop features and training datasets for AI models.\nTrade Decision Enhancement:\n Build models that assist in predicting market trends, identifying trading opportunities, and optimizing trade execution strategies, focusing on improving decision accuracy.\nBacktesting and Evaluation:\n Conduct backtesting of AI models using historical data, and continuously refine models based on performance metrics. Use tools like precision, recall, and confusion matrices to ensure model robustness.\nCollaboration with Trading Team:\n Work closely with traders and engineers to understand trading strategies and ensure seamless integration of AI solutions with the trading algorithms and systems.\nOptimization:\n Fine-tune and optimize models to ensure they are computationally efficient, accurate, and scalable to handle real-time data and decision-making processes.\nContinuous Learning:\n Stay updated with advancements in AI, machine learning, and financial technology, and incorporate cutting-edge techniques into the model development process.\nDocumentation:\n Maintain comprehensive documentation for AI models, data pipelines, and integration processes, ensuring clarity and reproducibility.\nEducational Background:\n Bachelor\u2019s Degree in Computer Science, Data Science, AI\/ML Engineering, or a related field (or equivalent work experience).\nExperience:\n Minimum of 2 years of experience working in AI\/ML model development, with hands-on experience in LSTM, transformers, or other deep learning architectures.\nTechnical Skills:\nProficiency in Python and machine learning frameworks such as TensorFlow, PyTorch, or Keras.\nExperience with \ntime-series analysis\n and \nsequence modeling\n (e.g., LSTM, GRU).\nFamiliarity with transformer-based models (e.g., \nLLaMA, GPT\n), and their applications in trade decision analysis.\nStrong knowledge of \ndata preprocessing\n, feature engineering, and model evaluation techniques.\nExperience with \nfinancial market data\n and \ntrading algorithms\n is a plus.\nFamiliarity with cloud platforms (AWS, GCP, etc.) for training and deploying AI models.\nProficiency in working with large datasets and database technologies (SQL, NoSQL).\nProficiency in Python and machine learning frameworks such as TensorFlow, PyTorch, or Keras.\nExperience with \ntime-series analysis\n and \nsequence modeling\n (e.g., LSTM, GRU).\nFamiliarity with transformer-based models (e.g., \nLLaMA, GPT\n), and their applications in trade decision analysis.\nStrong knowledge of \ndata preprocessing\n, feature engineering, and model evaluation techniques.\nExperience with \nfinancial market data\n and \ntrading algorithms\n is a plus.\nFamiliarity with cloud platforms (AWS, GCP, etc.) for training and deploying AI models.\nProficiency in working with large datasets and database technologies (SQL, NoSQL).\nAdditional Skills:\nUnderstanding of financial markets, technical analysis, and trading strategies.\nStrong mathematical and statistical foundation in probability, time-series modeling, and optimization techniques.\nExperience with tools for data visualization and performance tracking (e.g., Matplotlib, Plotly, MLFlow).\nKnowledge of \nmachine learning lifecycle management\n and MLOps practices.\nUnderstanding of financial markets, technical analysis, and trading strategies.\nStrong mathematical and statistical foundation in probability, time-series modeling, and optimization techniques.\nExperience with tools for data visualization and performance tracking (e.g., Matplotlib, Plotly, MLFlow).\nKnowledge of \nmachine learning lifecycle management\n and MLOps practices.\nStrong analytical and problem-solving skills, with the ability to work independently and deliver results.\nAbility to collaborate effectively with cross-functional teams, including traders, developers, and data engineers.\nA passion for learning new AI techniques and applying them to real-world financial problems.\nGood communication skills, with the ability to explain complex technical concepts to non-technical stakeholders.\nAttention to detail and a proactive attitude toward model refinement and improvement.\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as an Artificial Intelligence Engineer?\nWhich of the following programming languages are you experienced in?\nHave you worked in a role which requires experience with machine learning?\nHow many years' experience do you have using SQL queries?\nWhich of the following Relational Database Management Systems (RDBMS) are you experienced with?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","117":"Forming clear data addressable problem statements from current business problems\nResearch, build, deploy and maintain RecommendationsAI solutions integrated with recruitment products aiming to properly connect candidates to recruiters\nImprove the chances of matching (job placements) to leverage our AI platform to the next level\nCollaborate with Strategy, Product, Data Science and Software Development teams to address a variety of challenging business problems\nLead the formulation, development, deployment, and testing of new solutions\nExplore new methodologies and technologies to address R&D problems in a truly collaborative way\nA Bachelor, MSc or PhD qualification in Computer Science, Computational Physics, Mathematics, Statistics or a related field\nProfessional experience in one of the following programming languages:\nLarge scale development using Python, Go, C\/C++, or Java\nAbility to perform data exploratory analysis for proof of concepts and to communicate the results to a diverse audience\nGood communication and interpersonal skills\nLarge scale development using Python, Go, C\/C++, or Java\nStrong background in:\nAlgorithms and data structures\nInformation Retrieval\nMachine Learning\nPractice with\nSearch engine such as Elasticsearch or SOLR;\nRelational database such as MySQL or PostgreSQL;\nAmazon Web Services (e.g. EC2, ELB, S3, VPC, Route 53);\nDistributed processing framework such as Hadoop or Spark;\nContainer package such as Docker;\nKnowledge in:\nRecommender Systems\nData Mining\nNatural Language Processing\nOptimization\nDeep Learning\nAbility to adapt quickly and manage an environment of rapid change and development\nAlgorithms and data structures\nInformation Retrieval\nMachine Learning\nSearch engine such as Elasticsearch or SOLR;\nRelational database such as MySQL or PostgreSQL;\nAmazon Web Services (e.g. EC2, ELB, S3, VPC, Route 53);\nDistributed processing framework such as Hadoop or Spark;\nContainer package such as Docker;\nRecommender Systems\nData Mining\nNatural Language Processing\nOptimization\nDeep Learning\nAbility to adapt quickly and manage an environment of rapid change and development\nMature and collaborative work culture and environment\nHybrid work mode\nExtended employee benefits","118":"Work with stakeholders to define the scope, requirements, processes and procedures to ensure the success of artificial intelligence and machine learning (AI\/ML) projects.\nCreate and deliver data-driven solutions that add business value using statistical models, machine learning algorithms, data mining and visualization techniques.\nCollect, organize and analyze large complex, structured\/unstructured, diverse big data.\nDevelop scripts to automate processes to cleanse, integrate and evaluate large datasets from disparate data sources.\nIdentify data trends, patterns and insights through statistical analysis and machine learning techniques.\nDesign, develop and implement statistical models and machine learning algorithms.\nDevelop predictive models to solve complex business problems.\nContinuously evaluate and improve the performance of existing models and algorithms.\nMaster or Bachelor Degree in Computer Science, Data Science, Mathematics, Statistics\/Operations Research or related qualification.\nProven work experience as a Data Scientist\/Data Analyst or similar role.\nProficient in Python programming and SQL languages.\nProficient in open-source software libraries for machine learning and artificial intelligence such as TensorFlow and Keras, open-source message broker software such as RabbitMQ, distributed event store and stream-processing platform such as Apache Kafka.\nProficient in Apache HBase open-source non-relational distributed database and Apache Hadoop Distributed File System (HDFS).\nExperience with data visualization tools such as Power BI, QlikView or Splunk.\nStay up-to-date with the latest advancements in data science, artificial intelligence and machine learning.\nDetailed, strong technical and analytical skills.\nGood communication, decision making and presentation skills.","119":"Which of the following languages are you fluent in?\nHow would you rate your English language skills?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","120":"Responsible for requirement study, testing, deployment, and support\/enhancement of in-house systems, mobile applications, and reporting.\nWork closely with the helpdesk functional team, peers, and business users on system requirement studies and issue clarification.\nAssist in solution architecture, application design, and database design based on task requirements.\nManage developers in designing and developing architecture for data warehousing components (e.g., tool integration strategy, data staging, movement and aggregation, information and analytics delivery, and data quality strategy).\nDesign and implement standard reporting and dashboards using SSIS, SSAS, SSRS, Microsoft SQL stored procedures, and Microsoft Excel Pivot.\nPerform technical specification writing and documentation.\nExhibit strong collaboration and communication skills, a positive attitude, and take responsibility for assigned tasks.\nWork independently, be detail-oriented, and demonstrate strong problem-solving skills.\nWork on bug fixes and fine-tune application performance.\nBe a fast learner and capable of working in a fast-paced environment with tight deadlines.\nBachelor's degree in a related field.\nA minimum of 5 years of experience in web and software development.\nExperience in the retail industry is an added advantage.\nDemonstrated knowledge of web\/mobile languages\/technologies such as JavaScript, ASP.NET, HTML, CSS, PHP, AngularJS, Node.js, MVC, jQuery, AJAX, Bootstrap, etc.\nDemonstrated knowledge of backend languages\/technologies such as C#, MS SQL Server, MySQL, web services, VBA, etc.\nDemonstrated knowledge of software components and third-party programs, such as API (JSON, REST, XML).\nDemonstrated knowledge of source control management, such as GitHub.\nExperience with Windows Server and Linux.\nOpportunity to work with a leading cosmetics retailer, gaining experience in a fast-paced, dynamic industry.\nExposure to a diverse range of international and local beauty brands.\nAccess to professional development within a large, well-established company.\nBe part of a collaborative, innovative team focused on delivering exceptional customer experiences.\nBenefit from growth opportunities in both e-commerce and physical retail sectors.","121":"AI Strategy & Leadership:\n Take full ownership of the AI roadmap for trade decision analysis, defining the model architecture, training, and evaluation methodologies. Lead the team\u2019s AI efforts and independently drive technical direction.\nAdvanced Model Development:\n Design and build state-of-the-art machine learning models, including \nLSTM\n, \ntransformer-based models\n (e.g., \nLLaMA\n, \nGPT\n), or other relevant architectures to analyze time-series data and predict market movements.\nAlgorithm Development:\n Implement and optimize algorithms that improve the speed and accuracy of trade decisions, focusing on high-performance, real-time models that can be deployed in production environments.\nEnd-to-End Model Lifecycle:\n Own the end-to-end development cycle for AI models, including \ndata preprocessing\n, model training, validation, testing, and deployment. Ensure models are production-ready and robust under varying market conditions.\nBacktesting & Performance Evaluation:\n Perform extensive backtesting of AI models using historical market data, develop benchmarks, and continually refine models for improved performance. Lead model tuning for accuracy, speed, and reliability.\nIntegration with Trading Systems:\n Collaborate closely with trading and engineering teams to ensure that AI models seamlessly integrate into the trading platform. Provide technical expertise to align models with existing trade execution frameworks.\nScalability & Optimization:\n Build scalable AI solutions capable of handling high-frequency data streams and vast amounts of market data. Ensure the efficiency of AI models in real-time systems with minimal latency.\nAI Infrastructure & MLOps:\n Establish and maintain AI pipelines, automation, and infrastructure for model training, testing, deployment, and monitoring. Lead efforts in \nMLOps\n to optimize model lifecycles.\nResearch & Innovation:\n Keep up with the latest research in AI, machine learning, and financial modeling. Innovate by applying cutting-edge techniques, including transfer learning, reinforcement learning, or other novel AI approaches.\nTechnical Leadership:\n Provide mentorship and technical guidance to junior and intermediate AI engineers. Lead code reviews, contribute to defining coding standards, and ensure best practices across the AI team.\nDocumentation & Standards:\n Create comprehensive technical documentation and ensure that AI systems are built following industry standards for maintainability and scalability.\nEducational Background:\n Master\u2019s or Ph.D. in Computer Science, Data Science, AI\/ML Engineering, or related fields, or equivalent work experience.\nExperience:\n Minimum of 5 years of hands-on experience in AI\/ML development, with a strong track record of deploying models in production. Proven experience in time-series forecasting and financial market applications is a plus.\nTechnical Skills:\nExpertise in \nmachine learning frameworks\n like \nTensorFlow\n, \nPyTorch\n, or \nKeras\n.\nStrong proficiency in \nLSTM\n, \nGRU\n, and \ntransformer-based models\n (e.g., \nLLaMA\n, \nBERT\n, \nGPT\n).\nSolid experience in \ntime-series analysis\n, feature engineering, and building prediction models for financial data.\nDeep understanding of \ntrading systems\n, market microstructure, and execution algorithms.\nExperience with \ncloud platforms\n (e.g., AWS, GCP) and distributed computing to train large-scale models.\nProficiency in building \nreal-time machine learning pipelines\n, handling streaming data, and ensuring low-latency responses.\nExperience in \nbacktesting\n, hyperparameter tuning, and model optimization for high accuracy.\nProficiency in \nMLOps\n tools for model lifecycle management (e.g., MLFlow, Kubeflow).\nStrong skills in \nSQL\n, \nNoSQL\n, and managing large datasets.\nExpertise in \nmachine learning frameworks\n like \nTensorFlow\n, \nPyTorch\n, or \nKeras\n.\nStrong proficiency in \nLSTM\n, \nGRU\n, and \ntransformer-based models\n (e.g., \nLLaMA\n, \nBERT\n, \nGPT\n).\nSolid experience in \ntime-series analysis\n, feature engineering, and building prediction models for financial data.\nDeep understanding of \ntrading systems\n, market microstructure, and execution algorithms.\nExperience with \ncloud platforms\n (e.g., AWS, GCP) and distributed computing to train large-scale models.\nProficiency in building \nreal-time machine learning pipelines\n, handling streaming data, and ensuring low-latency responses.\nExperience in \nbacktesting\n, hyperparameter tuning, and model optimization for high accuracy.\nProficiency in \nMLOps\n tools for model lifecycle management (e.g., MLFlow, Kubeflow).\nStrong skills in \nSQL\n, \nNoSQL\n, and managing large datasets.\nAdditional Skills:\nExpertise in \nfinancial markets\n, \nalgorithmic trading\n, and developing AI solutions for real-time decision-making.\nFamiliarity with \nreinforcement learning\n, \ndeep learning\n, and \ntransfer learning\n for financial applications.\nExperience with \ndistributed computing frameworks\n (e.g., Spark, Dask) to process large-scale datasets.\nKnowledge of \ndata visualization\n tools and methods for presenting insights and model performance.\nExpertise in \nfinancial markets\n, \nalgorithmic trading\n, and developing AI solutions for real-time decision-making.\nFamiliarity with \nreinforcement learning\n, \ndeep learning\n, and \ntransfer learning\n for financial applications.\nExperience with \ndistributed computing frameworks\n (e.g., Spark, Dask) to process large-scale datasets.\nKnowledge of \ndata visualization\n tools and methods for presenting insights and model performance.\nStrong leadership and \ntechnical mentorship\n skills, with a proven ability to drive projects from ideation to deployment.\nExcellent problem-solving skills, with a track record of resolving complex AI and data science challenges.\nAbility to work independently, make informed technical decisions, and take ownership of large-scale AI projects.\nStrong communication skills, with the ability to explain complex AI concepts to non-technical stakeholders.\nA passion for continuously improving AI systems and staying ahead of the curve in new AI\/ML techniques.\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as an Artificial Intelligence Engineer?\nHow many years' experience do you have using SQL queries?\nHave you worked in a role which requires experience with machine learning?\nWhich of the following programming languages are you experienced in?\nWhich of the following Relational Database Management Systems (RDBMS) are you experienced with?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","122":"\n\nLead the business analysis function, contributing to the development of data-driven strategies. \n\n\nImplement and share innovative ideas for data utilization and analysis. \n\n\nTake a proactive approach in identifying opportunities for data-driven improvements. \n\n\nShowcase advanced proficiency in Excel or Google sheet formulas for detailed business analysis and modeling. \n\n\nUtilize Excel for in-depth insights into complex datasets. \n\n\nDevelop and implement interactive dashboards for effective data communication. \n\n\nApply experience and knowledge in analyzing call center, customer services, sales, or telemarketing data. \n\n\nProvide actionable insights to improve performance and efficiency. \n\n\nImplement and maintain data governance practices to ensure data accuracy and integrity. \n\n\nCollaborate with cross-functional teams to streamline data processes. \n\n\nCollaborate effectively with teams to understand data needs and requirements. \n\n\nCommunicate complex data insights in a clear and accessible manner. \n\n\nStay updated on industry trends, emerging technologies, and best practices in business analysis. \n\n\nProactively integrate new tools and methodologies for improved business analysis.\n\n\n\n\nBachelor's degree in Data Science, Data Analysis, Business Analysis Statistics, Computer Science, Business Administration or a related field (fresh graduates are welcomed). \n\n\nGood proficiency in \nExcel Analysis\n or other \nData analysis tools\n. \n\n\nAbility to speak in Mandarin is highly preferred to deal with Chinese stakeholders. \n\n\nExperience in call center, customer services, sales, or telemarketing analysis is highly preferred. \n\n\nExperience with programming languages and \nBI Tools\n such as Python, R, Power BI, Tableau is added advantage.\n\n\nWhat is your expected monthly basic salary (RM) ?\nWhat is the notice period required by your current employer? (Months)\nList down the data analytics tools you are experienced with. \n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","123":"\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","124":"Responsible for requirement study, testing, deployment, and support\/enhancement of the in-house systems, mobile applications, and reporting.\nWork closely with the helpdesk functional team, peers, and business users on system requirement studies and issue clarification.\nAssist in solution architecture, application design, and database design based on task requirements.\nManage developers in designing and developing the architecture for data warehousing components (e.g., tool integration strategy, data staging, movement and aggregation, information and analytics delivery, and data quality strategy).\nDesign and implement standard reporting and dashboards using SSIS, SSAS, SSRS, Microsoft SQL stored procedures, and Microsoft Excel Pivot.\nPerform technical specification writing and documentation.\nExhibit good collaboration and communication skills, a positive attitude, and responsibility for assigned tasks.\nWork independently, be detail-oriented, and possess strong problem-solving skills.\nWork on bug fixing and fine-tuning application performance.\nBe a fast learner and able to work in a fast-paced environment with tight deadlines.\nBachelor\u2019s degree in a related field.\nMinimum of 5 years of experience in web and software development.\nWorking experience in the retail industry is an added advantage.\nDemonstrated knowledge of web\/mobile languages\/technologies, such as JavaScript, ASP.NET, HTML, CSS, PHP, Angular JS, Node.js, MVC, jQuery, AJAX, Bootstrap, etc.\nDemonstrated knowledge of backend languages\/technologies, such as C#, MS SQL Server, MySQL, web services, VBA, etc.\nDemonstrated knowledge of software components and third-party programs such as API (JSON, REST, XML).\nDemonstrated knowledge of source control management such as GitHub.\nExperience with Windows Server and Linux.\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a systems analyst?\nWhich of the following programming languages are you experienced in?","125":"\n\nDesign and implement generative and analytical AI projects.\n\n\nAnalyze complex data sets to identify patterns, trends, and insights.\n\n\nCollaborate with cross-functional teams to integrate AI solutions across various applications.\n\n\nConduct research to remain at the forefront of advancements in AI technologies.\n\n\n\n\nProven expertise in AI development and deployment.\n\n\nStrong background in data feature analysis and machine learning algorithms.\n\n\nExperience with large datasets, developing models that yield actionable insights.\n\n\nProficiency in AI-related programming languages and tools, including Python, TensorFlow, and PyTorch.\n\n\nMaster\u2019s degree or higher in Computer Science, Data Science, or a related field.\nRelevant experience in Computer Science, Data Science, or a similar discipline.\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","126":"Which of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following languages are you fluent in?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","127":"What's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Data Engineer?\nHow many years' experience do you have using SQL queries?\nWhich of the following programming languages are you experienced in?\nWhich of the following data analytics tools are you experienced with?\nHow many years' experience do you have in a DevOps role?","128":"Implement, troubleshoot, and test data products and services using standard techniques and tools.\nHelp building data solutions which are scalable, resilient, and future proof.\nUnderstand typical problems in databases, data processes, data products and services. You understand and can apply typical solutions to those problems.\nImplement, troubleshoot, and test pipelines, Web APIs, services, or scripts.\nWork in an Agile and cross-functional team\nDegree in Computer Science, Information Technology or a related field\n1-2 years of experience in data engineering or a similar role\nAgile methodologies. You know about agile methodologies and the ways you can apply the principles in practice. You can take an open-minded approach; you know why iteration is important. You know how agile processes can be used to validate ideas with users.\nData development process. You can design, build and test data products based on feeds from multiple systems using a range of different data exchange, storage and access technologies. You can create testable, repeatable and reusable products.\nData technology. You can apply data models using database technology. You understand and apply appropriate data design principles to achieve performant and secure databases. You are aware of general trends in data technology.\nTechnical understanding (data engineering). You understand core technical concepts like data normalisation, modelling, performance of data intensive solutions. You understand basic software development concepts.\nGood command of written and spoken English and Chinese; Cantonese is an advantage\nCompetitive salary and performance-based bonuses\nComprehensive health and wellness benefits\nOpportunities for professional development and career growth\nFlexible work arrangements and a dynamic, collaborative work culture\nTeam-building activities and social events to foster connections\nWhich of the following statements best describes your right to work in Malaysia?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Data Engineer?\nHow many years' experience do you have working in an agile environment?","129":"Create and maintain optimal data architecture\u00a0\nAssemble large, complex data sets that meet functional and non-functional business requirements\u00a0\nIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\u00a0\nBuild the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources\u00a0\nWork with stakeholders including the users, cross functional teams to assist with data-related technical issues and support their data infrastructure needs.\u00a0\nStandard process to keep data secure with right access and authorization\u00a0\nFocus on automated testing and robust monitoring\nExcellent problem solving and interpersonal communication skills\u00a0\nStrong desire to learn and share knowledge with others.\u00a0\nBe inquisitive, innovative, and a team player with a strong focus on quality workmanship.\u00a0\nTroubleshooting skills and root cause analysis for performance issues\u00a0\nAbility to lean, adopt and implement new skills to drive innovation and excellence.\u00a0\nAbility to work with cross functional teams in dynamic environment\nA bachelor's with 5+ years of experience in CS\/CE or a related field\u00a0\nExperience building and optimizing big data pipelines\u00a0\nExperience with skills pf handling unstructured data\u00a0\nExperience with data transformations, structures, metadata, workload management\u00a0\nExperience with big data tools: Spark, Kafka, NIFI. ADF etc.\u00a0\nExperience with at least programming languages: Python, C#, .NET\u00a0\nExperience with relational SQL and NOSQL DBs\u00a0\nExperience in leveraging open-source packages\u00a0\nExperience in cloud native skills such as Docker, Kubernetes, Rancher etc. Good to have skills:\u00a0\nExperience with semiconductor manufacturing\u00a0\nExperience of data engineering on cloud\u00a0\nExperience in developing AI\/ML Solutions \u00a0\nWhich of the following statements best describes your right to work in Malaysia?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Big Data Engineer?\nWhich of the following programming languages are you experienced in?\nHow many years' experience do you have using SQL queries?\nHow would you rate your English language skills?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","130":"Email Annotation\n: Annotate emails for AI filters machine learning.\nEmail Examination\n: Review various email elements, including appearance, headers, links, and attachments. Analyze online resources related to internet domain and IP address reputations to determine email categories.\nMalicious URL Identification\n: Detect and block malicious URLs and phishing attempts to protect recipients and maintain email security.\nData Labeling\n: Label a diverse pool of data, including emails, messages, and statements, for use in training and improving AI and machine learning models.\nProcess Adherence\n: Ensure all operational sections adhere to established processes and procedures to maintain consistency and quality.\nKPI Management\n: Monitor and ensure that all key performance indicators (KPIs) are met. Propose and implement initiatives or improvement plans as needed to address any shortfalls.\nProject Support\n: Assist the Project Manager with day-to-day service operations and departmental administration as required.\nCandidate must possess at least a Diploma or Advanced Diploma\nPreferably 1 year(s) & above of working experience in the related field\nAbility to work 24\/7 rotational shift, including the ability to work nights, weekends and public holidays\nExperience in IT, security or systems support, or network administrator positions will be added advantage\nFluent English in speaking and writing\nGood communication and problem-solving skills\nResponsible, meticulous and a team player\nSelf-motivated, proactive, well organized\nFresh graduates are welcome to apply\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nAre you available for shift work?\nHow many years' experience do you have in the IT industry?\nWhich of the following types of qualifications do you have?","131":"Gather and analyze customer data to map and plan the customer journey, identifying trends and patterns to optimize the CRM strategy.\nConduct A\/B testing on promotional and marketing campaigns to evaluate their effectiveness and make recommendations for improvements.\nCollaborate with stakeholders to help them make data-driven decisions that enhance customer engagement and retention strategies.\nPrepare comprehensive reports on CRM and loyalty campaign performance, providing actionable insights and recommendations for continuous improvement.\nProvide in-depth analysis of customer behavior to identify growth opportunities and improve customer journey experiences.\nFluent in written and spoken \nEnglish\n and \nMandarin\n.\nBachelor's degree in Data Science, Marketing, Business Analytics, International Business, Public Relations, or Media Studies.\u00a0\nProven experience as a Data Analyst, preferably within Sales, Customer Behavior, Business Development or Marketing.\nProficiency in data analysis tools such as \nExcel\n, \nSQL\n, and data visualization tools (e.g., Tableau, Power BI).\nStrong knowledge of A\/B testing methodologies and experience in campaign optimization.\nExcellent analytical and problem-solving skills, with the ability to present complex data in a clear and concise manner.\nStrong communication skills to effectively collaborate with stakeholders and present insights.\nHybrid Work Mode: \nWork from Home every Monday and Friday.\nAccessible Location:\n Office is within walking distance from the MRT.\nMonthly Performance Bonus: \nUp to 4 digits monetary reward, get paid for your hard work.\u00a0\nProfessional Development:\n Sponsorship for professional training and workshops.\nAnnual Leave Encashment:\n Get paid for unused leave.\nWork Assets Provided:\n All necessary work tools and equipment are supplied.\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a data analyst?\nWhich of the following data analytics tools are you experienced with?\nHow many years' experience do you have using SQL queries?\nWhich of the following languages are you fluent in?","132":"Conduct in-depth research on industry trends, competitors, and customer needs.\nIdentify operational and market opportunities and recommend actions.\nCollaborate with cross-functional teams to develop strategic growth plans.\nLead meetings and presentations to share insights and ideas.\nPrepare data reports for management\/stakeholders\/client company.\nProvide data-driven recommendations to optimize business strategies, customer acquisition, and retention.\nFocus on achieving revenue targets and business milestones.\nBachelor\u2019s degree \/ Diploma\n in Risk Management, Mathematics, Statistics, Actuarial Science, Business, Computational Science\/Information Technology, Data Science, or equivalent.\nMinimum of \n3 to 5 years\n of relevant work experience\nExperience in \nMarketing, Finance, Economics, Business\n, or related fields \nis a plus\n.\nFluency in \nEnglish \nand\n Mandarin\n is compulsory, as dealing with Mandarin-speaking clients is required.\nMust have a strong knowledge of SQL\n and relevant work experience, particularly in using SQL to initiate and manage projects.\nProficient in\n Excel VBA, Power Query, Power BI \nis a plus.\nAble to lead, influence, and motivate teams to achieve high performance.\nComfortable working in a fast-paced environment with high workloads and deadline-driven projects.\nWilling to travel overseas when required.\nHybrid Work Mode:\n Rotational, work in the office 1 week per month.\nAccessible Location:\n Office is within walking distance from the MRT.\nMonthly Performance Bonus\n: Up to 4 digits monetary reward, get paid for your hard work.\nProfessional Development:\n Sponsorship for professional training and workshops.\nAnnual Leave Encashment:\n Get paid for unused leave.\nTeam Bonding:\n Monthly team bonding activities based on your preference.\nWork Assets Provided:\n All necessary work tools and equipment are supplied.\nWhich of the following types of qualifications do you have?\nWhat's your expected monthly basic salary?\nWhich of the following statements best describes your right to work in Malaysia?\nHow many years' experience do you have as a data analyst?\nWhich of the following languages are you fluent in?\nHow many years' experience do you have using SQL queries?\nHow much notice are you required to give your current employer?\nHow many years' experience do you have as a SQL Analyst?","133":"Carry out data entry work with accurate information on daily basis.\nEnsuring data registered are valid.\nUpdate and maintain existing data as well as metadata management.\nAssist in design database structure and pipeline.\u00a0\nReport writing and demonstrate the understanding of relationships among each data.\u00a0\nDesign and prepare reports in a timely manner for different stakeholders.\nHousekeeping and maintenance of the database.\nUndertake any ad-hoc duties as assigned.\u00a0\nAt least a diploma in Computer Science\/ Data Science\/ any other related qualification that is equivalent.\nDetail oriented.\nStrong analytical mind and good communication skills.\nAble to work independently, responsible, self-motivated.\nProficient in MS Office (MS Excel, MS Word, MS Power Point), SQL, and Data Management.\nAble to complete tasks within given timelines with minimal supervision.\nExcellent interpersonal skills and able to work in fast-paced environment.\nSkills in programming language, data analytics and MS Power BI is a strong advantage.\nWilling to work on site office in Taman Melawati, WPKL.\u00a0\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nHow would you rate your English language skills?\nHow much notice are you required to give your current employer?\nWhich of the following programming languages are you experienced in?\nHow far are you willing to travel for work?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","134":"Understanding the whole company product line, function, and feature\nContact, coordinate and collect the needs of department. Analyse and propose a suitable system development plan for department head. Meet business needs and support transportation to achieve maximum efficiency and effectiveness.\u00a0\nReport, outlining the operation and progress of system development. Advise the department and supervisor correct control system development to meet demand and complete on time.\u00a0\nResearch and follow up new technologies and knowledge in the system and related business areas. And effectively apply to operation and bring maximum benefits to the company.\u00a0\nHaving a clear understanding of the business issues and using communication to help solve organizational problems and achieve organizational objective. And Turn business conceptualization into Software Solution.\u00a0\nWorking with business users to identify opportunities for improvement in business operations and processes.\u00a0\nSupporting test cycles particularly User Accept Test (UAT).\nProficiency in \nMandarin \nwould be preferrable.\u00a0\nAt least 1-2 years of related working experience would be added advantage.\u00a0\nWilling to work on \nMonday to Friday and alternative Saturdays.\u00a0\nPlus point if familiar with UAT and API.\u00a0\nUnderstand basic Excel functions: VLOOKUP, HLOOKUP, Pivot Table.\nWhat's your expected monthly basic salary?\nHow would you rate your Mandarin language skills?\nHow much notice are you required to give your current employer?","135":"Work with some of the best optimization minds in the world to contribute to the ongoing improvements of our optimization technologies and methodologies\nWork with Quintiq Business Consultants to design planning solutions that incorporate optimization\nDesigning and implementing the right optimization solution to solve our customers\u2019 puzzles\nParticipate in optimization research projects to come up with potential improvement ideas for our optimization solutions\nComes with 3-5 years of working experience\nDegree in Computer Science, Operations Research, Mathematics, or Artificial intelligence\nKnowledge of optimization techniques in operations research and artificial intelligence (linear programming, genetic algorithms, heuristic search techniques, constraint programming, etc.)\nExperience with object-oriented modeling (UML)\nHigh abstraction level and superior analytical skills\nWork for the one of the biggest software company in Europe\nGain exposure to a wide variety of industry experiences and IT technologies\nAn international work environment with brilliant colleagues around the globe\nA conducive and supportive environment for personal and career growth\nOpportunity to work on challenging projects\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","136":"Architect and design data infrastructure on cloud\nDesign and build resilient and efficient data pipelines for both batch and real-time streaming data\nAssemble and collect data sets that meet functional and non-functional business requirements\nIdentify, design & implement internal process improvements, automating manual processes optimizing data delivery, infrastructure for greater scalability\nBuild the infrastructure required for optimal extraction, transformation and loading of data from a variety of sources using SQL, APIs and cloud services technologies\nBuild tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics\nBuild tools for analytics and data team member that assist in building and optimizing the product into an innovative leader\nWork with data and analytics experts to strive for greater functionality in our data lake, systems and ML\/Feature Engineering for AI solutions\nWork with cross-functional departments to understand their data needs and requirements and build tools to assist them with their analytics tools\nAdditional responsibilities and tasks assigned by management from time to time\nMinimum 3 years of\u00a0relevant experience\nBachelor's or Master's degree in Data Science, Computer Science, Statistics, or a related field\nProficiency in programming languages such as Python, Java, or SQL\nExperience with data processing frameworks and technologies\nStrong understanding of database concepts and experience with relational\nKnowledge of data modeling and familiarity with cloud platforms and services\nExcellent problem-solving skills, attention to detail, and ability to work independently as well as part of a team\nStrong communication and interpersonal skills, with the ability to explain technical concepts to non-technical stakeholders\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Data Engineer?\nWhich of the following programming languages are you experienced in?\nHow many years' experience do you have using SQL queries?\nHave you worked in a role which requires experience with machine learning?","137":"To conduct user requirement analysis for the development\/ implementation of new systems and enhancements to existing systems.\nTo responsible for multiple platform applications design, development, testing, implementation, integration, documentation, maintenance and enhancement using multiple frameworks and languages.\nTo support & troubleshoot for Business Application System.\nImplement and follow coding standards and adhere to best practices and security guidelines.\nTo develops technical documents and handbooks to accurately represent the design and code of new applications.\nTo design and create report.\nTo plan and coordinate training for any system implementations or enhancements.\u00a0\nTo supervise, coach and train analyst programmers.\nAssess system capabilities and undertake feasibility studies that include financial considerations and timelines.\nOther ad-hoc duties.\u00a0\nCandidate must possess at least a Bachelor's Degree, Post Graduate Diploma, Professional Degree, Computer Science\/Information Technology or equivalent\n5 year(s) and above of relevant working experience\nSkills required: Java Technologies, C#, Visual Studio, Reporting Tools, HTML, CSS, jQuery, Vue.js, OOP, JDBC, jsp, servlet, Database Design Technologies with SQL Server and DB2\nExposure in ERP manufacturing environment and experience in data automation\nVariable Allowances\/Incentive (Handphone, Stay-Back\/Call-Back, Transport Allowance, etc)\nEmployee Education Assistance Program (For further studies)\nMedical & Dental Benefits\nInsurance\nFree Parking\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a systems analyst?\nHow many years' experience do you have as an Information Technology Executive?\nHow many years' experience do you have as an Analyst Manager?\nWhich of the following languages are you fluent in?","138":"Bachelor\u2019s degree in Business, Finance, Statistics, or a related field.\nProven 1 to 2 years\u2019 experience in data analysis, reporting, or a similar role.\nProficiency in data management and visualization tools (e.g., Excel, Power BI, Power Point).\nStrong analytical and problem-solving skills.\nExcellent attention to detail and accuracy.\nAbility to communicate complex data insights in a clear and concise manner.\nStrong organizational and time management skills.\nAbility to work independently and as part of a team.\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Business Analytics Executive?\nWhich of the following Microsoft Office products are you experienced with?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","139":"Develop and maintain scalable data pipelines on cloud platforms.\nImplement data validation, cleansing, transformation, and storage solutions in cloud and data lake environments.\nBuild ETL\/ELT processes to prepare datasets that empower data analysts and other users.\nDesign and implement cloud-native solutions for data ingestion, processing, and analytics.\n5+ years in Data Engineering, preferably in a vendor environment.\nExperienced with cloud data infrastructure such as Microsoft Azure, Google Cloud Platform, Amazon Web Services and Huawei Cloud.\nStrong background in Python, SQL, and big data tools like Hadoop, Spark, PySpark, and Delta Lake.\nOpen to local applicants only.\nCompetitive remuneration based on experience.\nSteep learning opportunity with leadership from an industry expert.\nExcellent career support and leadership training.","140":"Design and implement cloud solutions and CICD pipelines, build MLOps on Azure platform.\nRun code refactoring and optimization, containerization, deployment, versioning and monitoring of its quality.\u00a0\nWork with the data science team to research, develop, evaluate and optimize various models using different machine learning algorithms for problem solving or process optimisation.\u00a0\nExecute projects involving machine learning algorithm for computer vision applications using learners such as neural networks, clustering, segmentation, object detection, tracking.\u00a0\nDesign the self-running applications and software that makes use of that data and automates predictive models.\nBSc. or MSc. or Ph.D. in Mathematics, Computer Science, Data Science, Machine Learning, Artificial Intelligence or related fields provided they have a strong technical knowledge and experience in machine learning.\nExperience in design and implement Azure cloud-based solution and services.\nProficient in programming and scripting skills (Python and R).\nProficient in machine learning framework such as scikit-learn, pandas, TensorFlow or Keras.\nExperience in Geo-spatial analytical skills and GIS python library (GDAL, ArcPy, Geopandas, etc.) is a plus.\u00a0\nExcellent interpersonal skills, team player, resourceful and has strong analytical skills.\u00a0\nGood communication and written in English.\nWhich of the following statements best describes your right to work in Malaysia?\nHave you worked in a role which requires experience with machine learning?\nWhat's your expected monthly basic salary?\nHow many years' experience do you have as a Programmer?\nWhich of the following programming languages are you experienced in?\nHow much notice are you required to give your current employer?\nWhich of the following data analytics tools are you experienced with?","141":"Collaborate with various teams to understand and communicate business requirements\nDesign and build end-to-end ETL pipelines ensuring high reliability and security\nCreate and optimize data models for efficient data processing\nDevelop and maintain business data products\nStay up-to-date with the latest technologies and tools in the data engineering field\nProficient in creating and maintaining end-to-end ETL pipelines with a focus on reliability and security\nExperience with distributed computing agents such as Hive, Spark, Hadoop or Airflow\nStrong knowledge of data warehouse concepts and experience in data modeling and design is a must.\nStrong logical thinking and excellent verbal communication skills\nFluent in English, Mandarin language skills are necessary since some stakeholders are located in China\nCandidates with relevant data engineering experience will only be considered.\nKnowledge of big data architecture design, including data governance and compliance, is a plus","142":"Which of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Data Engineer?\nHow many years' experience do you have using SQL queries?\nWhich of the following programming languages are you experienced in?","143":"Define, design, build, and enhance business intelligence solutions.\nProvide 2nd level support on PDWH for Backend \/ Frontend DWH, Global PDWH, Production Data Marts, and iPRISM operations globally.\nProvide operational support for production data warehousing & BIA Solutions in the manufacturing domain.\nEnsure the Local\/Global Production Data Warehouse is running at a stable and high-performance level as per SLA.\nEnsure that systems, processes, and methodologies as specified are followed to ensure effective monitoring, control, and support of service delivery.\nDrive continuous improvement initiatives within the operations support area (e.g. automation of monitoring and internal controls) and control costs as per budget.\nSupport in the development and release of change requests.\nPromote transfer of knowledge and awareness to those in closely related areas, such as colleagues, and clients\/users.\nSupport in documentation and written procedures for routine and non-routine tasks.\nAble to work on AP & EU business hours during critical period.\nOn-call for critical operation support.\nBachelor's Degree in Computer Science \/ Information Technology or any relevant course.\nKnowledge in SQL and PL\/SQL in Oracle and know-how in MS SQL Database.\nUnderstanding of Data Warehousing \/ ETL techniques.\nGood analytical troubleshooting and problem-solving skills.\nStrong in service support operations & experienced in ticketing tracking systems.\nGood communication skills and a proactive team player.\nAble to work independently with minimal supervision.\nExperienced in data warehousing projects is an added advantage.\nFamiliar with business processes in the Semiconductor manufacturing industry.\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","144":"Which of the following statements best describes your right to work in Malaysia?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Data Engineer?\nHow many years' experience do you have using SQL queries?\nWhich of the following programming languages are you experienced in?\nWhich of the following Relational Database Management Systems (RDBMS) are you experienced with?","145":"Support root cause analysis to identify underlying operational issues addressable by system solutions.\nIdentify potential requirements for system design and explore new system capabilities to meet business needs.\nTranslate system capabilities into innovative solutions and lead technical solutioning for small projects with low complexity.\nUnderstand business requirements and application capabilities, managing low complexity change requests (CRs) and application enhancements to realize business needs.\nConduct thorough root cause analysis to understand requirement problem statements and propose appropriate system solutions.\nEvaluate and define potential requirements for systems design, ensuring documented requirements include associated metrics and testing procedures.\nPropose solution options and workarounds to meet business expectations while considering cost implications.\nManage CR delivery according to established processes, governing individual CR solutions and timelines.\nChampion a \"Shift Left\" mindset through the CR process, ensuring prompt tracking and updates in JIRA.\nCollaborate effectively with business stakeholders, product managers\/owners, vendors, and internal team members to prioritize and deliver against agreed-upon objectives.\nUndertake any other duties\/functions as assigned by SA Leadership.\nDegree in Computer Science \/ IT \/ Electrical & Electronic \/ Telecommunication or equivalent\nMinimum 3-4 years of relevant working experience in Telco Area\nStrong understanding of system boundaries, interfaces, and business context for frequently used applications.\nAbility to support and guide business in requirement review processes and document requirements effectively.\nProficiency in designing and developing ISD architecture solutions to support business agendas.\nAptitude for combining established methodologies with innovative techniques to address business challenges effectively.\nSkill in integrating end-user needs, technical possibilities, and business requirements to solve basic to slightly complex problems.\nExperience in leveraging established governance mechanisms to mediate conflicts, mitigate risks, and resolve issues.\nDemonstrated ability to deliver high-quality presentations and content.\nEffective stakeholder management skills and problem-solving techniques.\nAdoption of Agile and DevOps principles\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Solutions Analyst?\nWhich of the following issue and bug tracking software do you have experience with?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","146":"Provides tactical marketing and analysis support to internal customers including: customer profiling, segmentation, customer lifetime value analysis, attrition models, machine learning models, and local market opportunity analysis.\nUsing analytical and visualization software to access, transform integrate, analyze and visualize data to help solve real problems and provide business insight.\nMine data from primary and secondary sources. Clean and prune data to discard irrelevant information. Introduce new data source to improve machine learning models.\nIdentify customers for campaign targeting based on their needs and eligibility, and conduct in depth post implementation review for continues improvement and learning.\nWork closely with client to identify business requirements and translating data into informative insights and report to help solve real problems and provide business insight. Design key metrics to track business performance and identify business issue and challenges.\nSupport the campaign management from leads identification, interim tracking, and fulfillment.\nAnalyze and interpret results using standard statistical tools and techniques.\nPinpoint trends, correlations and patterns in complicated data sets\nMentoring and coaching others to improve their analytical skills.\nExperience in analyzing data trends and recommend solutions\/campaigns to create revenue or improve efficiency.\nExperience in data visualization.\nAnalytical, creative and innovative approach in solving problems\nExperience in building statistical model.\nExperience in insurance or financial services industry is preferred\nAt least 5 years of business intelligence and analytic experience in the financial industry is preferred. Candidate with supervisory experience is preferred.\nSAS\/ SQL, Tableau\/ Power BI and other analytics software (e.g. Python and R).\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nHow many years' experience do you have as a Data Analytics Manager?\nWhich of the following programming languages are you experienced in?\nHave you worked in a role which requires a sound understanding of business intelligence (BI) best practices?\nWhich of the following web analytics tools are you experienced with?\nHow many years' experience do you have using SQL queries?\nHave you worked in a role which requires experience with statistical modelling?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","147":"Designing, building, and maintaining data pipelines to collect, process, and store large datasets from various sources.\nDevelop, optimize, support, and maintain Extract, Transform, Load (ETL) processes to ensure data quality and integrity.\nMonitor and troubleshoot ETL processes to identify and resolve issues promptly, ensuring smooth operation and minimal downtime.\nIntegrate data from different sources into a cohesive and accessible data warehouse.\nMaintain clear and concise documentation for data pipelines, processes, and systems.\nWork under the close direction and supervision of senior team members to support clients' applications.\nBe responsible and accountable for task tracking, reporting, and meeting deadlines.\u00a0\nApply, maintain, and recommend improvements to development procedures and standards.\nAccept ownership for accomplishing new and different requests for personal and professional growth.\nExplore opportunities to add value to job accomplishments and contribute to team success.\nDatabase \u2013 DB2 (Preferred), Oracle (Preferred), IBM Netezza\nETL\/ELT data workflows \u2013 Data Stage (Preferred), SAP BI\nData warehouse, Data mart \u2013 including analysis of business\/users requirements, solutioning\nData design and data model\nIndependent with initiative.\nAbility to adapt to changes.\nEnjoy being challenged and to solve complex problems.\nPositive attitude with a great drive to deliver.\nPossess great sense of ownership to issues and problems.\nAptitude to grasp concepts quickly and ability to apply.\nPossess strong analysis abilities with acute sense of data analytics.\nMultiple years of experience in a professional environment performing analysis, design and development tasks on multiple platforms.\nFamiliar with data analytics, data mining concepts and machine learning algorithms.\nProficient in data design, data architecture, robust ETL\/ELT data workflows.\nWhich of the following statements best describes your right to work in Malaysia?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Data Engineer?\nWhich of the following Relational Database Management Systems (RDBMS) are you experienced with?\nHow many years' experience do you have using SQL queries?","148":"Which of the following types of qualifications do you have?\nWhich of the following statements best describes your right to work in Malaysia?\nHow many years' experience do you have as a Data Engineer?","149":"","150":"Develop a comprehensive understanding of HRD Corp\u2019s business requirements and the national-level training and development landscape to ensure data initiatives align with organisational goals.\nFormulate structured analytical frameworks and methodologies to support economic research programmes, contributing to the organisation\u2019s strategic knowledge base.\nDevelop, manage and configure advanced and predictive analytics models using various statistical techniques and specialised software tools, while driving innovation and predictive accuracy for high quality and comprehensive data.\nInterpret complex data sets and conduct comprehensive data analysis using statistical techniques and tools, such as Python, SAS, Tableau, SQL etc., depending on the requirement to optimise the efficiency and quality of reports for the consumption of the organisation and management in ensuring accurate and insightful data-driven decision-making.\nConduct in-depth data analysis and select relevant information to analyse key themes and trends using primary\/secondary\/multiple data sources and business intelligence tools, providing valuable insights for strategic decision-making.\nProduce organisational-level reports to management by in-depth data analysis and\ninterpretation that provide insights for strategic decisions and organisational performance improvement.\nDesign and visualise reports and dashboards using tools like Tableau and PowerBI to clearly and concisely communicate data findings to stakeholders, facilitating informed decision-making.\nMaintain data integrity by verifying the accuracy and consistency of data throughout the process, ensuring that all data used in analysis is reliable and valid, thereby supporting the credibility of research findings.\nContinuously improve data analysis processes and analytics models by implementing advanced analytics programming techniques, ensuring that the methodologies used are up-to-date and effective in delivering high-quality insights.\nBachelor\u2019s degree in data science, Computer Science, Statistics, Mathematics, or a related field, backed with relevant years of working experience.\nMaster\u2019s degree in above or advanced certifications in data science, machine learning, or related fields would be an added advantage.\no SAS (Statistical Analysis System) Certified Data Scientist\no SAS Certified Advanced Analytics Professional\no Open Certified Data Scientist\u00a0\no Microsoft Azure AI Fundamentals\u00a0\no IBM Data Science Professional Certificate\no CAP (Certified Analytics Professional)\u00a0\no DASCA (Data Science Council of America)\nMinimum 5-7 years of relevant working experience in conducting research and analytics function.\nRequires advanced proficiency in programming languages such as Python and other relevant statistical tools.\nProven ability in using exploratory analysis and preparing unstructured data to draw conclusions.\u00a0\nAbility to lead machine learning projects and modeling initiatives.\nExperience with data visualisation tools like Tableau and PowerBI.\nStrong analytical, critical thinking and problem-solving skills are a must.\nProficiency in data models and data sets, data cleaning methods, and handling\u00a0\nmultiple data sources.\nAbility to derive insights from complex data sets and present them clearly and concisely.\nKnowledge of additional programming languages or analytics tools is an advantage.\nRelevant experience in conducting research and analytics function would be an added advantage.\nWilling to work in\u00a0the \nHQ Office at Damansara Heights.\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nWhich of the following languages are you fluent in?\nAre you willing to undergo a pre-employment background check?\nHow much notice are you required to give your current employer?\nHow many years' experience do you have as a Research and Development Analytical Executive?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","151":"Having experience of 7+ years as senior oracle DBA\nArchitect HA and DR Solutions for PAAS services like Exadata, Autonomous Databases (ATP,ADW), RAC & Dataguard)\nInstallation and upgrade of Oracle and RAC on 10g\/11g\/12c\/18c\/19c version under Linux\/AIX platforms\nMust have oracle ASM\/ACFS implementation experience\nGood scripting skills to automate regular DBA admin tasks \u2022 Strong experience on backup utilities or tools like RMAN & EXPDP\/IMPDP, CRSCTL, SRVCTL, NetBackup, Networker\nApplying grid and DB PSU patch in standalone and multi-node RAC cluster servers\nShould have good command over speaking and writing.\nStrong experience on database and SQL queries tuning for Oracle and RAC databases\nShould have knowledge of oracle OEM 12C\/13C\nHe will be customer facing for all operational issues and activities\nStrong experience on configure and troubleshoot physical standby database using dataguard broker\nStrong experience on configure and troubleshoot golden gate replication components\nGood Grip over Tables fine tuning and troubleshooting\nImplement backup and recovery of Oracle databases for various scenarios\nAdministration over DB Objects including Tables , Clusters , Views , Procedures etc.\nGood in Impact Analysis of DB Change \/ DB Design Change etc.\nIn-depth understanding of Advanced Architectures (Multi-Node, RAC, ASM)\nGood understanding of core support processes and change management, maintain documentation standards\nMust have experience in Database tuning including I\/O, Load Analysis, ADDR, AWR, SQL Profiling etc\nResponsible for installation, upgrades (Database and RAC), patches, SR support, database tuning, concurrent manager administration, cloning\nAble to work in 24\/7 Support\nCandidate must possess at least a bachelor\u2019s degree, Post Graduate Diploma, Professional Degree (MCA \/ BE \/ BSC or SC computer science)\nOracle 10g\/11g\/12c\/18c\/19c OCP certification is a must\nHaving oracle RAC certification will be added advantage\nHaving previous banking BAU support will be added advantage\nHaving experience on additional database technologies MSSQL or DB2 or Sybase will be added advantage\nAt least 7 year(s) of working experience in the related field is required for this position.\nPreferably Senior Executives specializing in IT\/Computer \u2013 Network \/ System\/ Database Admin or equivalent.\nWhich of the following statements best describes your right to work in Malaysia?\nWhich of the following Relational Database Management Systems (RDBMS) are you experienced with?\nHow many years' experience do you have using SQL queries?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","152":"Collaborate closely with business stakeholders, including executives, managers, and subject matter experts, to understand their challenges, objectives, and opportunities for leveraging data science solutions.\u00a0\nProactively identify and define potential business use cases where data science techniques and models can provide valuable insights and drive impactful outcomes.\u00a0\nConduct in-depth discussions with business users to capture and document detailed requirements, ensuring a clear understanding of desired outcomes and deliverables.\u00a0\nUtilize advanced analytical techniques to explore and analyze relevant data sets, uncover patterns, correlations, and trends that can inform the development of effective data science solutions.\u00a0\nCreate visually compelling dashboards, reports, and presentations to communicate data-driven insights to stakeholders in a clear and understandable manner.\u00a0\nLead the design and development of data science models, algorithms, and prototypes to address identified business use cases, considering scalability, feasibility, and technical constraints.\u00a0\nCollaborate with data engineers and software developers to implement and operationalize data science models into production environments, ensuring smooth integration with existing systems and processes.\u00a0\nConduct rigorous evaluation and testing of implemented models to ensure accuracy, reliability, and alignment with business requirements. Make necessary refinements and optimizations as needed.\u00a0\nDrive the adoption of data science solutions by working closely with business users, providing training, support, and guidance on using and interpreting the outputs of implemented models.\u00a0\nA degree in Engineering, Statistics, Data Science, Applied Mathematics, Computer Science, Business Analytics or related technical field.\u00a0\nMinimum of 2 \u2013 4 years of relevant experience.\u00a0\nProficiency in statistical analysis, machine learning techniques, programming languages such as Python or R, and Deep Learning framework such as TensorFlow, PyTorch. Familiarity with data visualization tools and SQL is desirable.\u00a0\nStrong business understanding and the ability to translate business requirements into data science solutions effectively.\u00a0\nExcellent interpersonal, verbal, and written communication skills to engage with business users, explain technical concepts, and build rapport with stakeholders at all levels of the organization.\u00a0\nStrong analytical thinking and problem-solving abilities, with the capability to transform complex business challenges into actionable data science use cases.\u00a0\nProven experience in managing end-to-end data science projects, including requirements gathering, solution design, implementation, and post-deployment support.\u00a0\nLeaves: Annual Leave, Medical Leave, Hospitalization Leave, Special Leave.\u00a0\nMedical Benefits \u2013 Sunway Medical Insurance for Outpatient & Inpatient inclusive for dependents.\u00a0\nDental and Optical benefits.\u00a0\nGroup Term Life & Personal Accident Insurance Scheme.\u00a0\nExecutive Health Screening for confirmed executive.\u00a0\nFlexible Working Arrangement\/Hybrid Working Arrangement\u00a0\nSalary increment based on individual performance.\u00a0\nBonus based on company & individual performance.\u00a0\nCareer Development: Training and certification sponsored by the company, Annual Talent Review, Career Planning.\u00a0\nRewards and recognition: Long Service Award.\u00a0\nAdditional Benefits: Staff Discount (i.e. ThemePark, Hospitality, Education, Property, Medical, Retail, Food & Beverages), Sports and Recreational, Family Day, Annual Dinner, Flexible Working Arrangement for working mothers.\u00a0\nOpen communication. Young, energetic and fun working environment.\u00a0\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nHow many years' experience do you have as a data scientist?","153":"Design and develop AI models to enhance ERP functionalities.\nIntegrate AI solutions with ERP using its API.\nCollaborate with internal stakeholders to gather requirements and deliver customized solutions.\nTrain and support users in leveraging AI features.\nStay updated with the latest advancements in AI and ERP technologies.\nAI and Machine Learning:\nProficiency in machine learning algorithms and deep learning frameworks.\nExperience with NLP and predictive analytics.\nProgramming and Development:\nStrong skills in Python, R, SQL, and RESTful API development.\nExperience with data integration and ETL processes.\nData Management and Analysis:\nSkills in data preprocessing and database management.\nFamiliarity with big data technologies.\nSoftware Engineering:\nExperience with version control systems and SDLC.\nSkills in testing and validating AI models.\nAnalytical and Problem-Solving Skills:\nStrong analytical thinking and problem-solving abilities.\nCommunication and Collaboration:\nAbility to engage with stakeholders and provide training and support.\nStrong documentation skills.\nProficiency in machine learning algorithms and deep learning frameworks.\nExperience with NLP and predictive analytics.\nStrong skills in Python, R, SQL, and RESTful API development.\nExperience with data integration and ETL processes.\nSkills in data preprocessing and database management.\nFamiliarity with big data technologies.\nExperience with version control systems and SDLC.\nSkills in testing and validating AI models.\nStrong analytical thinking and problem-solving abilities.\nAbility to engage with stakeholders and provide training and support.\nStrong documentation skills.\nBachelor\u2019s or Master\u2019s degree in Computer Science, Data Science, or related field.\nRelevant certifications in AI, data science, or ERP systems.\nProven experience in AI development and ERP integration.\nFamiliarity with cloud computing platforms and DevOps practices.\nWhat's your expected monthly basic salary?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","154":"Design, develop, and deploy AI models and algorithms for various financial applications.\nCollaborate with cross-functional teams to gather and analyze data, identify opportunities for AI integration, and provide data-driven insights.\nImplement Generative AI, predictive analytics, and other AI techniques to develop advanced financial tools.\nStay up-to-date with the latest AI and machine learning trends and technologies and assess their potential applications in the Fintech industry.\nOptimize AI models for performance, scalability, and reliability.\nCreate and maintain documentation for AI solutions, including model architecture, data pipelines, and processes.\nParticipate in code reviews and provide guidance on best practices for AI development.\nBe part of building up MLOps ecosystem.\nBachelor's or Master's degree in Computer Science, Artificial Intelligence, Data Science, or a related field.\nHaving final year project or any working experience related to AI would be an advantage.\nExcellent problem-solving and analytical skills.\nEffective communication and teamwork abilities.\nQualifications\nSkills\nWorking Experience\nExpected Salary\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nHow much notice are you required to give your current employer?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","155":"Which of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as an Analytics Specialist?\nWhich of the following Relational Database Management Systems (RDBMS) are you experienced with?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","156":"You will understand our requirements and outcomes to ensure data-driven decision-making.\nYou will conduct tailored analysis for specific products and operations, define critical business metrics, track them rigorously, and recommend continuous improvements.\nYou will frame business scenarios and propose features that impact critical business processes and decisions.\nYou will transform requirements into concise insights through reports, presentations, and dashboards, and consolidate data from multiple sources to create comprehensive views for decision-making.\nYou will develop data pipelines and custom data science models to solve identified problems.\nYou will launch A\/B tests, analyse the results, and provide recommendations based on your findings.\nYou have at least 4 years of experience in data-related or quantitative fields such as Analytics, Science, Statistics, or Mathematics.\nYou are fluent with SQL, Python, R or other scripting\/programming languages.\nYou are experienced in handling large datasets and maintaining complex Extract, Transform and Load (ETL) processes.\nYou have solid statistical knowledge and hands-on experience running and analysing controlled experiments.\nYou are proficient in creating dashboards using Tableau, PowerBI or other visualisation tools.\nWe have your back with \nTerm Life Insurance \nand comprehensive \nMedical Insurance.\nWith \nGrabFlex, \ncreate a benefits package that suits your needs and aspirations.\nCelebrate moments that matter in life with loved ones through \nParental\n and \nBirthday leave\n, and give back to your communities through \nLove-all-Serve-all (LASA)\n volunteering leave\nWe have a confidential \nGrabber Assistance Programme\n to guide and uplift you and your loved ones through life's challenges.","157":"Cross-site leading role on enabling and sustain Equipment basic data with latest defined coupling\nLead team and actively maintain, provide consultancy for assigned data assets and responsible for defined data sets quality management\nInterface to FI\/IT on Equipment basic data specification\nKey user and expert for basic data system and planning model andensure high accuracy for purpose of business\nExpert and implement data governance for assigned data assets\nLead team and implement automation to improve basic data application\nAccountable for the implementation of global process and guideline. Close collaboration with cross-function and cross-site stakeholders to ensure standardization and implementation\n3- 5 years working experience in semiconductor or related field\nDegree in Computer science, Data science, Manufacturing engineering,Mathematics or other technical studies\nKnowledge of Oracle, SQL, Python, APF\/RTD, Tableau, Confluence,Outsystem\nExperience in data extract, transform, load solutions and dataanalytics solutions in industry (preferable semiconductor)\nProfound in communications and presentation of complex technical solutions to different stakeholders\nFluent in German and English\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","158":"Analyse and understand the business data requirements and translate it into a reporting solution.\nResponsible for creating an insight data\/ reporting \/ dashboard and presenting it to the respective stakeholders.\nParticipate in their current migration project from Tableau to PowerBI\nWill be supporting all global regions (global products with different business needs)\nCollaborate with data analysts, data engineers, and business stakeholders to gather requirements and ensure reports meet business needs.\n3 - 5 years of working experience\nHighly proficient in Power BI\nAble to understand, clean, transform, and prepare data from various sources to ensure it is suitable for reporting and analysis - visualisations\nAttractive remuneration package\nOpportunity for global business exposure\nDynamic working environment with career growth opportunities\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","159":"Provide leadership and guidance to the team to ensure alignment with management expectations.\nResponsible and oversee the implementation of all BI projects until Go Live.\nEnsure all projects are properly documented in accordance to the organization\u2019s project management methodology and templates.\nEnsure regular review with team on all BI projects and provide progress updates to the management.\nEnsure that the BI Servers and Datamart are in tiptop condition and able to support the smooth operation requirements.\nUp-to-date in BI Solution and market progress and provide continuous BI improvement to the organization.\nStrategize effective contingency plan to ensure information\/reporting downtime are kept to the minimum.\nSet and constant review the team\u2019s KPI and achievement.\nIdentify and plan for the team\u2019s learning\/training requirements to prepare for future goals.\nPerform relevant tasks as assigned by Management from time to time.\nAt least a Diploma in Computer related studies.\nMSSQL and Database Management certification is an added\nadvantage.\nGood communication and problem-solving skills.\nGood analytical skills to identify issues and bottlenecks.\nStrong problem-solving and analytical abilities in interpreting data.\nGood comprehension on Pivot table functionalities.\nGood team player.\nAbility to solve problems effectively, think creatively and deliver\nquality outputs in a timely manner.\nAbility to make decisions independently in a fast-paced environment.\nGood attention to detail.\nGood organizational, prioritization and time management skills.\nFast and keen learner \u2013 able to work individually and in a team.\nT-SQL Scripting\nDemonstrate proficiencies in office productivity tools (Excel, Words, Power Point).\nAt least 2 years of relevant working experience in Microsoft SQL\nenvironment, T-SQL development role.\nEnhance, refine or repurpose existing in-house data warehouse ETL\nprocess (MS SSIS).\nOptimize SQL queries, stored procedures, and database structures\nfor improved efficiency.\nStrong skills in SQL programming tasks including creating view,\nprocedures, function and packages.\nGather stakeholder requirements, translate into Business\nRequirements & Functional Requirements Documents, and\ntransform into System Design Documents.\nDesign, develop and implement innovative dashboards and analytic\nreports based on business stakeholder requirements.\nManage reporting issues and tickets reported by stakeholders by\nidentifying the potential root cause and able to coordinate and\ncommunicate with different parties to get the issues resolved.\nHave good knowledge in operational processes is an added\nadvantage.\nMonitor and maintain database health and performance using SQL\nServer Management Studio (SSMS) and other tools.\nIdentify and resolve performance bottlenecks and database-related\nissues.\nWhich of the following statements best describes your right to work in Malaysia?\nWhich of the following types of qualifications do you have?\nWhich of the following Relational Database Management Systems (RDBMS) are you experienced with?\nHow many years' experience do you have as an Information Technology Executive?\nHow many years' experience do you have using SQL queries?","160":"\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","161":"","162":"Design, develop, and deploy machine learning models and algorithms for complex and unique datasets, using various techniques such as mathematical modeling, scikit-learn, NLP, CNN, RNN, DL, RL, Transformers, GAN, LLM, RAG, prompt engineering, GPT.\nCollaborate with cross-functional teams to extract insights, identify business opportunities and provide data-driven recommendations\nStay up-to-date with the latest machine learning and AI techniques and tools\nCommunicate complex technical concepts to non-technical stakeholders in an easy-to-understand manner\nBachelor's degree or higher in Computer Science, Mathematics, Statistics, Actuarial Science, Informatics, Information Science or related fields\nStrong analytical skills and attention to detail\nParticipation in Kaggle, Mathematics Olympiad or similar competitions is a plus\nExcellent programming skills in Python, R, Java, or C++\nFamiliar with ML frameworks such as Tensorflow, Keras, PyTorch, MLFlow, AutoML, TensorRT, CUDA\nExcellent communication and collaboration skills\nExperience with designing, training, and deploying machine learning models\nCustomer centric and committed to deliver the best AI results to customers\nWhat's your expected monthly basic salary?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","163":"Responsible for the company's enterprise big data platform, building a hierarchical, flexible, and scalable enterprise big data platform.\nUnderstand business analysis requirements, design and develop corresponding data warehouses\/data marts, ETL development, and optimization work, to complete the construction of a structured, flexible, and scalable data warehouse.\nResponsible for data warehouse model design, report development, and maintenance.\nResponsible for the performance of the data warehouse system, model performance design, and optimization.\nWork together with the data product manager to solve technical problems related to business data analysis, data reporting, and data anomalies.\nDeeply understand business models, data models, and system models to improve system productivity.\nBachelor's degree or above in computer science, mathematics, or statistics; familiar with the internet industry, with over 3 years of experience in DW\/ETL\/BI work; proficient in at least one mainstream ETL\/BI solution.\nProficient in data warehouse architecture and principles, with experience in designing large-scale data warehouse architecture, model design, and performance tuning; proficient in SQL\/Hive, with good experience in SQL performance tuning, candidates with Java\/Python development experience are preferred.\nAble to proficiently use one or more mainstream databases (such as Oracle, MySQL, etc.), candidates with database design experience are preferred.\nExperience in developing big data distributed computing platforms, familiar with the principles and applications of Hadoop, Hive ecosystem products.\nSerious, responsible, and careful at work, with a good team spirit, good analytical skills, and communication skills.\nWhat's your expected monthly basic salary?\nHow many years' experience do you have as a Data Warehouse Engineer?\nWhich of the following languages are you fluent in?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","164":"Team Leadership: \nLead, mentor, and inspire a team of data scientists. Provide guidance on project priorities, technical challenges, and professional development. Foster a culture of innovation and continuous improvement within the team.\u00a0\nProject Management:\n Oversee end-to-end data science projects, ensuring timely and accurate delivery of advanced analytics and strategic insights. Coordinate with stakeholders to understand project requirements.\u00a0\nPredictive Modeling:\n Drive the development and implementation of predictive models using advanced statistical and machine learning techniques to solve complex business problems.\u00a0\nData Exploration and Preparation: \nGuide the team in exploring and preprocessing large datasets to extract meaningful features and insights.\u00a0\nCollaboration with Stakeholders: \nWork closely with cross-functional teams to understand business objectives, align data science initiatives, and communicate insights to both technical and non-technical stakeholders.\u00a0\nContinuous Improvement: \nDrive continuous improvement initiatives within the team, staying updated on the latest advancements in data science and contributing to the improvement of data science methodologies.\nLeadership Skills:\n Proven ability to lead and inspire a team of data scientists. Foster a collaborative and innovative team culture.\u00a0\nProject Management:\n Strong project management skills, including the ability to prioritize tasks, allocate resources, and meet deadlines.\u00a0\nAdvanced Analytical Skills:\n Proficient in analyzing large, complex datasets and extracting meaningful insights.\u00a0\nStatistical and Machine Learning Expertise:\n Experience in applying advanced statistical and machine learning techniques to solve real-world problems.\u00a0\nProgramming Skills: \nProficient in programming languages such as Python or R for data analysis and modeling.\u00a0\nCommunication Skills: \nExcellent communication skills to convey complex findings and insights effectively.\nEducational Background:\n Master's or Ph.D. in Data Science, Statistics, Computer Science, or a related field.\u00a0\nExperience:\n Proven experience as a Data Scientist, with a strong portfolio showcasing successful data science projects. Previous leadership or management experience is essential.\u00a0\nProgramming Proficiency: \nProficient in programming languages such as Python or R, and experience with relevant libraries and frameworks.\u00a0\nMachine Learning: \nSolid understanding and experience in applying machine learning algorithms to real-world problems.\u00a0\nCommunication Skills:\n Strong interpersonal and communication skills for effective collaboration with cross-functional teams.\u00a0\nContinuous Learning: \nStay updated with industry trends, data science techniques, and relevant tools. Attend training and development programs as needed.\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a data scientist?\nWhich of the following programming languages are you experienced in?","165":"What's your expected monthly basic salary?\nHow many years' experience do you have as an Agronomist?\nAre you willing to travel for this role when required?","166":"Build up call centre\u2019s data, analyse data indicators, and continuously optimize all data indicators;\nResponsible for setting and tracking operation targets (SLAs), analyzing abnormal data or weak links, giving early warning and improvement suggestions;\nDeeply understand the industry, improve the data analysis system, and promote the team's data analysis ability;\nAny ad-hoc duties as assigned by the Company from time to time.\nAt least 3 to 5 years of data analysis experience, large volume data analysis experience in call centre or related service industry is highly preferred;\nStrong knowledge of PowerBI and EXCEL functions for data analysis is an advantage;\nGood presentation ability to interpret and present statistical analysis (text, data and charts);\nGood at interpersonal communication, rigorous logical thinking, strong organization and coordination skills;\nIndependent, proactive, self-motivated, and able to meet tight deadline with minimal supervision.\nWhich of the following types of qualifications do you have?\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nHow many years' experience do you have as a Data Analytics Specialist?\nHow many years' experience do you have as a Power BI Developer?\nHow many years' experience do you have as an Excel Analyst?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","167":"Academic Qualification: Pursuing Bachelor's or Master's degree in Computer Science, Business Analytics, Statistics, Data Science, or any related field.\nExperience: Experience or coursework in Machine Learning, Natural Language Processing (NLP), Data Science or Analytics project.\nIT Literacy Able to work in an Agile environment with excellent time management skills.\nPersonality A positive attitude and a vibrant, creative personality.\nWhich of the following types of qualifications do you have?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","168":"create, train, and deploy machine learning models to address business challenges.\napply statistical analysis and data mining techniques to extract actionable insights.\nwork with data engineer(s) to design and maintain data pipelines.\nensure data integrity and quality through rigorous validation and processing methods.\nimplement data aggregation and enhancement processes to support analytics.\nassist in the development of AI products.\ncontinuously improve and optimize machine learning models for production use.\nbachelor's or master's degree in data science, computer science, statistics, or a related discipline\nminimum of 3 years of hands-on experience in data field\nstrong proficiency in Python and SQL\nskilled in machine learning tools like Scikit-learn, TensorFlow, PyTorch, etc\nsolid background in statistical analysis and data modeling\nexperience with data visualization platforms such as Tableau or Power BI\nfamiliar with data engineering tools like Apache Spark and Hadoop","169":"An exciting job with latest technology\nContinuous training & development of soft and hard skills\nA competitive salary, inline with your profile\nA package of benefits including healthcare insurance\nAn awesome team of colleagues & regular team building activities\nThe ability to work with the world\u2019s leading companies in technology and innovation\nAn environment where we embrace openness, transparency and grab every opportunity to have fun, while always doing what is right for our customers and partners.\nWhich of the following statements best describes your right to work in Malaysia?","170":"\u6570\u636e\u7ba1\u7406\u4e0e\u5206\u6790\uff1a\n \u4f7f\u7528 Excel \u7ba1\u7406\u548c\u5904\u7406\u5927\u578b\u6570\u636e\u96c6\uff0c\u8fdb\u884c\u6570\u636e\u6e05\u7406\uff0c\u5e76\u786e\u4fdd\u6570\u636e\u8d28\u91cf\u3002\n\u6570\u636e\u63d0\u53d6\u4e0e\u62a5\u544a\u66f4\u65b0\uff1a\n \u4ece\u5404\u79cd\u6765\u6e90\u63d0\u53d6\u6570\u636e\uff0c\u5305\u62ec\u6570\u636e\u5e93\uff0c\u5e76\u5b9a\u671f\u66f4\u65b0\u62a5\u544a\uff0c\u4ee5\u53cd\u6620\u6700\u65b0\u548c\u6700\u51c6\u786e\u7684\u89c1\u89e3\u3002\n\u62a5\u544a\u751f\u6210\uff1a\n \u5728 Excel \u4e2d\u521b\u5efa\u5e76\u81ea\u52a8\u751f\u6210\u7efc\u5408\u62a5\u544a\uff0c\u4ee5\u603b\u7ed3\u5173\u952e\u4e1a\u52a1\u6307\u6807\u548c\u8d8b\u52bf\u3002\n\u6570\u636e\u63d0\u53d6\uff1a\n \u4f7f\u7528 SQL \u4ece\u6570\u636e\u4ed3\u5e93\u4e2d\u63d0\u53d6\u548c\u5206\u6790\u6570\u636e\uff0c\u4ee5\u652f\u6301\u5404\u79cd\u4e1a\u52a1\u529f\u80fd\u548c\u62a5\u544a\u3002\n\u4eea\u8868\u677f\u521b\u5efa\uff1a\n \u8bbe\u8ba1\u548c\u7ef4\u62a4 Power BI \u4ea4\u4e92\u5f0f\u4eea\u8868\u677f\uff0c\u4ee5\u53ef\u89c6\u5316\u6570\u636e\u5e76\u5411\u5229\u76ca\u76f8\u5173\u8005\u63d0\u4f9b\u89c1\u89e3\u3002\n\u81ea\u52a8\u5316\uff1a\n \u4f7f\u7528 Python \u6216\u5176\u4ed6\u76f8\u5173\u5de5\u5177\u521b\u5efa\u5e76\u5b9e\u65bd\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u5904\u7406\u91cd\u590d\u6027\u4efb\u52a1\u3002\n\u903b\u8f91\u4e0e\u5206\u6790\u601d\u7ef4\uff1a\n \u8fd0\u7528\u5f3a\u5927\u7684\u903b\u8f91\u4e0e\u5206\u6790\u601d\u7ef4\u7406\u89e3\u5e76\u5904\u7406\u590d\u6742\u7684\u6570\u636e\u5173\u7cfb\uff0c\u786e\u4fdd\u89c1\u89e3\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002\n\u95ee\u9898\u89e3\u51b3\u4e0e\u4f18\u5316\uff1a\n \u8fd0\u7528\u521b\u9020\u6027\u548c\u6279\u5224\u6027\u601d\u7ef4\u8bc6\u522b\u73b0\u6709\u6d41\u7a0b\u4e2d\u7684\u8d8b\u52bf\u3001\u5f02\u5e38\u548c\u6539\u8fdb\u673a\u4f1a\u3002\n\u534f\u4f5c\uff1a\n \u4e0e\u8de8\u804c\u80fd\u56e2\u961f\u5bc6\u5207\u5408\u4f5c\uff0c\u4e86\u89e3\u6570\u636e\u9700\u6c42\uff0c\u5e76\u57fa\u4e8e\u5206\u6790\u63d0\u4f9b\u53ef\u884c\u7684\u5efa\u8bae\u3002\n\u5229\u76ca\u76f8\u5173\u8005\u6c9f\u901a\uff1a\n \u5411\u6280\u672f\u548c\u975e\u6280\u672f\u5229\u76ca\u76f8\u5173\u8005\u6e05\u6670\u6709\u6548\u5730\u5c55\u793a\u6570\u636e\u89c1\u89e3\u3001\u62a5\u544a\u548c\u5efa\u8bae\u3002\n\u6301\u7eed\u5b66\u4e60\uff1a\n \u5173\u6ce8\u884c\u4e1a\u8d8b\u52bf\u548c\u5206\u6790\u5de5\u5177\u7684\u8fdb\u5c55\uff0c\u6301\u7eed\u63d0\u5347\u6280\u672f\u548c\u8f6f\u6280\u80fd\u3002\nExcel\uff1a\n \u9ad8\u7ea7\u6280\u80fd\uff0c\u719f\u7ec3\u4f7f\u7528\u516c\u5f0f\u3001\u6570\u636e\u900f\u89c6\u8868\u548c\u6570\u636e\u53ef\u89c6\u5316\u3002\nSQL\uff1a\n \u57fa\u672c\u5230\u4e2d\u7ea7\u7684 SQL \u67e5\u8be2\u7f16\u5199\u77e5\u8bc6\uff0c\u8fdb\u884c\u6570\u636e\u63d0\u53d6\u548c\u5206\u6790\u3002\nPower BI\uff1a\n \u6709\u6570\u636e\u53ef\u89c6\u5316\u548c\u521b\u5efa\u4ea4\u4e92\u5f0f\u4eea\u8868\u677f\u7684\u7ecf\u9a8c\uff08\u4f18\u5148\u8003\u8651\uff09\u3002\nPython\uff1a\n \u719f\u6089\u4f7f\u7528 Python \u81ea\u52a8\u5316\u6570\u636e\u5904\u7406\uff08\u4f18\u5148\u8003\u8651\uff09\u3002\nOKR \u4efb\u52a1\u7ba1\u7406\uff1a\n \u719f\u6089 OKR \u6846\u67b6\uff0c\u4ee5\u4fbf\u5c06\u6570\u636e\u4efb\u52a1\u4e0e\u4e1a\u52a1\u76ee\u6807\u5bf9\u9f50\uff08\u4f18\u5148\u8003\u8651\uff09\u3002\n\u7ecf\u9a8c\uff1a\n \u81f3\u5c11 2 \u5e74\u6570\u636e\u5206\u6790\u6216\u76f8\u5173\u9886\u57df\u7684\u5de5\u4f5c\u7ecf\u9a8c\u3002\nData Management & Analysis:\u00a0\nUse Excel to manage and manipulate large datasets, perform data cleaning, and ensure data quality.\nData Extraction & Report Updates:\u00a0\nExtract data from various sources, including databases, and update reports regularly to reflect the most accurate and up-to-date insights.\nReport Generation:\u00a0\nCreate and automate comprehensive reports in Excel to summarize key business metrics and trends.\nData Extraction\n: Extract and analyze data from the data warehouse using SQL to support various business functions and reports.\nDashboard Creation:\u00a0\nDesign and maintain interactive dashboards in Power BI to visualize data and provide insights to stakeholders.\nAutomation: \u00a0\nCreate and implement automated solutions for repetitive tasks using Python or other relevant tools.\nLogical & Analytical Thinking:\u00a0\nApply strong logical and analytical thinking to understand and handle complex data relationships, ensuring the accuracy and reliability of insights.\nProblem Solving & Optimization:\u00a0\nUse creative and critical thinking to identify trends, anomalies, and opportunities for improvement in existing processes.\nCollaboration: \u00a0\nWork closely with cross-functional teams to understand data needs and provide actionable recommendations based on analysis.\nStakeholder Communication:\u00a0\nPresent data insights, reports, and recommendations clearly and effectively to both technical and non-technical stakeholders.\nContinuous Learning:\u00a0\nStay up to date with industry trends and advancements in analytics tools, continuously enhancing both technical and soft skills.\nExcel\n: Advanced proficiency with formulas, pivot tables, and data visualization.\nSQL\n: Basic to intermediate knowledge in writing SQL queries for data extraction and analysis.\nPower BI\n: Experience with data visualization and creating interactive dashboards (preferred).\nPython\n: Familiarity with automating data processes using Python (preferred).\nOKR Task Management\n: Familiarity with OKR frameworks for aligning data tasks with business objectives (preferred).\nExperience\n: At least \n2 years\n of experience in a data analysis role or a related field.\nWe are seeking candidates proficient in Mandarin to better serve our Mandarin-speaking customers.\nWhat's your expected monthly basic salary?\nHow many years' experience do you have as a data analyst?\nWhich of the following data analytics tools are you experienced with?","171":"You will understand business problems and convert them to ML problem space. Work with the business teams to understand workflows and requirements, and analyze data to identify patterns, trends, and anomalies that can inform automation projects and provide insights to stakeholders.\nYou will collaborate with the Data Science and Software Engineering teams to identify areas of automation and optimization within our systems, with a focus on operational efficiency and reducing manual interventions.\nYou will design, develop, and implement automation solutions that improve the efficiency of different processes, using your expertise in data analysis, machine learning, and engineering knowledge.\nYou will lead automation projects aimed at complex system fine-tuning with real market change, applying data-driven techniques to bring growth in the automated system.\nYou will use machine learning techniques to improve automation resilience and improve system performance.\nYou will work with stakeholders to define project goals and deliverables, ensuring that the automation projects align with the goals.\nAt least 3 years of experience in software engineering or data science, and experience in writing production code.\nProficiency in SQL, Python and at least one backend language like Go, Scala, Java, C++, or others.\nProficiency in data processing frameworks such as Spark or Flink.\nProficiency in ML and DL frameworks such as XGBoost or Pytorch.\nExperience in ETL pipelines for data processing, model training and serving.\nUnderstanding of optimization concepts and techniques, with experience in applying optimization methods to improve system performance.\nExperience with large-scale systems and DevOps best practices such as CI\/CD.\nWe have your back with Term Life Insurance and comprehensive Medical Insurance.\nWith GrabFlex, create a benefits package that suits your needs and aspirations.\nCelebrate moments that matter in life with loved ones through Parental and Birthday leave, and give back to your communities through Love-all-Serve-all (LASA) volunteering leave\nWe have a confidential Grabber Assistance Programme to guide and uplift you and your loved ones through life's challenges.\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","172":"Forming clear data addressable problem statements from current business problems\nGathering, validating and understanding data relevant to the problem statement\nDesigning and building data transformation pipelines and machine learning algorithms to solve the business problem\nWorking with product management and other business stakeholders to review and iterate data products to fit emerging market trends\nEvangelising appropriate ML methods and explaining them, and their associated benefits and limitations to team members from Engineering and Strategy.\nPost graduate qualification in a quantitative field (e.g. Physics, Mathematics, Bioinformatics, Computer Science)\nAdvanced data extraction and processing skills using SQL, Spark, etc\nFamiliarity with S3, EC2 and\/or EMR in AWS.\nDeep knowledge of machine learning algorithms and efficient data structures, ensembling and model performance tuning\nExperience with NLP\nConfident working at the command line in a *nix environment\nAble to write serviceable code (e.g. Scala, Go, Python, Ruby) and comfortable working with and around a professional software development teams\nGood communication and interpersonal skills with the ability to communicate with business key decision makers and product owners\nAbility to adapt quickly and thrive in an ambiguous and rapidly changing environment\nExperience with Deep Learning (particularly CNNs and RNNs)\nTrack record in working independently within an agile team environment, scoping work, making and keeping commitments to deliver against a shared agenda\nExperience working with datasets which do not fit within memory on a single machine\nHybrid working mode\nPermanent position\nMature and collaborative working culture\nExtensive employee benefits","173":"Which of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a data scientist?\nWhich of the following languages are you fluent in?","174":"Manage cost savings and efficiencies against department budget by set up specific goals in reducing cost.\nHow many years' experience do you have as a data analyst?\nWhich of the following Microsoft Office products are you experienced with?","175":" \nPrepare model performance monitoring reports and accountable for accurate, timely reporting to the management committee.\u00a0 The monitoring report served to provide insights to ensure correct use of model and facilitate critical decision making related to model recalibration or refinement.\n\n\n \nReview and on-going improvement in model performance monitoring process and automation.\n\n\n \nKnowledge of scripting particularly in SAS, Python, data savvy and able to work with huge datasets to ensure on-going model monitoring in accordance to Basel and MFRS requirements. \n\n\n \nDrill down into data\/trend identified from the data.\u00a0 Presents and discusses analysis, model monitoring results i.e. identify area of concern and its thought\/rational.\u00a0 \n\n\n \nRecommend and establish standards, guidelines and processes that improve model monitoring approaches.\n\n\n \nComprehensive awareness of the business, regulatory environment, technology and trends and ensure these are reflected in the models monitoring in timely and accurate manner. \n\n\n \nStrong communication skills.\u00a0 Ability to communicate model monitoring result through compelling narratives within the team as well as to different business leaders and provide value added input to make data driven business decision as well as model enhancement initiatives.\u00a0 \n\n\n \nSocialize with business expert to gather business insight in the respective area of model monitoring and data analytics.\n\n\n \nCollaboration within the team and related parties correspondence to data related activities i.e. data derivation rules etc. \n\n\n \nGood knowledge of relevant regulatory requirements on risk models and risk parameters.\n \nGood understanding on the respective area\u2019s business products and operations.\n \nGood analytical skills.\n \nGood statistical modeling knowledge.\n \nGood understanding of relational databases and data models.\n \nGood programming skills in data handling and statistical modeling.\n\n\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","176":"To produce regular experience analysis reports granularity for Accident and Health plans, in support of the Company\u2019s medical claim management strategy.\nTo produce regular mortality and morbidity claim experience analysis.\nTo work closely with the business and operation teams (ie. claim, underwriting, agency, marketing, etc.) to understand business requirements and to formulate an analytical work plan based on the stated objectives.\nExecute the analytical work plan end-to-end from producing data requirements, extracting data to completing the analysis and presenting the results\/analytic insights to business user.\nDevelop deep understanding of operational and business data and continuously improve existing workflow.\nPreparing reports for the management stating trends, patterns, and predictions using relevant data.\nAnalyzing local, national, and global trends that impact both the organization and the industry\nUsing statistical tools to identify, analyze, and interpret patterns and trends in complex data sets could be helpful for the diagnosis and prediction.\nA bachelor\u2019s degree in Actuarial Science, Computer Science, Information Management, IT, Applied Statistics, Finance, Accounting, Data Analytics or any related discipline.\nMinimum 6 years\u2019 experience in relevant fields (Domain knowledge: Insurance\/Takaful operations, Claims, NBUW etc)\nProficient in both written and spoken English and Bahasa.\u00a0\nProficient in Microsoft Office applications and analysis tool (SQL, Power BI, Qlik Sense, SAS, Python, Oracle DB etc)\nAbility to work with minimum supervision, flexible and agile in ways of working.\u00a0\nAnalytical skills and strong organizational abilities.\nGood presentation skills, ability to interpret and present to senior management.\nA team player with good communication skills being key in managing stakeholders.\nBackground in market research and project management skills will be an added advantage.\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following languages are you fluent in?","177":"Min 3 years working experience\nProficient in SQL, Python, Snowflake \/ Azure \/ AWS \/ GCP\nExpert in ETL processes, Data Transformation, Pipeline Development, Database Management and Data Warehousing\nCompetitive salary and benefits package\nInnovation Solutions but using cutting-edge technologies","178":"Manage critical technical maintenance activities associated with all mechanical systems to reduce operational risk and in accordance with the MOP.\u00a0\nResponsible for developing the SOP, EOP and MOP for all the critical facility equipment and activities\nProvide technical support during the construction phase, responding to RFIs and addressing any issues that arise.\nWork with the Shift team on incident investigation, follow up actions and the submission of the interim and final report to Senior management for review.\u00a0\nTo identify the parameters to be trend in the BMS\/DCIM system data and focusing on data analysis to identify opportunities to improve the reliability\/efficiency of the Critical equipment or processes.\nTo support in the Green Mark DC Certification and ensure that the existing Chiller Plant is compliance to the Green Mark requirement.\nParticipate in perform drill \/ Tabletop exercise \/ dry run-on equipment failure in developing the Emergency Operating Procedures.\nTo support and coordinate in Major activities like Annual Shutdown, Overhaul etc\u00a0\nCoordinating with multiple disciplines to ensure that projects are delivered within budget and on schedule while managing the mechanical team including HVAC, fire protection, plumbing.\nKeep abreast of changes in codes and technologies appropriate to the mechanical, plumbing and fire protection disciplines.\nAnalyse and evaluate mechanical system performance, identifying areas for improvement and making recommendations for upgrades.\nEvaluate and recommend new technologies and equipment to enhance system performance and reduce operational costs.\nCollaborate with cross-functional teams, including electrical and mechanical engineers, to ensure seamless integration of the chiller systems with other data centre infrastructure.\nAnalyse energy usage, identifying opportunities for optimization and cost savings.\nDiploma\/ degree in Mechanical Engineering\/ Building Services or equivalent.\n5 years of working experience in data center or critical infrastructure industry\u00a0like refinery or oil and gas\nFamiliar with Microsoft Excel and Word, BMS, CMMS\/ DCIM, ERP and Microsoft BI.\nExcellent in problem solving and root cause analysis.\nAbility to articulate and explain technical concepts to non-technical trained stakeholder\nWhich of the following statements best describes your right to work in Malaysia?\nHow many years' experience do you have as a mechanical engineer?","179":"\n\nDesign, develop, document and implement end-to-end data pipelines and data integration processes, both batch and real-time. This includes data analysis, data profiling, data cleansing, data lineage, data mapping, data transformation, developing ETL \/ ELT jobs and workflows, and deployment of data solutions.\n\n\nMonitor, recommend, develop and implement ways to improve data quality including reliability, efficiency and cleanliness, and to optimize and fine-tune ETL \/ ELT processes.\n\n\nRecommend, execute and deliver best practices in data management and data lifecycle processes, including modular development of ETL \/ ELT processes, coding and configuration standards, error handling and notification standards, auditing standards, and data archival standards.\n\n\nEnsure development adheres to guidelines and governance policies on data and business intelligence platform.\n\n\nCollaborate with IT team members, SMEs, vendors and internal business stakeholders, to understand data needs, gather requirements and implement data solutions to deliver business goals.\n\n\nBAU supports any data issues and change requests, documents all investigations, findings, recommendations and resolutions.\n\n\nSupport daily operation incidents and service requests.\n\n\n\n\nHands-on experience on Azure Data Solution such as Azure Synapse Spark, Synapse DB, Data Factory, Databricks, Azure Lake Storage and Power BI.\n\n\nExperience with various ETL\/ELT frameworks, data warehousing concepts, data management framework and data lifecycle processes.\n\n\nExperienced in handling and processing different types of data (structured, semi-structured and unstructured).\n\n\nUtilized Azure DevOps to implement CI\/CD workflows and deployment of ETL jobs across multiple environments.\n\n\nStrong knowledge in various database technologies (RDBMS, NoSQL and columnar).\n\n\nProficient in ETL programming languages like Python, PySpark and SQL.\n\n\nExperience with Microsoft Fabric is an added advantage.\n\n\nAbility to communicate and present technical information in a clear and unambiguous manner.\n\n\nStrong ability to work independently and cooperate with diverse teams in a multiple stakeholder environment.\n\n\nStrong sense of work ownership, high affinity with any data and a desire for constant improvements.\n\n\nExperience with SAP data sources preferred.\n\n","180":" \nAttractive remuneration, great perks, and performance incentives\n \nComprehensive medical, insurance, or social security coverage\n \nWorld-class workspaces\n \nEngaging activities and recognition programs\n \nStrong learning and development plans for your career growth\n \nPositive culture for you to #BeMore at work\n \nEasy to locate area with direct access to public transport\n \nFlexible working arrangements\n \nBe coached and mentored by experts in your field\n \nJoin a global company, winner of hundreds of industry awards\n \n \nData Architecture Design: \n \nDesign and implement effective data architecture, solutions and models to store, retrieve, cleanse, process company data that would fit the dynamic nature of our clients' data systems and analytics needs\n \nExamine and identify data architectural and processes necessities by evaluating client operations, applications, and programming.\n \nAssess data architecture implementation procedures to ensure they comply with internal and external regulations.\n \n \n \nData Governance and Quality: \n \nLead data governance initiatives to ensure data accuracy, completeness, security, and regulatory compliance.\n \nMonitor data quality, identify data inconsistencies, and implement corrective strategies to address short and long terms challenges.\n \n \n \nData Strategy and Policy Development: \n \nDevelop and implement comprehensive data management policies and procedures to ensure the integrity, availability, and confidentiality of data.\n \nCollaborate with IT security to implement robust data security measures.\n \n \n \nData Integration and Migration: \n \nPlan and execute data migration between systems, ensuring data integrity and minimal impact on ongoing business, data and development operations.\n \nOversee the integration of new data management technologies and software engineering tools into the existing system.\n \n \n \nTeam Leadership & Project Management: \n \nOversee data-related projects from inception to completion, ensuring they meet deadlines, budgets, and quality standards.\n \nManage and lead the data management team, setting clear objectives and evaluating performance.\n \nCollaborate with other departments to identify and meet data requirements, ensuring that data is accessible and useful across the organization.\n \nPrioritize and allocate resources effectively to manage multiple projects simultaneously. Any other duties and responsibilities that may be assigned to you by the management from time to time, within your category of employment in the organization.\n \n \n \n \nDesign and implement effective data architecture, solutions and models to store, retrieve, cleanse, process company data that would fit the dynamic nature of our clients' data systems and analytics needs\n \nExamine and identify data architectural and processes necessities by evaluating client operations, applications, and programming.\n \nAssess data architecture implementation procedures to ensure they comply with internal and external regulations.\n \n \nLead data governance initiatives to ensure data accuracy, completeness, security, and regulatory compliance.\n \nMonitor data quality, identify data inconsistencies, and implement corrective strategies to address short and long terms challenges.\n \n \nDevelop and implement comprehensive data management policies and procedures to ensure the integrity, availability, and confidentiality of data.\n \nCollaborate with IT security to implement robust data security measures.\n \n \nPlan and execute data migration between systems, ensuring data integrity and minimal impact on ongoing business, data and development operations.\n \nOversee the integration of new data management technologies and software engineering tools into the existing system.\n \n \nOversee data-related projects from inception to completion, ensuring they meet deadlines, budgets, and quality standards.\n \nManage and lead the data management team, setting clear objectives and evaluating performance.\n \nCollaborate with other departments to identify and meet data requirements, ensuring that data is accessible and useful across the organization.\n \nPrioritize and allocate resources effectively to manage multiple projects simultaneously. Any other duties and responsibilities that may be assigned to you by the management from time to time, within your category of employment in the organization.\n \n \nBachelor's or master's degree in Data Science, Computer Science, Information Management, or a related field.\n \nProven experience (7-10 years' experience) in data management, data governance, and significant experience in data architecture or a similar role.\n \nStrong understanding of databases, data analysis procedures, and data administration.\n \nIn-depth knowledge of data architecture design and deployment, database management, and data modeling tools.\n \nExperience with data management software and tools.\n \nExcellent leadership and team management skills.\n \nStrong communication and interpersonal abilities.\n \nHands-on approach, getting things done fast and ability to work without continual guidance.\n \nKnowledge of data privacy laws and compliance requirements.\n \nCertification in data management (e.g., CDMP) and data architecture (e.g., TOGAF, CDA) is preferred.\n \nExperience in data development & management on Cloud platforms like AWS, GCP, Azure, with basic familiarity of BI software i,e., Power BI, Looker Studio or Tableau is preferred.\n \nGood to have experience with Workflow Management i.e. Airflow and Jenkins, and CI\/CD tools such as Git and JIRA.\n \nCreative thinker with agile mind and ability to recognize inefficiencies and challenge the status quo.\n \nAttention to detail.\n \nExcellent presentation skills.\n \nWorks well in ambiguity and embraces the adventure!\n \n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","181":"\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","182":"Develop and implement data-driven strategies for workforce planning, including forecasting talent needs, succession planning, and identifying skill gaps.\nUtilize predictive analytics to anticipate future workforce trends, such as attrition, hiring needs, and capability shifts.\nDesign and implement dashboards for ongoing workforce tracking, enabling proactive decisions around hiring, promotions, and internal mobility.\nCreate comprehensive reports and visualizations that communicate actionable insights to HR leadership and business stakeholders, and prepare standard reporting capabilities.\nAutomate reporting processes and integrate various data sources to provide cohesive reporting capabilities.\nPresent data insights to non-technical stakeholders in a clear, concise manner, ensuring understanding across diverse business units.\nBuild and maintain dynamic, real-time dashboards using Power BI, providing leadership with key insights into HR metrics.\nWork closely with HR, finance, and business leaders to understand their data needs and deliver customized solutions.\nSupport the HR function in transforming data into insights that inform talent acquisition, retention, and development strategies.\u00a0\nLead and support projects focused on improving HR processes and outcomes through data-driven strategies.\nStay updated on industry trends and best practices in people analytics, incorporating them into the company's HR strategy.\nEnsure compliance with data protection laws and regulations (e.g., GDPR) when handling employee data.\nMaintain the highest level of integrity and confidentiality when dealing with sensitive employee data.\nBachelor\u2019s or Master\u2019s degree in Data Science, Statistics, or Business Administration, or a related field.\n5 years of experience in data analytics, preferably within an HR context.\nExperience with SAP SuccessFactors Reporting\nStrong experience in data-driven approaches to anticipate future workforce needs\nProven track record of delivering actionable insights that positively impact business outcomes.\nProficiency in statistical analysis software (e.g., R, Python) and Excel for complex data analyses.\nAdvanced Power BI skills, including the ability to create dynamic, user-friendly dashboards.\nStrong problem-solving and critical-thinking abilities, especially in interpreting HR data.\nExcellent communication skills, with the ability to present data to non-technical stakeholders.\nStrong project management and organizational skills, capable of managing multiple initiatives simultaneously.\nStrong attention to detail and a commitment to data accuracy.\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","183":"Which of the following statements best describes your right to work in Malaysia?\nWhich of the following types of qualifications do you have?\nWhich of the following languages are you fluent in?\nWhat is your degree CGPA range?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","184":"Architect and Design Solutions:\n\u00a0Lead the design and architecture of scalable, secure, and resilient cloud solutions across multiple cloud platforms (AWS, Azure, Google Cloud).\nData and AI Integration:\n\u00a0Develop and implement data strategies, including data lakes, data warehouses, and real-time data processing. Integrate AI and machine learning models to enhance business processes and decision-making.\nTechnical Leadership:\n\u00a0Provide technical leadership and guidance to development teams, ensuring best practices in cloud architecture, data management, and AI implementation.\nStakeholder Collaboration:\n\u00a0Collaborate with business stakeholders to understand requirements and translate them into technical solutions. Communicate complex technical concepts to non-technical stakeholders.\nInnovation and Strategy:\n\u00a0Stay updated with the latest trends and technologies in cloud computing, data, and AI. Drive innovation and strategic initiatives to enhance our technology stack.\nSecurity and Compliance:\n\u00a0Ensure that all solutions adhere to security best practices and compliance requirements. Implement robust security measures to protect data and applications.\nPerformance Optimization:\n\u00a0Monitor and optimize the performance of cloud-based applications and data systems. Identify and resolve performance bottlenecks.\nDocumentation and Training:\n\u00a0Create comprehensive documentation for designed solutions. Provide training and support to internal teams and clients.\nEducation:\n\u00a0Bachelor\u2019s or Master\u2019s degree in Computer Science, Information Technology, or a related field.\nExperience:\n\u00a0Minimum of 8 years of experience in solution architecture, with a focus on cloud computing, data management, and AI.\nCloud Expertise:\n\u00a0Proficiency in multiple cloud platforms (AWS, Azure, Google Cloud). Certification in one or more cloud platforms is a plus.\nData Management:\n\u00a0Strong experience with data architecture, data lakes, data warehouses, and real-time data processing.\nAI and Machine Learning:\n\u00a0Hands-on experience with AI and machine learning frameworks and tools (e.g., TensorFlow, PyTorch, Azure ML, AWS SageMaker).\nTechnical Skills:\n\u00a0Proficiency in programming languages such as Python, Java, or C#. Experience with containerization (Docker, Kubernetes) and CI\/CD pipelines.\nSoft Skills:\n\u00a0Excellent communication, problem-solving, and leadership skills. Ability to work collaboratively in a fast-paced environment.\nCertifications:\n\u00a0Relevant certifications in cloud computing, data management, and AI are highly desirable.\nWhich of the following types of qualifications do you have?\nWhich of the following statements best describes your right to work in Malaysia?\nWhich of the following programming languages are you experienced in?\nWhat's your expected monthly basic salary?\nHave you worked in a role which requires experience with machine learning?\nHow many years' experience do you have as a solutions architect?\nHow many years' experience do you have as an Artificial Intelligence Specialist?","185":"\n\nCollaborate with cross-functional teams to analyze and drive actions to improve End to End Yield.\n\n\nDevelop and implement algorithms and methodologies to identify and address yield issues.\n\n\nDesign and maintain web services for data analysis and visualization.\n\n\nUtilize coding skills to automate data collection, analysis, and reporting processes.\n\n\nImplement AI Techniques to develop predictive yield models and optimize production & Test performance.\n\n\nWork closely with engineering teams to optimize manufacturing processes and reduce scraps.\n\n\nMonitor and analyze production data to identify trends and potential areas for improvement.\n\n\nDrive continuous improvement initiatives to enhance yield performance and product quality.\n\n\nProvide regular reports and updates on yield metrics and performance.\n\n\nAble to sustain existing process systems will be added advantage.\n\n\n\n\nBachelor\u2019s degree in electrical engineering, Computer Engineering, or related field.\n\n\nAt least 4 years\u2019 experience in yield engineering or semiconductor manufacturing.\n\n\nStrong coding skills, with proficiency in languages such as Python, SQL, Java, or C++.\n\n\nStrong data analysis and statistical techniques.\n\n\nKnowledge of database systems and data management.\n\n\nKnowledge on AI and machine learning algorithms will be added advantage.\n\n\nFamiliarity with semiconductor assembly process and test methodology.\u00a0\n\n\nExperience in web service development and maintenance.\n\n\nExcellent communication and collaboration skills.\n\n\nAbility to work effectively in a fast-paced, dynamic environment.\n\n\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","186":"Develop, maintain, and improve dashboards to monitor and assess chatbot performance.\u00a0\nExperience with conversational design principles and best practices for chatbot user interfaces would be an advantages.\u00a0\nConduct market research to stay abreast of industry trends, competitor offerings, and emerging technologies in AI and chatbots.\nAssist in creating and maintaining product roadmaps that align with business goals and user needs.\nCommunicate product features, updates, and user feedback to both technical and non-technical stakeholders.\nContribute to the continuous improvement of our \nAI models \nand natural language processing\u00a0capabilities.\nBachelor's degree in Computer Science or a related technical field.\n5~8 years of experience in product management\n, preferably in AI, chatbots, or related technologies.\nStrong understanding of AI and Machine Learning concepts, particularly in \nnatural language processing (NLP)\n and Gen AI.\nProficiency in data analysis and interpretation, with experience using tools such as R, SQL, or Python.\nExcellent problem-solving skills with the ability to translate data insights into actionable product improvements.\nStrong project management skills.\nOutstanding communication and collaboration skills, with the ability to work effectively in cross-functional teams.\nDemonstrated ability to manage priorities and drive product outcomes.\nKnowledge of regulations related to \ndata privacy and protection\n as they apply to AI and chatbots.\nTechnical leadership and guidance in the evaluation, selection and integration of software and cloud-based technologies.\n\u00a0\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Solution Lead?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","187":"The individual will be responsible to provide ETL (extract-transfer-load) solutions and deployment of these solutions thus involve in various BI and Big Data Analytics related projects.\nThe individual will also be responsible in building necessary automation data feeds (ETL\/ELT) mechanisms for data transfer from various source applications to target applications. Perform data integration - administration, optimization of performance evaluation & monitoring to the data feeds.\nSupport existing production portfolio and troubleshoot issues in providing fixes and solutions.\nParticipate in all aspects of software product development life cycle (SDLC) including requirement gathering, work flow architecture design, development, testing, demo, training and documentation. Plan, prepare and lead User Acceptance Test (UAT) for releases and ensure testing completeness.\nThe individual should demonstrate hi-energy and desire for data mining, scripting, problem solving and data analysis.\nWork collaboratively with DBAs, infrastructure, network, data enablement teams and application BA analysts.\nCollaborate improvements in data governance, methodologies and processes. Demonstrate a deep interest and understanding of big data, data modelling, data structures, data catalogue and how to manipulate data in an efficient manner. Quick in formulating quality, feasible and practical solution fit to big data application\nAble to perform knowledge sharing of theoretical and practical.\nKnack of exploring and try out new things related to Data Analytics world.\nTraining will be provided on needed basis.\nSomeone with minimum 5 years of IT working experience especially into Business Intelligence or Data Analytics related job.\nPossess at least a Degree in Computer Science, Information Technology, Engineering or related courses.\nData integration (ETL), mining, analytics \nexperiences is A MUST. \nExperience in manipulating and analyzing complex, high-volume, high-dimensionality data from varying sources and perform ETL (extract transfer load) scripts.\nDevelopment\u00a0experience in Data Lake solutions such as Data Bricks, Azure DataLake, Fabric, AWS, Snowflake, Cloudera or Data Fabric such as Atlan, cinchy, IBM for \nBig Data solution is preferred.\nHave experience in development in Hadoop environment is an added advantage and understand components the applications in Hadoop eco-system using ETL framework components such as Nifi, Kafka, Pentaho, Spark, Datalake Insights etc.\nCloud environment \ndevelopment\u00a0 experience is y preferred. HCIA\/HCIP\/HCIE certificate in cloud computing, or equivalent certificates in the industry preferred, ep: \nAWS, Azure, GCP cloud certificates\n. Familiarity with AWS particularly services S3, Lambda, EMR, EC2 is added advantage.\nSQL \nexperience a MUST\n. Perform SQL as daily routine job. Working experiences in development database (such as MSSQL Server, Teradata or Oracle).\nHave working experience or exposure with Business Intelligence tools is highly recommended. Preferably: \nTableau, Power Query, Power BI Desktop etc\n.\nComing from manufacturing background (but not essential).\nOther preferred software skill(s): \nPHP, Python, Java, Javascript is an added advantage\n.\nStrong visualization capability and passionate in quantitative analysis \u2013 statistics, math, modeling, design etc.\nStrong written and verbal communication skills. Good communication background. Good command in English speaking, listening and writing is highly desired. Important as this needed to work will multi organization manufacturing and enterprise within the company\nMust be result oriented with strong analytical, troubleshooting & problem-solving skills with minimal supervision.\nKnowledge of Project Management and Safe Agile process is an added advantage.\nExtremely passionate with data from source to end solution\nExperienced working in a virtual team environment is a plus.\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Data Engineer?\nHow many years' experience do you have using SQL queries?\nWhich of the following programming languages are you experienced in?\nWhich of the following data analytics tools are you experienced with?\nHow much notice are you required to give your current employer?\nHow many years' experience do you have as a Data Integration Engineer?","188":"As a Data Engineer for Big Data Solutions\u00a0you will actively collaborate in the development of IT pipelines to transfer data between different systems in the international semiconductor operations network (SO)\nThis includes working on ETL (Extract \u2013 Transfer \u2013 Load) development for Hadoop ecosystem, SQL and other related technologies\nSupport in developing and programming a custom ETL framework in Python\nWork with customer departments and senior management to understand business objectives and requirements of the organization and develop solutions\nCollaborate with IT departments from different plants worldwide to roll out our developed solutions to the semiconductor IPN\nBe part of an agile development team and take responsibility for tasks defined by the product owner\nUniversity Degree (Bachelor\/Master) in Information Technology or comparable qualifications\nCandidate posses 3-5 years similar work experience in the same field\nGood communication skills (Verbal and Written) especially in meetings and reviews with all levels and departments\nAble to work in an intercultural team\nStrong interest in modern technologies, agile mindset and ability to work under pressure\nReliability and flexibility to work in a pioneer team\nKnowledge of programming language like Python, Java, C++\nExperience with working in a Hadoop Ecosystem (eg. PySpark, Airflow, Kafka)\nStructured and independent way of working, analytical skills to grasp complex interrelationships\nWillingness to take over responsibility\nExperience with project management tools and processes\nTechnical background within semiconductor business\nFluent in English (written and spoken), German skills are a plus\u00a0\nLeave Entitlement e.g: Annual Leave, Medical Leave and etc\nCompany Insurances and etc","189":"What's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as an Information Technology Business Analyst?\nWhich of the following languages are you fluent in?\nHave you worked in a role which requires a sound understanding of the software development lifecycle?\nHow would you rate your English language skills?\nWhich of the following Microsoft Office products are you experienced with?\nHow many years' experience do you have using SQL queries?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","190":"Act as the Level 1 & Level 2 Application Support for applications like ERP\nProvide training to end users.\nInvolve in analyzing problems escalated from Level 1 and finding solutions.\nInvolve in working and communicating with the vendor whenever a problem cannot be resolved locally.\nSupport local application development and support across the product supply and commercial processes\nUnderstanding in the areas of application programming, database, and system design.\nUse Excel to create a required dashboard.\nUpdate website info as and when needed\nDegree in Computer Science, Information Technology, or any relevant discipline.\nAt least 2 years of experience in supporting and delivering IT applications, preferably prior experience working on ERP system\nExperience in Epicor will be an added advantage.\nAdvanced knowledge of Excel is preferred.\nAssists in the enforcement of project deadlines and schedules.\nAd-hoc tasks assigned by superior\nProficiency in English, Bahasa Malaysia, and Mandarin in both written and oral.\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as an Information Technology Business Analyst?\nHow would you rate your English language skills?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","191":"Conduct research on strategic and competitiveness issues, including macroeconomics, microeconomics, sustainable development, societal well-being, planetary health and climate, health and well-being, future of work, poverty and inequality, justice and equity, emerging science, technology and innovation, foresight exercises, etc.\nContribute to consulting projects based on project requirements.\nAssist in designing and implementing research outputs, including policy briefs, working papers, conference presentations, and peer-reviewed journal articles.\nUndertake data collection and ensure ethical practices in collection, storage, sharing, and dissemination.\nPerform data analysis using appropriate methods. Quantitative work may involve modelling and statistical analysis with R, EViews, STATA, or Python, while qualitative work may include focus groups, interviews, and thematic analysis with NVivo or ATLAS.ti.\nDerive and deliver key insights for final project deliverables such as slides and reports.\nConduct workshops and training for the Institute and University.\nBachelor's degree with a focus on empirical analysis (Fresh graduates are welcome to apply).\nPossesses a good understanding of policies, programmes, and theoretical foundations of strategy competitiveness across Sunway IGSC\u2019s three primary work domains: Economy, Society, and Environment.\nProficient in English (fluency in Bahasa Malaysia or an additional language is an added advantage).\nStrong critical thinking and problem-solving skills.\nProficient in the latest data analysis methods, with a solid understanding of data structures and processing techniques.\u00a0\nStrong interest and capability in both quantitative and qualitative research methodologies.\nExceptional written and verbal communication skills, with the ability to engage and collaborate effectively with a diverse range of stakeholders.\nProven track record as a valuable team member, combined with the ability to exercise sound judgement, initiative, and independence in various tasks.\nStrong organizational abilities, including effective prioritization, time management, and planning skills to consistently meet tight deadlines.","192":"Provides on-going training and technical support of our Epicor ERP system and in-house developed MES system, and tooling management system.\nDevelop dashboards and reports to support department and business needs\nPerforms routine maintenance, patch updates, and day-to-day maintenance work on all ERP and integration platforms.\nWork closely with corporate IT in China to ensure all the IT policies, procedures and standards are in consistence in place.\u00a0\nCustomize and configure Epicor ERP modules to align with the organization's specific business needs.\nAssist with implementing, maintaining, supporting, and troubleshooting application systems as assigned.\nFacilitates training of end users and testing of business applications\nPerform other duties as assigned.\nBS in Computer Science\/Information Systems or equivalent technical experience preferred\nExperience with ERP systems is highly desirable, Minimum 2+ years' experience in ERP support & development area required. Prior consulting experience in ERP implementation is a plus\nStrong analytical and problem-solving skills\nGood verbal, presentation and written communication skills\u00a0\nExperience in Systems Analysis & troubleshooting\nBusiness Intelligence tool skills, e.g. QlikView is an added advantage\nWhich of the following types of qualifications do you have?\nWhich of the following statements best describes your right to work in Malaysia?\nHave you worked in a role which requires a sound understanding of business intelligence (BI) best practices?\nWhat's your expected monthly basic salary?\nHave you worked in a role which requires Qlikview development experience?\nHow many years' experience do you have as an Application Suport Analyst?\nHow many years' experience do you have in an application support function?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","193":"\n\nDesign, develop, document and implement end-to-end data pipelines and data integration processes, both batch and real-time. This includes data analysis, data profiling, data cleansing, data lineage, data mapping, data transformation, developing ETL \/ ELT jobs and workflows, and deployment of data solutions.\n\n\nMonitor, recommend, develop and implement ways to improve data quality including reliability, efficiency and cleanliness, and to optimize and fine-tune ETL \/ ELT processes.Recommend, execute and deliver best practices in data management and data lifecycle processes, including modular development of ETL \/ ELT processes, coding and configuration standards, error handling and notification standards, auditing standards, and data archival standards.\n\n\nEnsure development adheres to guidelines and governance policies on data and business intelligence platform.\n\n\nCollaborate with IT team members, SMEs, vendors and internal business stakeholders, to understand data needs, gather requirements and implement data solutions to deliver business goals.\n\n\nBAU supports any data issues and change requests, documents all investigations, findings, recommendations and resolutions.\n\n\nSupport daily operation incidents and service requests.\n\n\n\n\nHands-on experience on Azure Data Solution such as Azure Synapse Spark, Synapse DB, Data Factory, Databricks, Azure Lake Storage and Power BI.\n\n\nExperience with various ETL\/ELT frameworks, data warehousing concepts, data management framework and data lifecycle processes.\n\n\nExperienced in handling and processing different types of data (structured, semi-structured and unstructured).\n\n\nUtilized Azure DevOps to implement CI\/CD workflows and deployment of ETL jobs across multiple environments.\n\n\nStrong knowledge in various database technologies (RDBMS, NoSQL and columnar).\n\n\nProficient in ETL programming languages like Python, PySpark and SQL.\n\n\nExperience with Microsoft Fabric is an added advantage.\n\n\nAbility to communicate and present technical information in a clear and unambiguous manner.\n\n\nStrong ability to work independently and cooperate with diverse teams in a multiple stakeholder environment.\n\n\nStrong sense of work ownership, high affinity with any data and a desire for constant improvements.\n\n\nExperience with SAP data sources preferred.\n\n","194":"Take ML models\/algorithms from conception to production, by designing and implementing ML microservices and pipelines in production environment.\u00a0\nDevelop pipelines for continuous operation, feedback and monitoring of ML models leveraging best practices from the CI\/CD vertical within the MLOps domain.\u00a0\u00a0\nThis can include monitoring for data drift, triggering model retraining and setting up rollbacks.\u00a0\nMaintain and continuously optimize live productive ML services with a focus on scalability, availability, and reliability.\u00a0\nStrive for automation and cloud operation readiness.\u00a0\nCollaborate with data scientists and data engineers to deliver ML models in productive services.\u00a0\nStay updated with the latest trends and technologies in AI\/ML, GenAI and MLOps to drive innovation and system enhancements.\u00a0\nBachelor's degree in computer science or equivalent. A minimum of 4 years' experience in software engineering or machine learning engineering is preferred.\u00a0\nStrong programming skills in Python, Java and SQL variants, with knowledge of design patterns, code optimization, and object-oriented design.\u00a0\nProficiency in ML operationalization and orchestration (MLOps) tools, techniques and platforms. This includes scaling delivery of models, managing and governing ML Models, and managing and scaling AI platforms\u00a0\nFamiliar with Kubernetes and Docker, including installation, deployment, configuration and optimization.\u00a0\nGood understanding of ML frameworks such as TensorFlow, Keras, PyTorch.\u00a0\nExperience in web development skills such as HTML, Javascript, CSS is a big plus.\u00a0\nKnowledge of AWS cloud platform would be an advantage.\u00a0\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Machine Learning Engineer?\nWhich of the following programming languages are you experienced in?\nHave you worked in a role which requires experience with machine learning?\nHow many years' experience do you have using SQL queries?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","195":"Min 3 years working experience\nProficient in SQL, Python, and cloud platforms like AWS, Azure, Snowflake, GCP\nFamiliar with BI Tools like Power BI and Tableau\nCompetitive salary and benefits package\nHybrid and supportive working culture\nInnovation Solutions but using cutting-edge technologies","196":"Work with property develop and construction-related datasets in regards to sustainability.\nConduct exploratory data analysis to uncover methods of data extraction, uncover insights and patterns throught data visualisation.\n.Implement prompt engineering and python to extract data from source files\nCreate informative data visualizations using Power BI and Autodesk tools to communicate findings effectively .\nCreate dashboards which are able to effectively monitor project's data.\nWork closely with cross-functional teams to build and communicate usage of the dashboards.\nDocument code, methodologies, and results to allow continuity of work.\nCover sustainability implementation in the organisation assigned.\nCandidates currently pursuing a Bachelor's in Computer Science, or a related field.\nHave basic understanding of prompt engineering and\u00a0 Power BI.\nAbility to process and analyse large volume of data and information.\u00a0\nPossess an excellent command of the English language (written & oral), strong communication, negotiation, and analytical skills.\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","197":"Bachelor or Master or PhD in Science (Biochemistry, Molecular Biology, Biotechnology, Biology, Biomedical Science) or equivalent.\nTypically, >4 years of relevant experience or >1 year of direct experience in NGS and qPCR applications.\nStrong understanding of molecular biology, analytical chemistry and laboratory equipment and procedures.\nRequires in-depth knowledge and experience in related field and ability to work independently.\nRequires having good teamwork with other competency such as instrument hardware\/software engineers.\nRequires basic knowledge in statistical analysis software (e.g., R, Python, SAS, Minitab), experimental design principles, hypothesis testing, and other statistical methods.\nRequires basic knowledge on data analytics and visualization (e.g. Macro, VBA, Power BI, Power Apps). Any relevant or similar data analytics and visualization could be considered.\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","198":"\n\nDesign and develop software applications for data collection, processing, analysis, and visualization.\n\n\nIntegrate various manufacturing and testing equipment with our data systems to automate data capture.\n\n\n\n\nImplement algorithms to process and analyze large datasets to identify trends, anomalies, and efficiency opportunities.\n\n\nDevelop machine learning models to predict machine failures and optimize manufacturing processes.\n\n\n\n\nWork closely with manufacturing engineers to understand their data needs and provide technical solutions.\n\n\nContinuously explore new technologies and methodologies to improve existing systems and processes.\n\n\n\n\nCreate dashboards and reports to visualize key manufacturing metrics and insights.\n\n\nEnsure accurate and timely delivery of data to stakeholders.\n\n\n\n\nEnsure the integrity and reliability of data analytics software.\n\n\nDocument code, processes, and methodologies for knowledge sharing.\n\n\n\n\nCollaborate with IT and operational teams to integrate software solutions into the broader company ecosystem.\n\n\nParticipate in cross-functional teams to support broader organizational goals.\n\n\n\n\nBachelor's\/Master\u2019s degree in Computer Science\/Engineering, data science or related field\n\n\n2-5 years of experience in software development\u00a0\n\n\nExperience in programming language (python, R) and database (SQL) to perform data mining and analysis.\n\n\nKnowledge of statistical techniques in data science (regression, properties of distribution)\n\n\nKnowledge in machine learning techniques (neural network, machine learning)\n\n\nStrong analytic skills and problem-solving skills.\n\n\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","199":"\n\nAnalyze and organize raw data\u00a0\n\n\nBuild data systems and pipelines\n\n\nEvaluate business needs and objectives\n\n\nInterpret trends and patterns\n\n\nConduct complex data analysis and report on results\u00a0\n\n\nPrepare data for prescriptive and predictive modeling\n\n\nBuild algorithms and prototypes\n\n\nCombine raw information from different sources\n\n\nExplore ways to enhance data quality and reliability\n\n\nIdentify opportunities for data acquisition\n\n\nDevelop analytical tools and programs\n\n\nCollaborate with data scientists and architects on several projects\n\n\n\n\nProficiency in Oracle PL\/SQL and MS SQL.\n\n\nExperience with data replication, change data capture, and performance tuning.\n\n\nFamiliarity with data warehousing concepts and ETL processes.\n\n\n(Good to have) Knowledge of Kafka and Debezium.\n\n","200":"","201":"Propose new solutions and evolve existing ones to be used by product features that relies on AI.\nDesign and conduct online and offline evaluations to compare variants of AI-based product features.\nAssist the team in delivering AI projects that help the business to achieve their strategic priorities.\nBreak-down the problems and propose directions to overcome obstacles.\nResearch, build, deploy and maintain integrated AI solutions.\nWork with Strategy, Product, Operation, Commercial and Software Development teams to address a variety of challenging business problems.\nCollaborate with teams from Asia and Pacific partners.\nStrengthen secure coding practises and tooling within team.\nForm clear data addressable problem statements from current business problems.\nGather, validate, and understand data relevant to the problem statement.\nDesign and build data transformation pipelines and machine learning algorithms to solve the business problem.\nWork with product management and other business partners to review and iterate data products to fit emerging market trends.\nActively communicate with others in an effective, timely manner with empathy.\nContribute to the safety, work-life balance, and well-being of other team members.\nHelp creates a safe space for sharing of different opinions\/feedback.\nImprove your abilities through tutoring and set example behaviour.\nActively seek out learning opportunities for self and others through inviting and providing regular feedback.\nContributor to the data science community at SEEK Pass and SEEK (e.g., Open-source projects, Mentoring, Guilds).\nImproves self and others through inviting and providing regular feedback.\nA MSc or PhD qualification in Computer Science, Computational Physics, Mathematics, Statistics, or a related field.\n3 years of experience in Data Science.\nConsistently write effective, testable, readable, and secure code in one of the following programming languages: Python, Go, Scala, C\/C++, or Java\nSound experience using modern data science practices.\nExperience with Data Modeling and Machine Learning algorithms.\nExperience applying continuous integration and continuous deployment (CI\/CD).\nCommercial experience with agile methodologies (e.g., Kanban, Lean, Scrum).\nCommercial experience working in multi-functional technology teams.\nProactively manages professional growth and identifies learning opportunities.\nExperience giving and receiving effective feedback and contributing to others\u2019 learning.\nAbility to perform data exploratory analysis for proof of concepts and to Communicate the results to a diverse audience.\nPractice with:\nComputer Vision processing libraries (e.g., OpenCV, YOLO, Rekognition)\nRelational database such as MySQL or PostgreSQL.\nAmazon Web Services (e.g. EC2, S3, VPC, SQS, SageMaker).\nDistributed processing framework such as Hadoop or Spark.\nContainer package such as Docker.\nDeployment tools, such as Ansible, Terraform and Chef.\nUses data to support decision-making.\nKnowledge in:\nComputer Vision\nDeep Learning\nNatural Language Processing\nOptimisation\nAbility to adapt quickly and manage an environment of rapid change and development.\nComfortable in a start-up environment with ambiguity, minimum viable products, and rapid iteration & learning\nExperience integrating with third-party systems.\nExperience working with encrypted and highly sensitive data.\nSupport of flexible working, including a mix of office and work from home days depending on your role.\nThe opportunity to work from anywhere for up to 4 weeks per financial year\nCasual dress \u2013 every day","202":"Collect, clean, and preprocess data from various sources.\nDevelop, train, and deploy machine learning models to solve business problems.\nUtilize statistical analysis and data mining techniques to derive actionable insights.\nCommunicate findings to stakeholders through data visualization and presentations.\nCollaborate with the full-time data engineer to design and maintain data pipelines.\nEnsure data integrity and quality through robust validation and processing mechanisms.\nImplement data aggregation and enhancement processes to support analytics.\nContribute to the development of AI products.\nContinuously refine and optimize machine learning models for production use.\nMonitor and maintain deployed models to ensure optimal performance.\nCandidate must possess at least Diploma or Bachelor\u2019s or Master\u2019s degree in Data Science, Computer Science, Statistics, or a related field.\nAt least 3 year(s) \nof relevant experience in data science, machine learning, and data engineering.\nProficiency in programming languages such as Python and SQL.\nExperience with machine learning frameworks and libraries (e.g., Scikit-learn, TensorFlow, PyTorch).\nStrong understanding of statistical analysis and data modelling techniques.\nFamiliarity with data visualization tools (e.g., Tableau, Power BI) and data management systems.\nKnowledge of data engineering best practices and tools (e.g., Apache Spark, Hadoop).\nExcellent problem-solving and analytical skills.\nStrong communication skills, both written and verbal, with the ability to convey technical concepts to non-technical stakeholders.\nAbility to work independently and as part of a team in a fast-paced environment.\nStrong communication skills, both written and verbal in English. Fluency in Mandarin is a plus.\nThe Ascent @ Paradigm Mall\nMonday - Friday (Flexible working hours)\n13th month salary\nEPF \/ SOCSO \/ PCB.\nMedical, Dental and Optical benefits.\nFree-flow snacks and drinks in office pantry.\nSmart casual working attire.\nFull Attendance Allowance.\nFree Parking.\nYoung, vibrant and open work culture.\nHow many years' experience do you have as a data scientist?\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nHave you worked in a role which requires experience with machine learning?\nWhich of the following languages are you fluent in?\nHow much notice are you required to give your current employer?\nHow many years' experience do you have as a Data Engineer?","203":"Which of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as an Artificial Intelligence Engineer?\nWhich of the following programming languages are you experienced in?\nHave you worked in a role which requires experience with machine learning?\nHow many years' experience do you have as an Artificial Intelligence Specialist?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","204":"Design and development of data engineering, analytics and integration roadmap, aligned with our long-term business goals.\nPartner with business stakeholders to understand their data needs and translate them into actionable data strategies.\nDesign and implement a scalable data infrastructure, including data warehouses, data lakes, and data pipelines.\nSelect and implement appropriate data governance policies and procedures to ensure data quality, security, and compliance.\nChampion a culture of data literacy across the organization by establishing training programs and promoting best practices.\nStay current with emerging data technologies and trends, recommending solutions that optimize our data utilization.\nGather requirements and specifications during project development lifecycle from\u00a0 technical stakeholder\/users\nGather\u00a0technical stakeholder\/users expectations and limitations\nEvaluate existing systems and programs to recognize areas for improvement and integration.\nDevelop solutions based on the defined schedules and test plans, prepare analyst reports, and ensure adherence to project guidelines and objectives\nIdentify potential issues between systems and\u00a0 technical stakeholder\/users specifications and propose new solutions to work around these limitations.\nExamine technical stakeholder\/users\u2019s existing systems and configurations to ensure projects are uniform with enterprise-level systems.\nResolve issues regarding specifications and requirements\nInterface with technical stakeholder\/users to provide feedback and updates on development projects.\nGather information to prepare reports and presentations to update technical stakeholder\/users on development of projects\u00a0\nDegree in Computer Science, Information Technology, or a related field\nMinimum 3 years of experience as a Data Engineer or in a similar data-focused role\nProficient in data engineering tools and technologies such as SQL, Apache Spark, and cloud-based data platforms (e.g., AWS, Azure)\nStrong understanding of data modelling, ETL processes, and data warehousing principles.(Power BI experience is added advantage).\nExperience in building and maintaining reliable and scalable data pipelines\nExcellent problem-solving and analytical skills, with the ability to turn complex data into actionable insights\nHands-on experience with data security and privacy best practices\nExcellent communication and collaboration skills to work effectively with cross-functional teams\nCompetitive salary and performance-based bonuses\nComprehensive medical and insurance benefits\nOpportunities for career growth and professional development\nCollaborative and inclusive work culture\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Data Engineer?\nWhich of the following data analytics tools are you experienced with?","205":"Rating : Rate an AI generated response based on given criteria, and provide justification.\u00a0\nPrompt writing : Create a prompt following the instruction given.\nResponse writing : Create a model response for a given prompt\nWhich of the following languages are you fluent in?\nHow would you rate your English language skills?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","206":"Design and implement generative and analytical AI projects.\nAnalyze complex data sets to identify patterns, trends, and insights.\nCollaborate with cross-functional teams to integrate AI solutions across various applications.\nConduct research to remain at the forefront of advancements in AI technologies.\nProven expertise in AI development and deployment.\nStrong background in data feature analysis and machine learning algorithms.\nExperience with large datasets, developing models that yield actionable insights.\nProficiency in AI-related programming languages and tools, including Python, TensorFlow, and PyTorch.\nDegree or higher in Computer Science, Data Science, or a related field.\nWhich of the following statements best describes your right to work in Malaysia?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as an Algorithm Engineer?\nHave you worked in a role which requires experience with machine learning?\nWhich of the following languages are you fluent in?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","207":" \nAnalyze and interpret complex data, transforming it into actionable insights that can drive informed decision-making within organization.\u00a0\n \nInvolves in schema and architecture design, developing data pipelines, ensuring data quality, and using effective tools to extract meaningful patterns and trends from large datasets.\u00a0\n\n\n \nClearly communicate technical concepts and data insights to both technical and non-technical audiences, provide valuable information that helps to improve business strategies and outcomes.\n\n\n \nData Analysis: Analyzing large datasets to conduct in-depth data analysis to extract and derive meaningful insights and trends.\u00a0\n \nData Visualization: Creating clear and effective visualizations to communicate insights with business teams.\u00a0\n\n\n \nCreate metadata for datasets to facilitate data discovery and understanding by users.\u00a0\n\n\n \nCollaborate with business teams or management teams to establish business needs by recommending solutions and delivering insights to increase productivity.\u00a0\n\n\n \nCoordinate with cross-functional teams and stakeholders to understand business requirements, design and implement data products, and monitor outcomes to provide additional value to the organization.\u00a0\n\n\n \nDevelop and implement strategies to enhance data reliability and source ability.\u00a0\n\n\n \nA min. of 0-3 years experience (banking & insurance experience is a plus)\u00a0\n\n\n \nKnowledge of relational databases and a good command of SQL\u00a0\n\n\n \nUnderstanding of basic data pipeline design, including data extraction, transformation, and loading processes.\u00a0\n\n\n \nStrong analytical and problem-solving skills.\n\n\n \nProficiency in programming languages:\u202fSAS, Python,\u202fSQL etc.\u00a0\n\n\n \nBig Data Technologies:\u202fHands-on experience with Hadoop,\u202fSpark or similar technologies for large-scale data processing.\u00a0\n\n\n \nData Quality and Testing:\u202fUnderstanding of data quality checks,\u202fmonitoring,\u202fand testing procedures.\u00a0\n\n\n \nBasic knowledge of data visualization tools (e.g. Tableau, Power BI).\u00a0\n\n\n \nUnderstanding of statistical analysis, machine learning concepts, modeling conceptual ideas and database management.\u00a0\n\n","208":"Understand business processes deeply, identify opportunities where data science can add value, and solve problems using advanced statistical analyses or machine learning techniques as necessary, including prescriptive analytics and predictive modelling\nInitiate, design and lead projects to maximise business impact with the right data driven solution across business functions, including pricing and inventory (e.g. price prediction and optimization), operations (e.g. computer vision automation), customer conversion (e.g. recommendation and personalisation engine), etc.\nResponsible for ensuring successful end-to-end delivery and maintenance of machine learning, data science and AI initiatives, including measurement of model performance in action and monitoring for drifts over time\nWork with MLOps engineers in developing machine learning pipelines to streamline and automate the deployment of models. Ensure timely high standard delivery of output and documentation\nDesign and execute experiments iteratively to improve the performance of data science solutions deployed\nPropose framework and drive hypothesis validation, ensuring statistically sound decision making from proper A\/B test setups whenever feasible\nWork with Product & Tech teams across organisations to enhance data collection process as necessary\nInnately curious, highly analytical and enjoy distilling complex business problems into technical requirements and find answers in the data\nAt least 3 years of practical experience in data science, advanced business analytics, machine learning, AI or computer vision\nExperience in the complete modelling lifecycle, from ideation to deployment and continual monitoring and maintenance\nProficient in Python and\/or R. Preferably Python\nComfortable using SQL for data exploration, and analysis. Preferably familiar with Google BigQuery or similar\nResult-oriented and resourceful. You can cut to the core of a problem, identify what needs to be done, and work with the teams to make things happen\nConstructive communication of ideas, issues, and solutions in a team environment\nSelf-starter who is extremely motivated to continue learning and growing, able to pick up new skills quickly\nExperience in MLOps framework, cloud services by AWS\/ GCP, Tensorflow\/ Pytorch will be an advantage.\nExperience in the automotive or e-commerce industry\nExperience working at a tech startup or fast-growing organisation\nExperience in computer vision or AI research\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a data scientist?\nWhich of the following programming languages are you experienced in?\nHow many years' experience do you have using SQL queries?\nHave you worked in a role which requires experience with machine learning?","209":"\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","210":"\n\nExplore and path-find solutions to complex business problems, coordinate concept proving and pilot testing. Works closely with business stakeholder, observations to find patterns and relationships in data.\n\n\nInteracts with users and users leadership to define requirements and plans for breakthrough product\/solutions. In either research environments or specific product environments, utilizes current programming methodologies to translate machine learning models and data processing methods into software.\n\n\nBuilds machine learning workflows and infrastructure necessary to productize AI platforms, self-service AI solutions, or AI models and sustain them in production.\n\n\nResponsible for preparing data for ML models at scale, building appropriate inference interfaces for ML model consumption, enabling ML Ops for continuous delivery and automation of ML pipelines, and\/or building and sustaining AI production platforms.\n\n\nEnable MLOps for scaled\/POR integration, deployment, adoption and support.\n\n\n\n\nCandidate must have at least 5+ years of working experience.\n\n\nHas degree in Computer Science, Mathematics, Machine Learning, Al, Optimization, Operation Research, Statistics or equivalent.\n\n\nIndependent and self-driven individuals with a must have deep knowledge in machine learning algorithms and applying to solve problems in various disciplines. Deep expertise in Python, Tensorflow, Large Language Model, CNVRG, ELK, Kubernetes, KubeFlow, Scripting, SQL queries, and related software.\n\n\nAbility to build data ingestion libraries from heterogeneous data sources including Postgres SQL, MS SQL, Excel, Oracle, Json, Teradata, etc.\n\n\nExperience in AI or software solution architecture design, and development will be an added advantage.\n\n\nSkilled in programming, testing, debugging, documentation and\/or deployment of the solution\/products.\n\n\nHave strong understanding of manufacturing business segment stakeholders and possess strong written and communication skills. Project\/program management experience will have an added advantage.\n\n\nCuriosity and endless desire to learn, along with passion for solving intricate business problems using data science\n\n\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","211":"Work closely with our IT team to identify issues and use data to propose solutions for effective decision-making.\nAssess the effectiveness of data sources and data-gathering techniques and improve data collection methods.\nBuild algorithms and design experiments to merge, manage, interrogate and extract data to supply quality data for machine learning.\nUse machine learning tools and statistical techniques to produce solutions to problems.\nTest data mining models to select the most appropriate ones for use on a project.\nMaintain clear and coherent communication, both verbal and written, to understand data needs and report results.\nHorizon scan to stay up to date with the latest technology, techniques and methods.\nConduct research from which you'll develop prototypes and proof of concepts.\nExploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real world\nSupervising the data acquisition process. Establish new systems and processes and look for opportunities to improve the flow of data\nLook for opportunities to use insights\/datasets\/code\/models across other functions to provide strategic solutions\nStay curious and enthusiastic about using algorithms to solve problems and enthuse others to see the benefit of your work.\nStrong interest in latest Machine Learning Research\nExperience with Azure, AWS or Google Cloud\nExperience with computer vision, object detection and\/or multi-object tracking\nStrong analytical and problem-solving skills.\nExcellent interpersonal and communication skills.\nBachelor\u2019s degree in Data Science \/ Computer science \/ Information Technology or a related subject and\/or equivalent formal training or work experience.\nCareer growth & learning opportunities\nOutpatient, dental & optical, medical insurance\nSpecial leaves\nLong established company with headquarters in Shanghai & Hong Kong\nWhich of the following types of qualifications do you have?\nHave you worked in a role which requires experience with machine learning?","212":"Problem-solving and analytical understanding for statistics and data.\u00a0\nTechnical skills and competency in using data analytics software like Excel, Salesforce, others.\u00a0\nContinuously strive for ways to improve operational efficiency, develop reports, and maintain spreadsheets\/data metrics to monitor, track, and evaluate performance.\nSupport and provide technical assistance for inquiries and issues.\nOppo conversion knowledge will be added advantage.\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","213":"Analyze customer data to identify trends, patterns, and opportunities.\u00a0\nDevelop insights to guide customer acquisition, retention, and engagement strategies.\u00a0\nAlign data analysis with departmental objectives to support business growth.\u00a0\nDesign and develop analytical modules that streamline data processing and reporting for sales and campaign performances.\u00a0\nCollaborate with Tech team to implement and maintain these modules.\u00a0\nEnsure scalability and adaptability of modules for various business applications.\u00a0\u00a0\nExtract data from various sources including database, APIs and flat files.\u00a0\nCreate compelling data visualizations that communicate key insights effectively.\u00a0\nUtilize platforms such as Qlik Sense , Tableau, Power BI, Excel or similar tools to develop dashboards and reports.\u00a0\nContinuously refine visualization techniques for clarity and impact to all business units.\u00a0\nGenerate reports and presentations that summarizes key findings and suggests recommendations.\u00a0\nSupport strategic planning with data-driven insights and forecasts.\u00a0\nMonitor and report on KPIs to assess the effectiveness of customer strategies.\u00a0\nEnsure the integrity and security of data by following company\u2019s policies with regular check and audits.\u00a0\nMaintain comprehensive records and documentation on data sources, data processes, findings, assumptions.\u00a0\u00a0\nWork closely with cross-functional teams, including Operations, Digital Asset, Technology, and Product.\u00a0\nCommunicate complex data findings clearly to both technical and non-technical stakeholders.\u00a0\nProvide training and support on data analysis tools and best practices.\u00a0\nCollaborate with regional teams to understand customer needs, market trends, and the rollout of new technologies and services, providing strategic and tactical product recommendations with active discussions.\u00a0\nMaintain a close working relationship with HOD and team members plus other business unit stakeholders on all matters pertaining to, including but not limited to execution and reporting of the company\u2019s customer acquisition campaign.\u00a0\nExecutes departmental tasks and achieve targets set on departmental key result areas (KRAs) and key performance indexes (KPIs) with productive participation and support.\u00a0\nStay updated with the latest trends in data analysis, visualization, and customer strategy.\u00a0\nSeek continuous improvement in processes, tools, and methodologies.\u00a0\nParticipate in professional development to enhance skills and knowledge.\u00a0\nFollow the Company's code of conduct, policies, procedures, and lawful directions related to employment and duties.\u00a0\nPerform any additional tasks as directed by management from time to time.\u00a0\n3+ years of experience in data analysis, preferably in a customer-centric or strategic role.\u00a0\nStrong experience with data visualization tools (e.g., Qlik Sense, Tableau, Power BI).\u00a0\nProficiency in data analytic tools such as SQL, Python, R, or similar.\u00a0\nKnowledge of statistical analysis and predictive modelling techniques.\u00a0\nFamiliarity with CRM systems and customer data is an advantage.\u00a0","214":"Analyse Data:\n Extract insights from large datasets to inform business strategies\nDevelop Models:\n Create predictive models for risk assessments, customer behaviour, fraud detection, etc\nEnhance Personalization:\n Build algorithms to tailor insurance products to individual needs\nCollaboration: \nWork directly with cross- functional teams (Business and IT)\nAdvanced Python and SQL skills. \u00a0Python packages such as NumPy, pandas, matplotlib, scikit-learn, etc.\nCloud environment in either AWS or GCP\nSolid experience in GenAI and\/or MLOps is an advantage\n4+ years in data science\/ machine engineering working experience\nEducation in mathematics, statistics, data science or equivalent\nProven experience in handling end to end data science projects\nCollaborative and think outside of the box mindset\nLanguage in written and spoken English\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a data scientist?\nWhich of the following programming languages are you experienced in?\nDo you have experience with multi-variate and A\/B testing methodologies?","215":"Which of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","216":"End-to-end delivery of data analytics projects including project framework, analysis technique and implementation of data science models\nAnalyse and interpret large volume and complex datasets to extract insights, trends, and patterns, helping organizations make data-driven decisions.\nIntegrate external factor and global context into analytical models to enhance predictive accuracy and provide a broader context for decision making.\nApply various data science technologies: statistical analysis, machine learning and pattern recognition with subject-specific modelling to address opportunities in business performance and achieve supply chain efficiencies.\nDesign experiments and statistical tests to validate hypotheses.\nPresent findings to non-technical stakeholders in a clear and understandable manner\nA bachelor's degree in a quantitative field such as Data Science, Statistics, Mathematics, Physics, or related fields, with a \nminimum of 5 working years of experience.\nStrong background in statistics and probability theory is essential for analyzing and interpreting complex data.\nProficiency in programming languages commonly used in data science, such as Python or R. Familiarity with tools like SQL for database querying is also valuable.\nUnderstanding and practical experience with machine learning techniques and algorithms. This includes supervised and unsupervised learning, regression, classification, clustering, and more.\nAbility to create meaningful visualizations to communicate complex findings effectively. Familiarity with tools like Matplotlib, Seaborn, or Tableau can be beneficial.\nStrong communication skills to explain complex technical findings to non-technical stakeholders and decision-makers.\nHaving supply chain knowledge will be an added advantage.\nHow many years' experience do you have as a data scientist?\nDo you have a Bachelor Degree?","217":"Model Development:\n Design and implement AI models, such as LSTM, transformer-based architectures (LLaMA, GPT, etc.), or other relevant machine learning algorithms, tailored to trading systems and market analysis.\nAlgorithm Development:\n Implement and optimize algorithms that improve the speed and accuracy of trade decisions, focusing on high-performance, real-time models that can be deployed in production environments.\nData Analysis:\n Preprocess and analyze financial data, including historical market data, technical indicators, and other data sources to develop features and training datasets for AI models.\nTrade Decision Enhancement:\n Build models that assist in predicting market trends, identifying trading opportunities, and optimizing trade execution strategies, focusing on improving decision accuracy.\nBacktesting and Evaluation:\n Conduct backtesting of AI models using historical data, and continuously refine models based on performance metrics. Use tools like precision, recall, and confusion matrices to ensure model robustness.\nCollaboration with Trading Team:\n Work closely with traders and engineers to understand trading strategies and ensure seamless integration of AI solutions with the trading algorithms and systems.\nOptimization:\n Fine-tune and optimize models to ensure they are computationally efficient, accurate, and scalable to handle real-time data and decision-making processes.\nContinuous Learning:\n Stay updated with advancements in AI, machine learning, and financial technology, and incorporate cutting-edge techniques into the model development process.\nDocumentation:\n Maintain comprehensive documentation for AI models, data pipelines, and integration processes, ensuring clarity and reproducibility.\nEducational Background:\n Bachelor\u2019s Degree in Computer Science, Data Science, AI\/ML Engineering, or a related field (or equivalent work experience).\nExperience:\n Minimum of 2 years of experience working in AI\/ML model development, with hands-on experience in LSTM, transformers, or other deep learning architectures.\nTechnical Skills:\nProficiency in Python and machine learning frameworks such as TensorFlow, PyTorch, or Keras.\nExperience with \ntime-series analysis\n and \nsequence modeling\n (e.g., LSTM, GRU).\nFamiliarity with transformer-based models (e.g., \nLLaMA, GPT\n), and their applications in trade decision analysis.\nStrong knowledge of \ndata preprocessing\n, feature engineering, and model evaluation techniques.\nExperience with \nfinancial market data\n and \ntrading algorithms\n is a plus.\nFamiliarity with cloud platforms (AWS, GCP, etc.) for training and deploying AI models.\nProficiency in working with large datasets and database technologies (SQL, NoSQL).\nProficiency in Python and machine learning frameworks such as TensorFlow, PyTorch, or Keras.\nExperience with \ntime-series analysis\n and \nsequence modeling\n (e.g., LSTM, GRU).\nFamiliarity with transformer-based models (e.g., \nLLaMA, GPT\n), and their applications in trade decision analysis.\nStrong knowledge of \ndata preprocessing\n, feature engineering, and model evaluation techniques.\nExperience with \nfinancial market data\n and \ntrading algorithms\n is a plus.\nFamiliarity with cloud platforms (AWS, GCP, etc.) for training and deploying AI models.\nProficiency in working with large datasets and database technologies (SQL, NoSQL).\nAdditional Skills:\nUnderstanding of financial markets, technical analysis, and trading strategies.\nStrong mathematical and statistical foundation in probability, time-series modeling, and optimization techniques.\nExperience with tools for data visualization and performance tracking (e.g., Matplotlib, Plotly, MLFlow).\nKnowledge of \nmachine learning lifecycle management\n and MLOps practices.\nUnderstanding of financial markets, technical analysis, and trading strategies.\nStrong mathematical and statistical foundation in probability, time-series modeling, and optimization techniques.\nExperience with tools for data visualization and performance tracking (e.g., Matplotlib, Plotly, MLFlow).\nKnowledge of \nmachine learning lifecycle management\n and MLOps practices.\nStrong analytical and problem-solving skills, with the ability to work independently and deliver results.\nAbility to collaborate effectively with cross-functional teams, including traders, developers, and data engineers.\nA passion for learning new AI techniques and applying them to real-world financial problems.\nGood communication skills, with the ability to explain complex technical concepts to non-technical stakeholders.\nAttention to detail and a proactive attitude toward model refinement and improvement.\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as an Artificial Intelligence Engineer?\nWhich of the following programming languages are you experienced in?\nHave you worked in a role which requires experience with machine learning?\nHow many years' experience do you have using SQL queries?\nWhich of the following Relational Database Management Systems (RDBMS) are you experienced with?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","218":"Forming clear data addressable problem statements from current business problems\nResearch, build, deploy and maintain RecommendationsAI solutions integrated with recruitment products aiming to properly connect candidates to recruiters\nImprove the chances of matching (job placements) to leverage our AI platform to the next level\nCollaborate with Strategy, Product, Data Science and Software Development teams to address a variety of challenging business problems\nLead the formulation, development, deployment, and testing of new solutions\nExplore new methodologies and technologies to address R&D problems in a truly collaborative way\nA Bachelor, MSc or PhD qualification in Computer Science, Computational Physics, Mathematics, Statistics or a related field\nProfessional experience in one of the following programming languages:\nLarge scale development using Python, Go, C\/C++, or Java\nAbility to perform data exploratory analysis for proof of concepts and to communicate the results to a diverse audience\nGood communication and interpersonal skills\nLarge scale development using Python, Go, C\/C++, or Java\nStrong background in:\nAlgorithms and data structures\nInformation Retrieval\nMachine Learning\nPractice with\nSearch engine such as Elasticsearch or SOLR;\nRelational database such as MySQL or PostgreSQL;\nAmazon Web Services (e.g. EC2, ELB, S3, VPC, Route 53);\nDistributed processing framework such as Hadoop or Spark;\nContainer package such as Docker;\nKnowledge in:\nRecommender Systems\nData Mining\nNatural Language Processing\nOptimization\nDeep Learning\nAbility to adapt quickly and manage an environment of rapid change and development\nAlgorithms and data structures\nInformation Retrieval\nMachine Learning\nSearch engine such as Elasticsearch or SOLR;\nRelational database such as MySQL or PostgreSQL;\nAmazon Web Services (e.g. EC2, ELB, S3, VPC, Route 53);\nDistributed processing framework such as Hadoop or Spark;\nContainer package such as Docker;\nRecommender Systems\nData Mining\nNatural Language Processing\nOptimization\nDeep Learning\nAbility to adapt quickly and manage an environment of rapid change and development\nMature and collaborative work culture and environment\nHybrid work mode\nExtended employee benefits","219":"Work with stakeholders to define the scope, requirements, processes and procedures to ensure the success of artificial intelligence and machine learning (AI\/ML) projects.\nCreate and deliver data-driven solutions that add business value using statistical models, machine learning algorithms, data mining and visualization techniques.\nCollect, organize and analyze large complex, structured\/unstructured, diverse big data.\nDevelop scripts to automate processes to cleanse, integrate and evaluate large datasets from disparate data sources.\nIdentify data trends, patterns and insights through statistical analysis and machine learning techniques.\nDesign, develop and implement statistical models and machine learning algorithms.\nDevelop predictive models to solve complex business problems.\nContinuously evaluate and improve the performance of existing models and algorithms.\nMaster or Bachelor Degree in Computer Science, Data Science, Mathematics, Statistics\/Operations Research or related qualification.\nProven work experience as a Data Scientist\/Data Analyst or similar role.\nProficient in Python programming and SQL languages.\nProficient in open-source software libraries for machine learning and artificial intelligence such as TensorFlow and Keras, open-source message broker software such as RabbitMQ, distributed event store and stream-processing platform such as Apache Kafka.\nProficient in Apache HBase open-source non-relational distributed database and Apache Hadoop Distributed File System (HDFS).\nExperience with data visualization tools such as Power BI, QlikView or Splunk.\nStay up-to-date with the latest advancements in data science, artificial intelligence and machine learning.\nDetailed, strong technical and analytical skills.\nGood communication, decision making and presentation skills.","220":"Which of the following languages are you fluent in?\nHow would you rate your English language skills?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","221":"Responsible for requirement study, testing, deployment, and support\/enhancement of in-house systems, mobile applications, and reporting.\nWork closely with the helpdesk functional team, peers, and business users on system requirement studies and issue clarification.\nAssist in solution architecture, application design, and database design based on task requirements.\nManage developers in designing and developing architecture for data warehousing components (e.g., tool integration strategy, data staging, movement and aggregation, information and analytics delivery, and data quality strategy).\nDesign and implement standard reporting and dashboards using SSIS, SSAS, SSRS, Microsoft SQL stored procedures, and Microsoft Excel Pivot.\nPerform technical specification writing and documentation.\nExhibit strong collaboration and communication skills, a positive attitude, and take responsibility for assigned tasks.\nWork independently, be detail-oriented, and demonstrate strong problem-solving skills.\nWork on bug fixes and fine-tune application performance.\nBe a fast learner and capable of working in a fast-paced environment with tight deadlines.\nBachelor's degree in a related field.\nA minimum of 5 years of experience in web and software development.\nExperience in the retail industry is an added advantage.\nDemonstrated knowledge of web\/mobile languages\/technologies such as JavaScript, ASP.NET, HTML, CSS, PHP, AngularJS, Node.js, MVC, jQuery, AJAX, Bootstrap, etc.\nDemonstrated knowledge of backend languages\/technologies such as C#, MS SQL Server, MySQL, web services, VBA, etc.\nDemonstrated knowledge of software components and third-party programs, such as API (JSON, REST, XML).\nDemonstrated knowledge of source control management, such as GitHub.\nExperience with Windows Server and Linux.\nOpportunity to work with a leading cosmetics retailer, gaining experience in a fast-paced, dynamic industry.\nExposure to a diverse range of international and local beauty brands.\nAccess to professional development within a large, well-established company.\nBe part of a collaborative, innovative team focused on delivering exceptional customer experiences.\nBenefit from growth opportunities in both e-commerce and physical retail sectors.","222":"AI Strategy & Leadership:\n Take full ownership of the AI roadmap for trade decision analysis, defining the model architecture, training, and evaluation methodologies. Lead the team\u2019s AI efforts and independently drive technical direction.\nAdvanced Model Development:\n Design and build state-of-the-art machine learning models, including \nLSTM\n, \ntransformer-based models\n (e.g., \nLLaMA\n, \nGPT\n), or other relevant architectures to analyze time-series data and predict market movements.\nAlgorithm Development:\n Implement and optimize algorithms that improve the speed and accuracy of trade decisions, focusing on high-performance, real-time models that can be deployed in production environments.\nEnd-to-End Model Lifecycle:\n Own the end-to-end development cycle for AI models, including \ndata preprocessing\n, model training, validation, testing, and deployment. Ensure models are production-ready and robust under varying market conditions.\nBacktesting & Performance Evaluation:\n Perform extensive backtesting of AI models using historical market data, develop benchmarks, and continually refine models for improved performance. Lead model tuning for accuracy, speed, and reliability.\nIntegration with Trading Systems:\n Collaborate closely with trading and engineering teams to ensure that AI models seamlessly integrate into the trading platform. Provide technical expertise to align models with existing trade execution frameworks.\nScalability & Optimization:\n Build scalable AI solutions capable of handling high-frequency data streams and vast amounts of market data. Ensure the efficiency of AI models in real-time systems with minimal latency.\nAI Infrastructure & MLOps:\n Establish and maintain AI pipelines, automation, and infrastructure for model training, testing, deployment, and monitoring. Lead efforts in \nMLOps\n to optimize model lifecycles.\nResearch & Innovation:\n Keep up with the latest research in AI, machine learning, and financial modeling. Innovate by applying cutting-edge techniques, including transfer learning, reinforcement learning, or other novel AI approaches.\nTechnical Leadership:\n Provide mentorship and technical guidance to junior and intermediate AI engineers. Lead code reviews, contribute to defining coding standards, and ensure best practices across the AI team.\nDocumentation & Standards:\n Create comprehensive technical documentation and ensure that AI systems are built following industry standards for maintainability and scalability.\nEducational Background:\n Master\u2019s or Ph.D. in Computer Science, Data Science, AI\/ML Engineering, or related fields, or equivalent work experience.\nExperience:\n Minimum of 5 years of hands-on experience in AI\/ML development, with a strong track record of deploying models in production. Proven experience in time-series forecasting and financial market applications is a plus.\nTechnical Skills:\nExpertise in \nmachine learning frameworks\n like \nTensorFlow\n, \nPyTorch\n, or \nKeras\n.\nStrong proficiency in \nLSTM\n, \nGRU\n, and \ntransformer-based models\n (e.g., \nLLaMA\n, \nBERT\n, \nGPT\n).\nSolid experience in \ntime-series analysis\n, feature engineering, and building prediction models for financial data.\nDeep understanding of \ntrading systems\n, market microstructure, and execution algorithms.\nExperience with \ncloud platforms\n (e.g., AWS, GCP) and distributed computing to train large-scale models.\nProficiency in building \nreal-time machine learning pipelines\n, handling streaming data, and ensuring low-latency responses.\nExperience in \nbacktesting\n, hyperparameter tuning, and model optimization for high accuracy.\nProficiency in \nMLOps\n tools for model lifecycle management (e.g., MLFlow, Kubeflow).\nStrong skills in \nSQL\n, \nNoSQL\n, and managing large datasets.\nExpertise in \nmachine learning frameworks\n like \nTensorFlow\n, \nPyTorch\n, or \nKeras\n.\nStrong proficiency in \nLSTM\n, \nGRU\n, and \ntransformer-based models\n (e.g., \nLLaMA\n, \nBERT\n, \nGPT\n).\nSolid experience in \ntime-series analysis\n, feature engineering, and building prediction models for financial data.\nDeep understanding of \ntrading systems\n, market microstructure, and execution algorithms.\nExperience with \ncloud platforms\n (e.g., AWS, GCP) and distributed computing to train large-scale models.\nProficiency in building \nreal-time machine learning pipelines\n, handling streaming data, and ensuring low-latency responses.\nExperience in \nbacktesting\n, hyperparameter tuning, and model optimization for high accuracy.\nProficiency in \nMLOps\n tools for model lifecycle management (e.g., MLFlow, Kubeflow).\nStrong skills in \nSQL\n, \nNoSQL\n, and managing large datasets.\nAdditional Skills:\nExpertise in \nfinancial markets\n, \nalgorithmic trading\n, and developing AI solutions for real-time decision-making.\nFamiliarity with \nreinforcement learning\n, \ndeep learning\n, and \ntransfer learning\n for financial applications.\nExperience with \ndistributed computing frameworks\n (e.g., Spark, Dask) to process large-scale datasets.\nKnowledge of \ndata visualization\n tools and methods for presenting insights and model performance.\nExpertise in \nfinancial markets\n, \nalgorithmic trading\n, and developing AI solutions for real-time decision-making.\nFamiliarity with \nreinforcement learning\n, \ndeep learning\n, and \ntransfer learning\n for financial applications.\nExperience with \ndistributed computing frameworks\n (e.g., Spark, Dask) to process large-scale datasets.\nKnowledge of \ndata visualization\n tools and methods for presenting insights and model performance.\nStrong leadership and \ntechnical mentorship\n skills, with a proven ability to drive projects from ideation to deployment.\nExcellent problem-solving skills, with a track record of resolving complex AI and data science challenges.\nAbility to work independently, make informed technical decisions, and take ownership of large-scale AI projects.\nStrong communication skills, with the ability to explain complex AI concepts to non-technical stakeholders.\nA passion for continuously improving AI systems and staying ahead of the curve in new AI\/ML techniques.\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as an Artificial Intelligence Engineer?\nHow many years' experience do you have using SQL queries?\nHave you worked in a role which requires experience with machine learning?\nWhich of the following programming languages are you experienced in?\nWhich of the following Relational Database Management Systems (RDBMS) are you experienced with?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","223":"\n\nLead the business analysis function, contributing to the development of data-driven strategies. \n\n\nImplement and share innovative ideas for data utilization and analysis. \n\n\nTake a proactive approach in identifying opportunities for data-driven improvements. \n\n\nShowcase advanced proficiency in Excel or Google sheet formulas for detailed business analysis and modeling. \n\n\nUtilize Excel for in-depth insights into complex datasets. \n\n\nDevelop and implement interactive dashboards for effective data communication. \n\n\nApply experience and knowledge in analyzing call center, customer services, sales, or telemarketing data. \n\n\nProvide actionable insights to improve performance and efficiency. \n\n\nImplement and maintain data governance practices to ensure data accuracy and integrity. \n\n\nCollaborate with cross-functional teams to streamline data processes. \n\n\nCollaborate effectively with teams to understand data needs and requirements. \n\n\nCommunicate complex data insights in a clear and accessible manner. \n\n\nStay updated on industry trends, emerging technologies, and best practices in business analysis. \n\n\nProactively integrate new tools and methodologies for improved business analysis.\n\n\n\n\nBachelor's degree in Data Science, Data Analysis, Business Analysis Statistics, Computer Science, Business Administration or a related field (fresh graduates are welcomed). \n\n\nGood proficiency in \nExcel Analysis\n or other \nData analysis tools\n. \n\n\nAbility to speak in Mandarin is highly preferred to deal with Chinese stakeholders. \n\n\nExperience in call center, customer services, sales, or telemarketing analysis is highly preferred. \n\n\nExperience with programming languages and \nBI Tools\n such as Python, R, Power BI, Tableau is added advantage.\n\n\nWhat is your expected monthly basic salary (RM) ?\nWhat is the notice period required by your current employer? (Months)\nList down the data analytics tools you are experienced with. \n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","224":"\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","225":"Responsible for requirement study, testing, deployment, and support\/enhancement of the in-house systems, mobile applications, and reporting.\nWork closely with the helpdesk functional team, peers, and business users on system requirement studies and issue clarification.\nAssist in solution architecture, application design, and database design based on task requirements.\nManage developers in designing and developing the architecture for data warehousing components (e.g., tool integration strategy, data staging, movement and aggregation, information and analytics delivery, and data quality strategy).\nDesign and implement standard reporting and dashboards using SSIS, SSAS, SSRS, Microsoft SQL stored procedures, and Microsoft Excel Pivot.\nPerform technical specification writing and documentation.\nExhibit good collaboration and communication skills, a positive attitude, and responsibility for assigned tasks.\nWork independently, be detail-oriented, and possess strong problem-solving skills.\nWork on bug fixing and fine-tuning application performance.\nBe a fast learner and able to work in a fast-paced environment with tight deadlines.\nBachelor\u2019s degree in a related field.\nMinimum of 5 years of experience in web and software development.\nWorking experience in the retail industry is an added advantage.\nDemonstrated knowledge of web\/mobile languages\/technologies, such as JavaScript, ASP.NET, HTML, CSS, PHP, Angular JS, Node.js, MVC, jQuery, AJAX, Bootstrap, etc.\nDemonstrated knowledge of backend languages\/technologies, such as C#, MS SQL Server, MySQL, web services, VBA, etc.\nDemonstrated knowledge of software components and third-party programs such as API (JSON, REST, XML).\nDemonstrated knowledge of source control management such as GitHub.\nExperience with Windows Server and Linux.\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a systems analyst?\nWhich of the following programming languages are you experienced in?","226":"\n\nDesign and implement generative and analytical AI projects.\n\n\nAnalyze complex data sets to identify patterns, trends, and insights.\n\n\nCollaborate with cross-functional teams to integrate AI solutions across various applications.\n\n\nConduct research to remain at the forefront of advancements in AI technologies.\n\n\n\n\nProven expertise in AI development and deployment.\n\n\nStrong background in data feature analysis and machine learning algorithms.\n\n\nExperience with large datasets, developing models that yield actionable insights.\n\n\nProficiency in AI-related programming languages and tools, including Python, TensorFlow, and PyTorch.\n\n\nMaster\u2019s degree or higher in Computer Science, Data Science, or a related field.\nRelevant experience in Computer Science, Data Science, or a similar discipline.\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","227":"Which of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following languages are you fluent in?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","228":"What's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Data Engineer?\nHow many years' experience do you have using SQL queries?\nWhich of the following programming languages are you experienced in?\nWhich of the following data analytics tools are you experienced with?\nHow many years' experience do you have in a DevOps role?","229":"Implement, troubleshoot, and test data products and services using standard techniques and tools.\nHelp building data solutions which are scalable, resilient, and future proof.\nUnderstand typical problems in databases, data processes, data products and services. You understand and can apply typical solutions to those problems.\nImplement, troubleshoot, and test pipelines, Web APIs, services, or scripts.\nWork in an Agile and cross-functional team\nDegree in Computer Science, Information Technology or a related field\n1-2 years of experience in data engineering or a similar role\nAgile methodologies. You know about agile methodologies and the ways you can apply the principles in practice. You can take an open-minded approach; you know why iteration is important. You know how agile processes can be used to validate ideas with users.\nData development process. You can design, build and test data products based on feeds from multiple systems using a range of different data exchange, storage and access technologies. You can create testable, repeatable and reusable products.\nData technology. You can apply data models using database technology. You understand and apply appropriate data design principles to achieve performant and secure databases. You are aware of general trends in data technology.\nTechnical understanding (data engineering). You understand core technical concepts like data normalisation, modelling, performance of data intensive solutions. You understand basic software development concepts.\nGood command of written and spoken English and Chinese; Cantonese is an advantage\nCompetitive salary and performance-based bonuses\nComprehensive health and wellness benefits\nOpportunities for professional development and career growth\nFlexible work arrangements and a dynamic, collaborative work culture\nTeam-building activities and social events to foster connections\nWhich of the following statements best describes your right to work in Malaysia?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Data Engineer?\nHow many years' experience do you have working in an agile environment?","230":"Create and maintain optimal data architecture\u00a0\nAssemble large, complex data sets that meet functional and non-functional business requirements\u00a0\nIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\u00a0\nBuild the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources\u00a0\nWork with stakeholders including the users, cross functional teams to assist with data-related technical issues and support their data infrastructure needs.\u00a0\nStandard process to keep data secure with right access and authorization\u00a0\nFocus on automated testing and robust monitoring\nExcellent problem solving and interpersonal communication skills\u00a0\nStrong desire to learn and share knowledge with others.\u00a0\nBe inquisitive, innovative, and a team player with a strong focus on quality workmanship.\u00a0\nTroubleshooting skills and root cause analysis for performance issues\u00a0\nAbility to lean, adopt and implement new skills to drive innovation and excellence.\u00a0\nAbility to work with cross functional teams in dynamic environment\nA bachelor's with 5+ years of experience in CS\/CE or a related field\u00a0\nExperience building and optimizing big data pipelines\u00a0\nExperience with skills pf handling unstructured data\u00a0\nExperience with data transformations, structures, metadata, workload management\u00a0\nExperience with big data tools: Spark, Kafka, NIFI. ADF etc.\u00a0\nExperience with at least programming languages: Python, C#, .NET\u00a0\nExperience with relational SQL and NOSQL DBs\u00a0\nExperience in leveraging open-source packages\u00a0\nExperience in cloud native skills such as Docker, Kubernetes, Rancher etc. Good to have skills:\u00a0\nExperience with semiconductor manufacturing\u00a0\nExperience of data engineering on cloud\u00a0\nExperience in developing AI\/ML Solutions \u00a0\nWhich of the following statements best describes your right to work in Malaysia?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Big Data Engineer?\nWhich of the following programming languages are you experienced in?\nHow many years' experience do you have using SQL queries?\nHow would you rate your English language skills?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","231":"Email Annotation\n: Annotate emails for AI filters machine learning.\nEmail Examination\n: Review various email elements, including appearance, headers, links, and attachments. Analyze online resources related to internet domain and IP address reputations to determine email categories.\nMalicious URL Identification\n: Detect and block malicious URLs and phishing attempts to protect recipients and maintain email security.\nData Labeling\n: Label a diverse pool of data, including emails, messages, and statements, for use in training and improving AI and machine learning models.\nProcess Adherence\n: Ensure all operational sections adhere to established processes and procedures to maintain consistency and quality.\nKPI Management\n: Monitor and ensure that all key performance indicators (KPIs) are met. Propose and implement initiatives or improvement plans as needed to address any shortfalls.\nProject Support\n: Assist the Project Manager with day-to-day service operations and departmental administration as required.\nCandidate must possess at least a Diploma or Advanced Diploma\nPreferably 1 year(s) & above of working experience in the related field\nAbility to work 24\/7 rotational shift, including the ability to work nights, weekends and public holidays\nExperience in IT, security or systems support, or network administrator positions will be added advantage\nFluent English in speaking and writing\nGood communication and problem-solving skills\nResponsible, meticulous and a team player\nSelf-motivated, proactive, well organized\nFresh graduates are welcome to apply\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nAre you available for shift work?\nHow many years' experience do you have in the IT industry?\nWhich of the following types of qualifications do you have?","232":"Gather and analyze customer data to map and plan the customer journey, identifying trends and patterns to optimize the CRM strategy.\nConduct A\/B testing on promotional and marketing campaigns to evaluate their effectiveness and make recommendations for improvements.\nCollaborate with stakeholders to help them make data-driven decisions that enhance customer engagement and retention strategies.\nPrepare comprehensive reports on CRM and loyalty campaign performance, providing actionable insights and recommendations for continuous improvement.\nProvide in-depth analysis of customer behavior to identify growth opportunities and improve customer journey experiences.\nFluent in written and spoken \nEnglish\n and \nMandarin\n.\nBachelor's degree in Data Science, Marketing, Business Analytics, International Business, Public Relations, or Media Studies.\u00a0\nProven experience as a Data Analyst, preferably within Sales, Customer Behavior, Business Development or Marketing.\nProficiency in data analysis tools such as \nExcel\n, \nSQL\n, and data visualization tools (e.g., Tableau, Power BI).\nStrong knowledge of A\/B testing methodologies and experience in campaign optimization.\nExcellent analytical and problem-solving skills, with the ability to present complex data in a clear and concise manner.\nStrong communication skills to effectively collaborate with stakeholders and present insights.\nHybrid Work Mode: \nWork from Home every Monday and Friday.\nAccessible Location:\n Office is within walking distance from the MRT.\nMonthly Performance Bonus: \nUp to 4 digits monetary reward, get paid for your hard work.\u00a0\nProfessional Development:\n Sponsorship for professional training and workshops.\nAnnual Leave Encashment:\n Get paid for unused leave.\nWork Assets Provided:\n All necessary work tools and equipment are supplied.\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a data analyst?\nWhich of the following data analytics tools are you experienced with?\nHow many years' experience do you have using SQL queries?\nWhich of the following languages are you fluent in?","233":"Conduct in-depth research on industry trends, competitors, and customer needs.\nIdentify operational and market opportunities and recommend actions.\nCollaborate with cross-functional teams to develop strategic growth plans.\nLead meetings and presentations to share insights and ideas.\nPrepare data reports for management\/stakeholders\/client company.\nProvide data-driven recommendations to optimize business strategies, customer acquisition, and retention.\nFocus on achieving revenue targets and business milestones.\nBachelor\u2019s degree \/ Diploma\n in Risk Management, Mathematics, Statistics, Actuarial Science, Business, Computational Science\/Information Technology, Data Science, or equivalent.\nMinimum of \n3 to 5 years\n of relevant work experience\nExperience in \nMarketing, Finance, Economics, Business\n, or related fields \nis a plus\n.\nFluency in \nEnglish \nand\n Mandarin\n is compulsory, as dealing with Mandarin-speaking clients is required.\nMust have a strong knowledge of SQL\n and relevant work experience, particularly in using SQL to initiate and manage projects.\nProficient in\n Excel VBA, Power Query, Power BI \nis a plus.\nAble to lead, influence, and motivate teams to achieve high performance.\nComfortable working in a fast-paced environment with high workloads and deadline-driven projects.\nWilling to travel overseas when required.\nHybrid Work Mode:\n Rotational, work in the office 1 week per month.\nAccessible Location:\n Office is within walking distance from the MRT.\nMonthly Performance Bonus\n: Up to 4 digits monetary reward, get paid for your hard work.\nProfessional Development:\n Sponsorship for professional training and workshops.\nAnnual Leave Encashment:\n Get paid for unused leave.\nTeam Bonding:\n Monthly team bonding activities based on your preference.\nWork Assets Provided:\n All necessary work tools and equipment are supplied.\nWhich of the following types of qualifications do you have?\nWhat's your expected monthly basic salary?\nWhich of the following statements best describes your right to work in Malaysia?\nHow many years' experience do you have as a data analyst?\nWhich of the following languages are you fluent in?\nHow many years' experience do you have using SQL queries?\nHow much notice are you required to give your current employer?\nHow many years' experience do you have as a SQL Analyst?","234":"Carry out data entry work with accurate information on daily basis.\nEnsuring data registered are valid.\nUpdate and maintain existing data as well as metadata management.\nAssist in design database structure and pipeline.\u00a0\nReport writing and demonstrate the understanding of relationships among each data.\u00a0\nDesign and prepare reports in a timely manner for different stakeholders.\nHousekeeping and maintenance of the database.\nUndertake any ad-hoc duties as assigned.\u00a0\nAt least a diploma in Computer Science\/ Data Science\/ any other related qualification that is equivalent.\nDetail oriented.\nStrong analytical mind and good communication skills.\nAble to work independently, responsible, self-motivated.\nProficient in MS Office (MS Excel, MS Word, MS Power Point), SQL, and Data Management.\nAble to complete tasks within given timelines with minimal supervision.\nExcellent interpersonal skills and able to work in fast-paced environment.\nSkills in programming language, data analytics and MS Power BI is a strong advantage.\nWilling to work on site office in Taman Melawati, WPKL.\u00a0\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nHow would you rate your English language skills?\nHow much notice are you required to give your current employer?\nWhich of the following programming languages are you experienced in?\nHow far are you willing to travel for work?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","235":"Understanding the whole company product line, function, and feature\nContact, coordinate and collect the needs of department. Analyse and propose a suitable system development plan for department head. Meet business needs and support transportation to achieve maximum efficiency and effectiveness.\u00a0\nReport, outlining the operation and progress of system development. Advise the department and supervisor correct control system development to meet demand and complete on time.\u00a0\nResearch and follow up new technologies and knowledge in the system and related business areas. And effectively apply to operation and bring maximum benefits to the company.\u00a0\nHaving a clear understanding of the business issues and using communication to help solve organizational problems and achieve organizational objective. And Turn business conceptualization into Software Solution.\u00a0\nWorking with business users to identify opportunities for improvement in business operations and processes.\u00a0\nSupporting test cycles particularly User Accept Test (UAT).\nProficiency in \nMandarin \nwould be preferrable.\u00a0\nAt least 1-2 years of related working experience would be added advantage.\u00a0\nWilling to work on \nMonday to Friday and alternative Saturdays.\u00a0\nPlus point if familiar with UAT and API.\u00a0\nUnderstand basic Excel functions: VLOOKUP, HLOOKUP, Pivot Table.\nWhat's your expected monthly basic salary?\nHow would you rate your Mandarin language skills?\nHow much notice are you required to give your current employer?","236":"Work with some of the best optimization minds in the world to contribute to the ongoing improvements of our optimization technologies and methodologies\nWork with Quintiq Business Consultants to design planning solutions that incorporate optimization\nDesigning and implementing the right optimization solution to solve our customers\u2019 puzzles\nParticipate in optimization research projects to come up with potential improvement ideas for our optimization solutions\nComes with 3-5 years of working experience\nDegree in Computer Science, Operations Research, Mathematics, or Artificial intelligence\nKnowledge of optimization techniques in operations research and artificial intelligence (linear programming, genetic algorithms, heuristic search techniques, constraint programming, etc.)\nExperience with object-oriented modeling (UML)\nHigh abstraction level and superior analytical skills\nWork for the one of the biggest software company in Europe\nGain exposure to a wide variety of industry experiences and IT technologies\nAn international work environment with brilliant colleagues around the globe\nA conducive and supportive environment for personal and career growth\nOpportunity to work on challenging projects\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","237":"Architect and design data infrastructure on cloud\nDesign and build resilient and efficient data pipelines for both batch and real-time streaming data\nAssemble and collect data sets that meet functional and non-functional business requirements\nIdentify, design & implement internal process improvements, automating manual processes optimizing data delivery, infrastructure for greater scalability\nBuild the infrastructure required for optimal extraction, transformation and loading of data from a variety of sources using SQL, APIs and cloud services technologies\nBuild tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics\nBuild tools for analytics and data team member that assist in building and optimizing the product into an innovative leader\nWork with data and analytics experts to strive for greater functionality in our data lake, systems and ML\/Feature Engineering for AI solutions\nWork with cross-functional departments to understand their data needs and requirements and build tools to assist them with their analytics tools\nAdditional responsibilities and tasks assigned by management from time to time\nMinimum 3 years of\u00a0relevant experience\nBachelor's or Master's degree in Data Science, Computer Science, Statistics, or a related field\nProficiency in programming languages such as Python, Java, or SQL\nExperience with data processing frameworks and technologies\nStrong understanding of database concepts and experience with relational\nKnowledge of data modeling and familiarity with cloud platforms and services\nExcellent problem-solving skills, attention to detail, and ability to work independently as well as part of a team\nStrong communication and interpersonal skills, with the ability to explain technical concepts to non-technical stakeholders\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Data Engineer?\nWhich of the following programming languages are you experienced in?\nHow many years' experience do you have using SQL queries?\nHave you worked in a role which requires experience with machine learning?","238":"To conduct user requirement analysis for the development\/ implementation of new systems and enhancements to existing systems.\nTo responsible for multiple platform applications design, development, testing, implementation, integration, documentation, maintenance and enhancement using multiple frameworks and languages.\nTo support & troubleshoot for Business Application System.\nImplement and follow coding standards and adhere to best practices and security guidelines.\nTo develops technical documents and handbooks to accurately represent the design and code of new applications.\nTo design and create report.\nTo plan and coordinate training for any system implementations or enhancements.\u00a0\nTo supervise, coach and train analyst programmers.\nAssess system capabilities and undertake feasibility studies that include financial considerations and timelines.\nOther ad-hoc duties.\u00a0\nCandidate must possess at least a Bachelor's Degree, Post Graduate Diploma, Professional Degree, Computer Science\/Information Technology or equivalent\n5 year(s) and above of relevant working experience\nSkills required: Java Technologies, C#, Visual Studio, Reporting Tools, HTML, CSS, jQuery, Vue.js, OOP, JDBC, jsp, servlet, Database Design Technologies with SQL Server and DB2\nExposure in ERP manufacturing environment and experience in data automation\nVariable Allowances\/Incentive (Handphone, Stay-Back\/Call-Back, Transport Allowance, etc)\nEmployee Education Assistance Program (For further studies)\nMedical & Dental Benefits\nInsurance\nFree Parking\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a systems analyst?\nHow many years' experience do you have as an Information Technology Executive?\nHow many years' experience do you have as an Analyst Manager?\nWhich of the following languages are you fluent in?","239":"Bachelor\u2019s degree in Business, Finance, Statistics, or a related field.\nProven 1 to 2 years\u2019 experience in data analysis, reporting, or a similar role.\nProficiency in data management and visualization tools (e.g., Excel, Power BI, Power Point).\nStrong analytical and problem-solving skills.\nExcellent attention to detail and accuracy.\nAbility to communicate complex data insights in a clear and concise manner.\nStrong organizational and time management skills.\nAbility to work independently and as part of a team.\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Business Analytics Executive?\nWhich of the following Microsoft Office products are you experienced with?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","240":"Develop and maintain scalable data pipelines on cloud platforms.\nImplement data validation, cleansing, transformation, and storage solutions in cloud and data lake environments.\nBuild ETL\/ELT processes to prepare datasets that empower data analysts and other users.\nDesign and implement cloud-native solutions for data ingestion, processing, and analytics.\n5+ years in Data Engineering, preferably in a vendor environment.\nExperienced with cloud data infrastructure such as Microsoft Azure, Google Cloud Platform, Amazon Web Services and Huawei Cloud.\nStrong background in Python, SQL, and big data tools like Hadoop, Spark, PySpark, and Delta Lake.\nOpen to local applicants only.\nCompetitive remuneration based on experience.\nSteep learning opportunity with leadership from an industry expert.\nExcellent career support and leadership training.","241":"Design and implement cloud solutions and CICD pipelines, build MLOps on Azure platform.\nRun code refactoring and optimization, containerization, deployment, versioning and monitoring of its quality.\u00a0\nWork with the data science team to research, develop, evaluate and optimize various models using different machine learning algorithms for problem solving or process optimisation.\u00a0\nExecute projects involving machine learning algorithm for computer vision applications using learners such as neural networks, clustering, segmentation, object detection, tracking.\u00a0\nDesign the self-running applications and software that makes use of that data and automates predictive models.\nBSc. or MSc. or Ph.D. in Mathematics, Computer Science, Data Science, Machine Learning, Artificial Intelligence or related fields provided they have a strong technical knowledge and experience in machine learning.\nExperience in design and implement Azure cloud-based solution and services.\nProficient in programming and scripting skills (Python and R).\nProficient in machine learning framework such as scikit-learn, pandas, TensorFlow or Keras.\nExperience in Geo-spatial analytical skills and GIS python library (GDAL, ArcPy, Geopandas, etc.) is a plus.\u00a0\nExcellent interpersonal skills, team player, resourceful and has strong analytical skills.\u00a0\nGood communication and written in English.\nWhich of the following statements best describes your right to work in Malaysia?\nHave you worked in a role which requires experience with machine learning?\nWhat's your expected monthly basic salary?\nHow many years' experience do you have as a Programmer?\nWhich of the following programming languages are you experienced in?\nHow much notice are you required to give your current employer?\nWhich of the following data analytics tools are you experienced with?","242":"Collaborate with various teams to understand and communicate business requirements\nDesign and build end-to-end ETL pipelines ensuring high reliability and security\nCreate and optimize data models for efficient data processing\nDevelop and maintain business data products\nStay up-to-date with the latest technologies and tools in the data engineering field\nProficient in creating and maintaining end-to-end ETL pipelines with a focus on reliability and security\nExperience with distributed computing agents such as Hive, Spark, Hadoop or Airflow\nStrong knowledge of data warehouse concepts and experience in data modeling and design is a must.\nStrong logical thinking and excellent verbal communication skills\nFluent in English, Mandarin language skills are necessary since some stakeholders are located in China\nCandidates with relevant data engineering experience will only be considered.\nKnowledge of big data architecture design, including data governance and compliance, is a plus","243":"Which of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Data Engineer?\nHow many years' experience do you have using SQL queries?\nWhich of the following programming languages are you experienced in?","244":"Define, design, build, and enhance business intelligence solutions.\nProvide 2nd level support on PDWH for Backend \/ Frontend DWH, Global PDWH, Production Data Marts, and iPRISM operations globally.\nProvide operational support for production data warehousing & BIA Solutions in the manufacturing domain.\nEnsure the Local\/Global Production Data Warehouse is running at a stable and high-performance level as per SLA.\nEnsure that systems, processes, and methodologies as specified are followed to ensure effective monitoring, control, and support of service delivery.\nDrive continuous improvement initiatives within the operations support area (e.g. automation of monitoring and internal controls) and control costs as per budget.\nSupport in the development and release of change requests.\nPromote transfer of knowledge and awareness to those in closely related areas, such as colleagues, and clients\/users.\nSupport in documentation and written procedures for routine and non-routine tasks.\nAble to work on AP & EU business hours during critical period.\nOn-call for critical operation support.\nBachelor's Degree in Computer Science \/ Information Technology or any relevant course.\nKnowledge in SQL and PL\/SQL in Oracle and know-how in MS SQL Database.\nUnderstanding of Data Warehousing \/ ETL techniques.\nGood analytical troubleshooting and problem-solving skills.\nStrong in service support operations & experienced in ticketing tracking systems.\nGood communication skills and a proactive team player.\nAble to work independently with minimal supervision.\nExperienced in data warehousing projects is an added advantage.\nFamiliar with business processes in the Semiconductor manufacturing industry.\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","245":"Which of the following statements best describes your right to work in Malaysia?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Data Engineer?\nHow many years' experience do you have using SQL queries?\nWhich of the following programming languages are you experienced in?\nWhich of the following Relational Database Management Systems (RDBMS) are you experienced with?","246":"Support root cause analysis to identify underlying operational issues addressable by system solutions.\nIdentify potential requirements for system design and explore new system capabilities to meet business needs.\nTranslate system capabilities into innovative solutions and lead technical solutioning for small projects with low complexity.\nUnderstand business requirements and application capabilities, managing low complexity change requests (CRs) and application enhancements to realize business needs.\nConduct thorough root cause analysis to understand requirement problem statements and propose appropriate system solutions.\nEvaluate and define potential requirements for systems design, ensuring documented requirements include associated metrics and testing procedures.\nPropose solution options and workarounds to meet business expectations while considering cost implications.\nManage CR delivery according to established processes, governing individual CR solutions and timelines.\nChampion a \"Shift Left\" mindset through the CR process, ensuring prompt tracking and updates in JIRA.\nCollaborate effectively with business stakeholders, product managers\/owners, vendors, and internal team members to prioritize and deliver against agreed-upon objectives.\nUndertake any other duties\/functions as assigned by SA Leadership.\nDegree in Computer Science \/ IT \/ Electrical & Electronic \/ Telecommunication or equivalent\nMinimum 3-4 years of relevant working experience in Telco Area\nStrong understanding of system boundaries, interfaces, and business context for frequently used applications.\nAbility to support and guide business in requirement review processes and document requirements effectively.\nProficiency in designing and developing ISD architecture solutions to support business agendas.\nAptitude for combining established methodologies with innovative techniques to address business challenges effectively.\nSkill in integrating end-user needs, technical possibilities, and business requirements to solve basic to slightly complex problems.\nExperience in leveraging established governance mechanisms to mediate conflicts, mitigate risks, and resolve issues.\nDemonstrated ability to deliver high-quality presentations and content.\nEffective stakeholder management skills and problem-solving techniques.\nAdoption of Agile and DevOps principles\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Solutions Analyst?\nWhich of the following issue and bug tracking software do you have experience with?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","247":"Provides tactical marketing and analysis support to internal customers including: customer profiling, segmentation, customer lifetime value analysis, attrition models, machine learning models, and local market opportunity analysis.\nUsing analytical and visualization software to access, transform integrate, analyze and visualize data to help solve real problems and provide business insight.\nMine data from primary and secondary sources. Clean and prune data to discard irrelevant information. Introduce new data source to improve machine learning models.\nIdentify customers for campaign targeting based on their needs and eligibility, and conduct in depth post implementation review for continues improvement and learning.\nWork closely with client to identify business requirements and translating data into informative insights and report to help solve real problems and provide business insight. Design key metrics to track business performance and identify business issue and challenges.\nSupport the campaign management from leads identification, interim tracking, and fulfillment.\nAnalyze and interpret results using standard statistical tools and techniques.\nPinpoint trends, correlations and patterns in complicated data sets\nMentoring and coaching others to improve their analytical skills.\nExperience in analyzing data trends and recommend solutions\/campaigns to create revenue or improve efficiency.\nExperience in data visualization.\nAnalytical, creative and innovative approach in solving problems\nExperience in building statistical model.\nExperience in insurance or financial services industry is preferred\nAt least 5 years of business intelligence and analytic experience in the financial industry is preferred. Candidate with supervisory experience is preferred.\nSAS\/ SQL, Tableau\/ Power BI and other analytics software (e.g. Python and R).\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nHow many years' experience do you have as a Data Analytics Manager?\nWhich of the following programming languages are you experienced in?\nHave you worked in a role which requires a sound understanding of business intelligence (BI) best practices?\nWhich of the following web analytics tools are you experienced with?\nHow many years' experience do you have using SQL queries?\nHave you worked in a role which requires experience with statistical modelling?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","248":"Designing, building, and maintaining data pipelines to collect, process, and store large datasets from various sources.\nDevelop, optimize, support, and maintain Extract, Transform, Load (ETL) processes to ensure data quality and integrity.\nMonitor and troubleshoot ETL processes to identify and resolve issues promptly, ensuring smooth operation and minimal downtime.\nIntegrate data from different sources into a cohesive and accessible data warehouse.\nMaintain clear and concise documentation for data pipelines, processes, and systems.\nWork under the close direction and supervision of senior team members to support clients' applications.\nBe responsible and accountable for task tracking, reporting, and meeting deadlines.\u00a0\nApply, maintain, and recommend improvements to development procedures and standards.\nAccept ownership for accomplishing new and different requests for personal and professional growth.\nExplore opportunities to add value to job accomplishments and contribute to team success.\nDatabase \u2013 DB2 (Preferred), Oracle (Preferred), IBM Netezza\nETL\/ELT data workflows \u2013 Data Stage (Preferred), SAP BI\nData warehouse, Data mart \u2013 including analysis of business\/users requirements, solutioning\nData design and data model\nIndependent with initiative.\nAbility to adapt to changes.\nEnjoy being challenged and to solve complex problems.\nPositive attitude with a great drive to deliver.\nPossess great sense of ownership to issues and problems.\nAptitude to grasp concepts quickly and ability to apply.\nPossess strong analysis abilities with acute sense of data analytics.\nMultiple years of experience in a professional environment performing analysis, design and development tasks on multiple platforms.\nFamiliar with data analytics, data mining concepts and machine learning algorithms.\nProficient in data design, data architecture, robust ETL\/ELT data workflows.\nWhich of the following statements best describes your right to work in Malaysia?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Data Engineer?\nWhich of the following Relational Database Management Systems (RDBMS) are you experienced with?\nHow many years' experience do you have using SQL queries?","249":"Which of the following types of qualifications do you have?\nWhich of the following statements best describes your right to work in Malaysia?\nHow many years' experience do you have as a Data Engineer?","250":"","251":"Develop a comprehensive understanding of HRD Corp\u2019s business requirements and the national-level training and development landscape to ensure data initiatives align with organisational goals.\nFormulate structured analytical frameworks and methodologies to support economic research programmes, contributing to the organisation\u2019s strategic knowledge base.\nDevelop, manage and configure advanced and predictive analytics models using various statistical techniques and specialised software tools, while driving innovation and predictive accuracy for high quality and comprehensive data.\nInterpret complex data sets and conduct comprehensive data analysis using statistical techniques and tools, such as Python, SAS, Tableau, SQL etc., depending on the requirement to optimise the efficiency and quality of reports for the consumption of the organisation and management in ensuring accurate and insightful data-driven decision-making.\nConduct in-depth data analysis and select relevant information to analyse key themes and trends using primary\/secondary\/multiple data sources and business intelligence tools, providing valuable insights for strategic decision-making.\nProduce organisational-level reports to management by in-depth data analysis and\ninterpretation that provide insights for strategic decisions and organisational performance improvement.\nDesign and visualise reports and dashboards using tools like Tableau and PowerBI to clearly and concisely communicate data findings to stakeholders, facilitating informed decision-making.\nMaintain data integrity by verifying the accuracy and consistency of data throughout the process, ensuring that all data used in analysis is reliable and valid, thereby supporting the credibility of research findings.\nContinuously improve data analysis processes and analytics models by implementing advanced analytics programming techniques, ensuring that the methodologies used are up-to-date and effective in delivering high-quality insights.\nBachelor\u2019s degree in data science, Computer Science, Statistics, Mathematics, or a related field, backed with relevant years of working experience.\nMaster\u2019s degree in above or advanced certifications in data science, machine learning, or related fields would be an added advantage.\no SAS (Statistical Analysis System) Certified Data Scientist\no SAS Certified Advanced Analytics Professional\no Open Certified Data Scientist\u00a0\no Microsoft Azure AI Fundamentals\u00a0\no IBM Data Science Professional Certificate\no CAP (Certified Analytics Professional)\u00a0\no DASCA (Data Science Council of America)\nMinimum 5-7 years of relevant working experience in conducting research and analytics function.\nRequires advanced proficiency in programming languages such as Python and other relevant statistical tools.\nProven ability in using exploratory analysis and preparing unstructured data to draw conclusions.\u00a0\nAbility to lead machine learning projects and modeling initiatives.\nExperience with data visualisation tools like Tableau and PowerBI.\nStrong analytical, critical thinking and problem-solving skills are a must.\nProficiency in data models and data sets, data cleaning methods, and handling\u00a0\nmultiple data sources.\nAbility to derive insights from complex data sets and present them clearly and concisely.\nKnowledge of additional programming languages or analytics tools is an advantage.\nRelevant experience in conducting research and analytics function would be an added advantage.\nWilling to work in\u00a0the \nHQ Office at Damansara Heights.\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nWhich of the following languages are you fluent in?\nAre you willing to undergo a pre-employment background check?\nHow much notice are you required to give your current employer?\nHow many years' experience do you have as a Research and Development Analytical Executive?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","252":"Having experience of 7+ years as senior oracle DBA\nArchitect HA and DR Solutions for PAAS services like Exadata, Autonomous Databases (ATP,ADW), RAC & Dataguard)\nInstallation and upgrade of Oracle and RAC on 10g\/11g\/12c\/18c\/19c version under Linux\/AIX platforms\nMust have oracle ASM\/ACFS implementation experience\nGood scripting skills to automate regular DBA admin tasks \u2022 Strong experience on backup utilities or tools like RMAN & EXPDP\/IMPDP, CRSCTL, SRVCTL, NetBackup, Networker\nApplying grid and DB PSU patch in standalone and multi-node RAC cluster servers\nShould have good command over speaking and writing.\nStrong experience on database and SQL queries tuning for Oracle and RAC databases\nShould have knowledge of oracle OEM 12C\/13C\nHe will be customer facing for all operational issues and activities\nStrong experience on configure and troubleshoot physical standby database using dataguard broker\nStrong experience on configure and troubleshoot golden gate replication components\nGood Grip over Tables fine tuning and troubleshooting\nImplement backup and recovery of Oracle databases for various scenarios\nAdministration over DB Objects including Tables , Clusters , Views , Procedures etc.\nGood in Impact Analysis of DB Change \/ DB Design Change etc.\nIn-depth understanding of Advanced Architectures (Multi-Node, RAC, ASM)\nGood understanding of core support processes and change management, maintain documentation standards\nMust have experience in Database tuning including I\/O, Load Analysis, ADDR, AWR, SQL Profiling etc\nResponsible for installation, upgrades (Database and RAC), patches, SR support, database tuning, concurrent manager administration, cloning\nAble to work in 24\/7 Support\nCandidate must possess at least a bachelor\u2019s degree, Post Graduate Diploma, Professional Degree (MCA \/ BE \/ BSC or SC computer science)\nOracle 10g\/11g\/12c\/18c\/19c OCP certification is a must\nHaving oracle RAC certification will be added advantage\nHaving previous banking BAU support will be added advantage\nHaving experience on additional database technologies MSSQL or DB2 or Sybase will be added advantage\nAt least 7 year(s) of working experience in the related field is required for this position.\nPreferably Senior Executives specializing in IT\/Computer \u2013 Network \/ System\/ Database Admin or equivalent.\nWhich of the following statements best describes your right to work in Malaysia?\nWhich of the following Relational Database Management Systems (RDBMS) are you experienced with?\nHow many years' experience do you have using SQL queries?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","253":"Collaborate closely with business stakeholders, including executives, managers, and subject matter experts, to understand their challenges, objectives, and opportunities for leveraging data science solutions.\u00a0\nProactively identify and define potential business use cases where data science techniques and models can provide valuable insights and drive impactful outcomes.\u00a0\nConduct in-depth discussions with business users to capture and document detailed requirements, ensuring a clear understanding of desired outcomes and deliverables.\u00a0\nUtilize advanced analytical techniques to explore and analyze relevant data sets, uncover patterns, correlations, and trends that can inform the development of effective data science solutions.\u00a0\nCreate visually compelling dashboards, reports, and presentations to communicate data-driven insights to stakeholders in a clear and understandable manner.\u00a0\nLead the design and development of data science models, algorithms, and prototypes to address identified business use cases, considering scalability, feasibility, and technical constraints.\u00a0\nCollaborate with data engineers and software developers to implement and operationalize data science models into production environments, ensuring smooth integration with existing systems and processes.\u00a0\nConduct rigorous evaluation and testing of implemented models to ensure accuracy, reliability, and alignment with business requirements. Make necessary refinements and optimizations as needed.\u00a0\nDrive the adoption of data science solutions by working closely with business users, providing training, support, and guidance on using and interpreting the outputs of implemented models.\u00a0\nA degree in Engineering, Statistics, Data Science, Applied Mathematics, Computer Science, Business Analytics or related technical field.\u00a0\nMinimum of 2 \u2013 4 years of relevant experience.\u00a0\nProficiency in statistical analysis, machine learning techniques, programming languages such as Python or R, and Deep Learning framework such as TensorFlow, PyTorch. Familiarity with data visualization tools and SQL is desirable.\u00a0\nStrong business understanding and the ability to translate business requirements into data science solutions effectively.\u00a0\nExcellent interpersonal, verbal, and written communication skills to engage with business users, explain technical concepts, and build rapport with stakeholders at all levels of the organization.\u00a0\nStrong analytical thinking and problem-solving abilities, with the capability to transform complex business challenges into actionable data science use cases.\u00a0\nProven experience in managing end-to-end data science projects, including requirements gathering, solution design, implementation, and post-deployment support.\u00a0\nLeaves: Annual Leave, Medical Leave, Hospitalization Leave, Special Leave.\u00a0\nMedical Benefits \u2013 Sunway Medical Insurance for Outpatient & Inpatient inclusive for dependents.\u00a0\nDental and Optical benefits.\u00a0\nGroup Term Life & Personal Accident Insurance Scheme.\u00a0\nExecutive Health Screening for confirmed executive.\u00a0\nFlexible Working Arrangement\/Hybrid Working Arrangement\u00a0\nSalary increment based on individual performance.\u00a0\nBonus based on company & individual performance.\u00a0\nCareer Development: Training and certification sponsored by the company, Annual Talent Review, Career Planning.\u00a0\nRewards and recognition: Long Service Award.\u00a0\nAdditional Benefits: Staff Discount (i.e. ThemePark, Hospitality, Education, Property, Medical, Retail, Food & Beverages), Sports and Recreational, Family Day, Annual Dinner, Flexible Working Arrangement for working mothers.\u00a0\nOpen communication. Young, energetic and fun working environment.\u00a0\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nHow many years' experience do you have as a data scientist?","254":"Design and develop AI models to enhance ERP functionalities.\nIntegrate AI solutions with ERP using its API.\nCollaborate with internal stakeholders to gather requirements and deliver customized solutions.\nTrain and support users in leveraging AI features.\nStay updated with the latest advancements in AI and ERP technologies.\nAI and Machine Learning:\nProficiency in machine learning algorithms and deep learning frameworks.\nExperience with NLP and predictive analytics.\nProgramming and Development:\nStrong skills in Python, R, SQL, and RESTful API development.\nExperience with data integration and ETL processes.\nData Management and Analysis:\nSkills in data preprocessing and database management.\nFamiliarity with big data technologies.\nSoftware Engineering:\nExperience with version control systems and SDLC.\nSkills in testing and validating AI models.\nAnalytical and Problem-Solving Skills:\nStrong analytical thinking and problem-solving abilities.\nCommunication and Collaboration:\nAbility to engage with stakeholders and provide training and support.\nStrong documentation skills.\nProficiency in machine learning algorithms and deep learning frameworks.\nExperience with NLP and predictive analytics.\nStrong skills in Python, R, SQL, and RESTful API development.\nExperience with data integration and ETL processes.\nSkills in data preprocessing and database management.\nFamiliarity with big data technologies.\nExperience with version control systems and SDLC.\nSkills in testing and validating AI models.\nStrong analytical thinking and problem-solving abilities.\nAbility to engage with stakeholders and provide training and support.\nStrong documentation skills.\nBachelor\u2019s or Master\u2019s degree in Computer Science, Data Science, or related field.\nRelevant certifications in AI, data science, or ERP systems.\nProven experience in AI development and ERP integration.\nFamiliarity with cloud computing platforms and DevOps practices.\nWhat's your expected monthly basic salary?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","255":"Design, develop, and deploy AI models and algorithms for various financial applications.\nCollaborate with cross-functional teams to gather and analyze data, identify opportunities for AI integration, and provide data-driven insights.\nImplement Generative AI, predictive analytics, and other AI techniques to develop advanced financial tools.\nStay up-to-date with the latest AI and machine learning trends and technologies and assess their potential applications in the Fintech industry.\nOptimize AI models for performance, scalability, and reliability.\nCreate and maintain documentation for AI solutions, including model architecture, data pipelines, and processes.\nParticipate in code reviews and provide guidance on best practices for AI development.\nBe part of building up MLOps ecosystem.\nBachelor's or Master's degree in Computer Science, Artificial Intelligence, Data Science, or a related field.\nHaving final year project or any working experience related to AI would be an advantage.\nExcellent problem-solving and analytical skills.\nEffective communication and teamwork abilities.\nQualifications\nSkills\nWorking Experience\nExpected Salary\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nHow much notice are you required to give your current employer?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","256":"Which of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as an Analytics Specialist?\nWhich of the following Relational Database Management Systems (RDBMS) are you experienced with?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","257":"You will understand our requirements and outcomes to ensure data-driven decision-making.\nYou will conduct tailored analysis for specific products and operations, define critical business metrics, track them rigorously, and recommend continuous improvements.\nYou will frame business scenarios and propose features that impact critical business processes and decisions.\nYou will transform requirements into concise insights through reports, presentations, and dashboards, and consolidate data from multiple sources to create comprehensive views for decision-making.\nYou will develop data pipelines and custom data science models to solve identified problems.\nYou will launch A\/B tests, analyse the results, and provide recommendations based on your findings.\nYou have at least 4 years of experience in data-related or quantitative fields such as Analytics, Science, Statistics, or Mathematics.\nYou are fluent with SQL, Python, R or other scripting\/programming languages.\nYou are experienced in handling large datasets and maintaining complex Extract, Transform and Load (ETL) processes.\nYou have solid statistical knowledge and hands-on experience running and analysing controlled experiments.\nYou are proficient in creating dashboards using Tableau, PowerBI or other visualisation tools.\nWe have your back with \nTerm Life Insurance \nand comprehensive \nMedical Insurance.\nWith \nGrabFlex, \ncreate a benefits package that suits your needs and aspirations.\nCelebrate moments that matter in life with loved ones through \nParental\n and \nBirthday leave\n, and give back to your communities through \nLove-all-Serve-all (LASA)\n volunteering leave\nWe have a confidential \nGrabber Assistance Programme\n to guide and uplift you and your loved ones through life's challenges.","258":"Cross-site leading role on enabling and sustain Equipment basic data with latest defined coupling\nLead team and actively maintain, provide consultancy for assigned data assets and responsible for defined data sets quality management\nInterface to FI\/IT on Equipment basic data specification\nKey user and expert for basic data system and planning model andensure high accuracy for purpose of business\nExpert and implement data governance for assigned data assets\nLead team and implement automation to improve basic data application\nAccountable for the implementation of global process and guideline. Close collaboration with cross-function and cross-site stakeholders to ensure standardization and implementation\n3- 5 years working experience in semiconductor or related field\nDegree in Computer science, Data science, Manufacturing engineering,Mathematics or other technical studies\nKnowledge of Oracle, SQL, Python, APF\/RTD, Tableau, Confluence,Outsystem\nExperience in data extract, transform, load solutions and dataanalytics solutions in industry (preferable semiconductor)\nProfound in communications and presentation of complex technical solutions to different stakeholders\nFluent in German and English\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","259":"Analyse and understand the business data requirements and translate it into a reporting solution.\nResponsible for creating an insight data\/ reporting \/ dashboard and presenting it to the respective stakeholders.\nParticipate in their current migration project from Tableau to PowerBI\nWill be supporting all global regions (global products with different business needs)\nCollaborate with data analysts, data engineers, and business stakeholders to gather requirements and ensure reports meet business needs.\n3 - 5 years of working experience\nHighly proficient in Power BI\nAble to understand, clean, transform, and prepare data from various sources to ensure it is suitable for reporting and analysis - visualisations\nAttractive remuneration package\nOpportunity for global business exposure\nDynamic working environment with career growth opportunities\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","260":"Provide leadership and guidance to the team to ensure alignment with management expectations.\nResponsible and oversee the implementation of all BI projects until Go Live.\nEnsure all projects are properly documented in accordance to the organization\u2019s project management methodology and templates.\nEnsure regular review with team on all BI projects and provide progress updates to the management.\nEnsure that the BI Servers and Datamart are in tiptop condition and able to support the smooth operation requirements.\nUp-to-date in BI Solution and market progress and provide continuous BI improvement to the organization.\nStrategize effective contingency plan to ensure information\/reporting downtime are kept to the minimum.\nSet and constant review the team\u2019s KPI and achievement.\nIdentify and plan for the team\u2019s learning\/training requirements to prepare for future goals.\nPerform relevant tasks as assigned by Management from time to time.\nAt least a Diploma in Computer related studies.\nMSSQL and Database Management certification is an added\nadvantage.\nGood communication and problem-solving skills.\nGood analytical skills to identify issues and bottlenecks.\nStrong problem-solving and analytical abilities in interpreting data.\nGood comprehension on Pivot table functionalities.\nGood team player.\nAbility to solve problems effectively, think creatively and deliver\nquality outputs in a timely manner.\nAbility to make decisions independently in a fast-paced environment.\nGood attention to detail.\nGood organizational, prioritization and time management skills.\nFast and keen learner \u2013 able to work individually and in a team.\nT-SQL Scripting\nDemonstrate proficiencies in office productivity tools (Excel, Words, Power Point).\nAt least 2 years of relevant working experience in Microsoft SQL\nenvironment, T-SQL development role.\nEnhance, refine or repurpose existing in-house data warehouse ETL\nprocess (MS SSIS).\nOptimize SQL queries, stored procedures, and database structures\nfor improved efficiency.\nStrong skills in SQL programming tasks including creating view,\nprocedures, function and packages.\nGather stakeholder requirements, translate into Business\nRequirements & Functional Requirements Documents, and\ntransform into System Design Documents.\nDesign, develop and implement innovative dashboards and analytic\nreports based on business stakeholder requirements.\nManage reporting issues and tickets reported by stakeholders by\nidentifying the potential root cause and able to coordinate and\ncommunicate with different parties to get the issues resolved.\nHave good knowledge in operational processes is an added\nadvantage.\nMonitor and maintain database health and performance using SQL\nServer Management Studio (SSMS) and other tools.\nIdentify and resolve performance bottlenecks and database-related\nissues.\nWhich of the following statements best describes your right to work in Malaysia?\nWhich of the following types of qualifications do you have?\nWhich of the following Relational Database Management Systems (RDBMS) are you experienced with?\nHow many years' experience do you have as an Information Technology Executive?\nHow many years' experience do you have using SQL queries?","261":"\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","262":"","263":"Design, develop, and deploy machine learning models and algorithms for complex and unique datasets, using various techniques such as mathematical modeling, scikit-learn, NLP, CNN, RNN, DL, RL, Transformers, GAN, LLM, RAG, prompt engineering, GPT.\nCollaborate with cross-functional teams to extract insights, identify business opportunities and provide data-driven recommendations\nStay up-to-date with the latest machine learning and AI techniques and tools\nCommunicate complex technical concepts to non-technical stakeholders in an easy-to-understand manner\nBachelor's degree or higher in Computer Science, Mathematics, Statistics, Actuarial Science, Informatics, Information Science or related fields\nStrong analytical skills and attention to detail\nParticipation in Kaggle, Mathematics Olympiad or similar competitions is a plus\nExcellent programming skills in Python, R, Java, or C++\nFamiliar with ML frameworks such as Tensorflow, Keras, PyTorch, MLFlow, AutoML, TensorRT, CUDA\nExcellent communication and collaboration skills\nExperience with designing, training, and deploying machine learning models\nCustomer centric and committed to deliver the best AI results to customers\nWhat's your expected monthly basic salary?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","264":"Responsible for the company's enterprise big data platform, building a hierarchical, flexible, and scalable enterprise big data platform.\nUnderstand business analysis requirements, design and develop corresponding data warehouses\/data marts, ETL development, and optimization work, to complete the construction of a structured, flexible, and scalable data warehouse.\nResponsible for data warehouse model design, report development, and maintenance.\nResponsible for the performance of the data warehouse system, model performance design, and optimization.\nWork together with the data product manager to solve technical problems related to business data analysis, data reporting, and data anomalies.\nDeeply understand business models, data models, and system models to improve system productivity.\nBachelor's degree or above in computer science, mathematics, or statistics; familiar with the internet industry, with over 3 years of experience in DW\/ETL\/BI work; proficient in at least one mainstream ETL\/BI solution.\nProficient in data warehouse architecture and principles, with experience in designing large-scale data warehouse architecture, model design, and performance tuning; proficient in SQL\/Hive, with good experience in SQL performance tuning, candidates with Java\/Python development experience are preferred.\nAble to proficiently use one or more mainstream databases (such as Oracle, MySQL, etc.), candidates with database design experience are preferred.\nExperience in developing big data distributed computing platforms, familiar with the principles and applications of Hadoop, Hive ecosystem products.\nSerious, responsible, and careful at work, with a good team spirit, good analytical skills, and communication skills.\nWhat's your expected monthly basic salary?\nHow many years' experience do you have as a Data Warehouse Engineer?\nWhich of the following languages are you fluent in?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","265":"Team Leadership: \nLead, mentor, and inspire a team of data scientists. Provide guidance on project priorities, technical challenges, and professional development. Foster a culture of innovation and continuous improvement within the team.\u00a0\nProject Management:\n Oversee end-to-end data science projects, ensuring timely and accurate delivery of advanced analytics and strategic insights. Coordinate with stakeholders to understand project requirements.\u00a0\nPredictive Modeling:\n Drive the development and implementation of predictive models using advanced statistical and machine learning techniques to solve complex business problems.\u00a0\nData Exploration and Preparation: \nGuide the team in exploring and preprocessing large datasets to extract meaningful features and insights.\u00a0\nCollaboration with Stakeholders: \nWork closely with cross-functional teams to understand business objectives, align data science initiatives, and communicate insights to both technical and non-technical stakeholders.\u00a0\nContinuous Improvement: \nDrive continuous improvement initiatives within the team, staying updated on the latest advancements in data science and contributing to the improvement of data science methodologies.\nLeadership Skills:\n Proven ability to lead and inspire a team of data scientists. Foster a collaborative and innovative team culture.\u00a0\nProject Management:\n Strong project management skills, including the ability to prioritize tasks, allocate resources, and meet deadlines.\u00a0\nAdvanced Analytical Skills:\n Proficient in analyzing large, complex datasets and extracting meaningful insights.\u00a0\nStatistical and Machine Learning Expertise:\n Experience in applying advanced statistical and machine learning techniques to solve real-world problems.\u00a0\nProgramming Skills: \nProficient in programming languages such as Python or R for data analysis and modeling.\u00a0\nCommunication Skills: \nExcellent communication skills to convey complex findings and insights effectively.\nEducational Background:\n Master's or Ph.D. in Data Science, Statistics, Computer Science, or a related field.\u00a0\nExperience:\n Proven experience as a Data Scientist, with a strong portfolio showcasing successful data science projects. Previous leadership or management experience is essential.\u00a0\nProgramming Proficiency: \nProficient in programming languages such as Python or R, and experience with relevant libraries and frameworks.\u00a0\nMachine Learning: \nSolid understanding and experience in applying machine learning algorithms to real-world problems.\u00a0\nCommunication Skills:\n Strong interpersonal and communication skills for effective collaboration with cross-functional teams.\u00a0\nContinuous Learning: \nStay updated with industry trends, data science techniques, and relevant tools. Attend training and development programs as needed.\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a data scientist?\nWhich of the following programming languages are you experienced in?","266":"What's your expected monthly basic salary?\nHow many years' experience do you have as an Agronomist?\nAre you willing to travel for this role when required?","267":"Build up call centre\u2019s data, analyse data indicators, and continuously optimize all data indicators;\nResponsible for setting and tracking operation targets (SLAs), analyzing abnormal data or weak links, giving early warning and improvement suggestions;\nDeeply understand the industry, improve the data analysis system, and promote the team's data analysis ability;\nAny ad-hoc duties as assigned by the Company from time to time.\nAt least 3 to 5 years of data analysis experience, large volume data analysis experience in call centre or related service industry is highly preferred;\nStrong knowledge of PowerBI and EXCEL functions for data analysis is an advantage;\nGood presentation ability to interpret and present statistical analysis (text, data and charts);\nGood at interpersonal communication, rigorous logical thinking, strong organization and coordination skills;\nIndependent, proactive, self-motivated, and able to meet tight deadline with minimal supervision.\nWhich of the following types of qualifications do you have?\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nHow many years' experience do you have as a Data Analytics Specialist?\nHow many years' experience do you have as a Power BI Developer?\nHow many years' experience do you have as an Excel Analyst?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","268":"Academic Qualification: Pursuing Bachelor's or Master's degree in Computer Science, Business Analytics, Statistics, Data Science, or any related field.\nExperience: Experience or coursework in Machine Learning, Natural Language Processing (NLP), Data Science or Analytics project.\nIT Literacy Able to work in an Agile environment with excellent time management skills.\nPersonality A positive attitude and a vibrant, creative personality.\nWhich of the following types of qualifications do you have?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","269":"create, train, and deploy machine learning models to address business challenges.\napply statistical analysis and data mining techniques to extract actionable insights.\nwork with data engineer(s) to design and maintain data pipelines.\nensure data integrity and quality through rigorous validation and processing methods.\nimplement data aggregation and enhancement processes to support analytics.\nassist in the development of AI products.\ncontinuously improve and optimize machine learning models for production use.\nbachelor's or master's degree in data science, computer science, statistics, or a related discipline\nminimum of 3 years of hands-on experience in data field\nstrong proficiency in Python and SQL\nskilled in machine learning tools like Scikit-learn, TensorFlow, PyTorch, etc\nsolid background in statistical analysis and data modeling\nexperience with data visualization platforms such as Tableau or Power BI\nfamiliar with data engineering tools like Apache Spark and Hadoop","270":"An exciting job with latest technology\nContinuous training & development of soft and hard skills\nA competitive salary, inline with your profile\nA package of benefits including healthcare insurance\nAn awesome team of colleagues & regular team building activities\nThe ability to work with the world\u2019s leading companies in technology and innovation\nAn environment where we embrace openness, transparency and grab every opportunity to have fun, while always doing what is right for our customers and partners.\nWhich of the following statements best describes your right to work in Malaysia?","271":"\u6570\u636e\u7ba1\u7406\u4e0e\u5206\u6790\uff1a\n \u4f7f\u7528 Excel \u7ba1\u7406\u548c\u5904\u7406\u5927\u578b\u6570\u636e\u96c6\uff0c\u8fdb\u884c\u6570\u636e\u6e05\u7406\uff0c\u5e76\u786e\u4fdd\u6570\u636e\u8d28\u91cf\u3002\n\u6570\u636e\u63d0\u53d6\u4e0e\u62a5\u544a\u66f4\u65b0\uff1a\n \u4ece\u5404\u79cd\u6765\u6e90\u63d0\u53d6\u6570\u636e\uff0c\u5305\u62ec\u6570\u636e\u5e93\uff0c\u5e76\u5b9a\u671f\u66f4\u65b0\u62a5\u544a\uff0c\u4ee5\u53cd\u6620\u6700\u65b0\u548c\u6700\u51c6\u786e\u7684\u89c1\u89e3\u3002\n\u62a5\u544a\u751f\u6210\uff1a\n \u5728 Excel \u4e2d\u521b\u5efa\u5e76\u81ea\u52a8\u751f\u6210\u7efc\u5408\u62a5\u544a\uff0c\u4ee5\u603b\u7ed3\u5173\u952e\u4e1a\u52a1\u6307\u6807\u548c\u8d8b\u52bf\u3002\n\u6570\u636e\u63d0\u53d6\uff1a\n \u4f7f\u7528 SQL \u4ece\u6570\u636e\u4ed3\u5e93\u4e2d\u63d0\u53d6\u548c\u5206\u6790\u6570\u636e\uff0c\u4ee5\u652f\u6301\u5404\u79cd\u4e1a\u52a1\u529f\u80fd\u548c\u62a5\u544a\u3002\n\u4eea\u8868\u677f\u521b\u5efa\uff1a\n \u8bbe\u8ba1\u548c\u7ef4\u62a4 Power BI \u4ea4\u4e92\u5f0f\u4eea\u8868\u677f\uff0c\u4ee5\u53ef\u89c6\u5316\u6570\u636e\u5e76\u5411\u5229\u76ca\u76f8\u5173\u8005\u63d0\u4f9b\u89c1\u89e3\u3002\n\u81ea\u52a8\u5316\uff1a\n \u4f7f\u7528 Python \u6216\u5176\u4ed6\u76f8\u5173\u5de5\u5177\u521b\u5efa\u5e76\u5b9e\u65bd\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u5904\u7406\u91cd\u590d\u6027\u4efb\u52a1\u3002\n\u903b\u8f91\u4e0e\u5206\u6790\u601d\u7ef4\uff1a\n \u8fd0\u7528\u5f3a\u5927\u7684\u903b\u8f91\u4e0e\u5206\u6790\u601d\u7ef4\u7406\u89e3\u5e76\u5904\u7406\u590d\u6742\u7684\u6570\u636e\u5173\u7cfb\uff0c\u786e\u4fdd\u89c1\u89e3\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002\n\u95ee\u9898\u89e3\u51b3\u4e0e\u4f18\u5316\uff1a\n \u8fd0\u7528\u521b\u9020\u6027\u548c\u6279\u5224\u6027\u601d\u7ef4\u8bc6\u522b\u73b0\u6709\u6d41\u7a0b\u4e2d\u7684\u8d8b\u52bf\u3001\u5f02\u5e38\u548c\u6539\u8fdb\u673a\u4f1a\u3002\n\u534f\u4f5c\uff1a\n \u4e0e\u8de8\u804c\u80fd\u56e2\u961f\u5bc6\u5207\u5408\u4f5c\uff0c\u4e86\u89e3\u6570\u636e\u9700\u6c42\uff0c\u5e76\u57fa\u4e8e\u5206\u6790\u63d0\u4f9b\u53ef\u884c\u7684\u5efa\u8bae\u3002\n\u5229\u76ca\u76f8\u5173\u8005\u6c9f\u901a\uff1a\n \u5411\u6280\u672f\u548c\u975e\u6280\u672f\u5229\u76ca\u76f8\u5173\u8005\u6e05\u6670\u6709\u6548\u5730\u5c55\u793a\u6570\u636e\u89c1\u89e3\u3001\u62a5\u544a\u548c\u5efa\u8bae\u3002\n\u6301\u7eed\u5b66\u4e60\uff1a\n \u5173\u6ce8\u884c\u4e1a\u8d8b\u52bf\u548c\u5206\u6790\u5de5\u5177\u7684\u8fdb\u5c55\uff0c\u6301\u7eed\u63d0\u5347\u6280\u672f\u548c\u8f6f\u6280\u80fd\u3002\nExcel\uff1a\n \u9ad8\u7ea7\u6280\u80fd\uff0c\u719f\u7ec3\u4f7f\u7528\u516c\u5f0f\u3001\u6570\u636e\u900f\u89c6\u8868\u548c\u6570\u636e\u53ef\u89c6\u5316\u3002\nSQL\uff1a\n \u57fa\u672c\u5230\u4e2d\u7ea7\u7684 SQL \u67e5\u8be2\u7f16\u5199\u77e5\u8bc6\uff0c\u8fdb\u884c\u6570\u636e\u63d0\u53d6\u548c\u5206\u6790\u3002\nPower BI\uff1a\n \u6709\u6570\u636e\u53ef\u89c6\u5316\u548c\u521b\u5efa\u4ea4\u4e92\u5f0f\u4eea\u8868\u677f\u7684\u7ecf\u9a8c\uff08\u4f18\u5148\u8003\u8651\uff09\u3002\nPython\uff1a\n \u719f\u6089\u4f7f\u7528 Python \u81ea\u52a8\u5316\u6570\u636e\u5904\u7406\uff08\u4f18\u5148\u8003\u8651\uff09\u3002\nOKR \u4efb\u52a1\u7ba1\u7406\uff1a\n \u719f\u6089 OKR \u6846\u67b6\uff0c\u4ee5\u4fbf\u5c06\u6570\u636e\u4efb\u52a1\u4e0e\u4e1a\u52a1\u76ee\u6807\u5bf9\u9f50\uff08\u4f18\u5148\u8003\u8651\uff09\u3002\n\u7ecf\u9a8c\uff1a\n \u81f3\u5c11 2 \u5e74\u6570\u636e\u5206\u6790\u6216\u76f8\u5173\u9886\u57df\u7684\u5de5\u4f5c\u7ecf\u9a8c\u3002\nData Management & Analysis:\u00a0\nUse Excel to manage and manipulate large datasets, perform data cleaning, and ensure data quality.\nData Extraction & Report Updates:\u00a0\nExtract data from various sources, including databases, and update reports regularly to reflect the most accurate and up-to-date insights.\nReport Generation:\u00a0\nCreate and automate comprehensive reports in Excel to summarize key business metrics and trends.\nData Extraction\n: Extract and analyze data from the data warehouse using SQL to support various business functions and reports.\nDashboard Creation:\u00a0\nDesign and maintain interactive dashboards in Power BI to visualize data and provide insights to stakeholders.\nAutomation: \u00a0\nCreate and implement automated solutions for repetitive tasks using Python or other relevant tools.\nLogical & Analytical Thinking:\u00a0\nApply strong logical and analytical thinking to understand and handle complex data relationships, ensuring the accuracy and reliability of insights.\nProblem Solving & Optimization:\u00a0\nUse creative and critical thinking to identify trends, anomalies, and opportunities for improvement in existing processes.\nCollaboration: \u00a0\nWork closely with cross-functional teams to understand data needs and provide actionable recommendations based on analysis.\nStakeholder Communication:\u00a0\nPresent data insights, reports, and recommendations clearly and effectively to both technical and non-technical stakeholders.\nContinuous Learning:\u00a0\nStay up to date with industry trends and advancements in analytics tools, continuously enhancing both technical and soft skills.\nExcel\n: Advanced proficiency with formulas, pivot tables, and data visualization.\nSQL\n: Basic to intermediate knowledge in writing SQL queries for data extraction and analysis.\nPower BI\n: Experience with data visualization and creating interactive dashboards (preferred).\nPython\n: Familiarity with automating data processes using Python (preferred).\nOKR Task Management\n: Familiarity with OKR frameworks for aligning data tasks with business objectives (preferred).\nExperience\n: At least \n2 years\n of experience in a data analysis role or a related field.\nWe are seeking candidates proficient in Mandarin to better serve our Mandarin-speaking customers.\nWhat's your expected monthly basic salary?\nHow many years' experience do you have as a data analyst?\nWhich of the following data analytics tools are you experienced with?","272":"You will understand business problems and convert them to ML problem space. Work with the business teams to understand workflows and requirements, and analyze data to identify patterns, trends, and anomalies that can inform automation projects and provide insights to stakeholders.\nYou will collaborate with the Data Science and Software Engineering teams to identify areas of automation and optimization within our systems, with a focus on operational efficiency and reducing manual interventions.\nYou will design, develop, and implement automation solutions that improve the efficiency of different processes, using your expertise in data analysis, machine learning, and engineering knowledge.\nYou will lead automation projects aimed at complex system fine-tuning with real market change, applying data-driven techniques to bring growth in the automated system.\nYou will use machine learning techniques to improve automation resilience and improve system performance.\nYou will work with stakeholders to define project goals and deliverables, ensuring that the automation projects align with the goals.\nAt least 3 years of experience in software engineering or data science, and experience in writing production code.\nProficiency in SQL, Python and at least one backend language like Go, Scala, Java, C++, or others.\nProficiency in data processing frameworks such as Spark or Flink.\nProficiency in ML and DL frameworks such as XGBoost or Pytorch.\nExperience in ETL pipelines for data processing, model training and serving.\nUnderstanding of optimization concepts and techniques, with experience in applying optimization methods to improve system performance.\nExperience with large-scale systems and DevOps best practices such as CI\/CD.\nWe have your back with Term Life Insurance and comprehensive Medical Insurance.\nWith GrabFlex, create a benefits package that suits your needs and aspirations.\nCelebrate moments that matter in life with loved ones through Parental and Birthday leave, and give back to your communities through Love-all-Serve-all (LASA) volunteering leave\nWe have a confidential Grabber Assistance Programme to guide and uplift you and your loved ones through life's challenges.\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","273":"Forming clear data addressable problem statements from current business problems\nGathering, validating and understanding data relevant to the problem statement\nDesigning and building data transformation pipelines and machine learning algorithms to solve the business problem\nWorking with product management and other business stakeholders to review and iterate data products to fit emerging market trends\nEvangelising appropriate ML methods and explaining them, and their associated benefits and limitations to team members from Engineering and Strategy.\nPost graduate qualification in a quantitative field (e.g. Physics, Mathematics, Bioinformatics, Computer Science)\nAdvanced data extraction and processing skills using SQL, Spark, etc\nFamiliarity with S3, EC2 and\/or EMR in AWS.\nDeep knowledge of machine learning algorithms and efficient data structures, ensembling and model performance tuning\nExperience with NLP\nConfident working at the command line in a *nix environment\nAble to write serviceable code (e.g. Scala, Go, Python, Ruby) and comfortable working with and around a professional software development teams\nGood communication and interpersonal skills with the ability to communicate with business key decision makers and product owners\nAbility to adapt quickly and thrive in an ambiguous and rapidly changing environment\nExperience with Deep Learning (particularly CNNs and RNNs)\nTrack record in working independently within an agile team environment, scoping work, making and keeping commitments to deliver against a shared agenda\nExperience working with datasets which do not fit within memory on a single machine\nHybrid working mode\nPermanent position\nMature and collaborative working culture\nExtensive employee benefits","274":"Which of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a data scientist?\nWhich of the following languages are you fluent in?","275":"Manage cost savings and efficiencies against department budget by set up specific goals in reducing cost.\nHow many years' experience do you have as a data analyst?\nWhich of the following Microsoft Office products are you experienced with?","276":" \nPrepare model performance monitoring reports and accountable for accurate, timely reporting to the management committee.\u00a0 The monitoring report served to provide insights to ensure correct use of model and facilitate critical decision making related to model recalibration or refinement.\n\n\n \nReview and on-going improvement in model performance monitoring process and automation.\n\n\n \nKnowledge of scripting particularly in SAS, Python, data savvy and able to work with huge datasets to ensure on-going model monitoring in accordance to Basel and MFRS requirements. \n\n\n \nDrill down into data\/trend identified from the data.\u00a0 Presents and discusses analysis, model monitoring results i.e. identify area of concern and its thought\/rational.\u00a0 \n\n\n \nRecommend and establish standards, guidelines and processes that improve model monitoring approaches.\n\n\n \nComprehensive awareness of the business, regulatory environment, technology and trends and ensure these are reflected in the models monitoring in timely and accurate manner. \n\n\n \nStrong communication skills.\u00a0 Ability to communicate model monitoring result through compelling narratives within the team as well as to different business leaders and provide value added input to make data driven business decision as well as model enhancement initiatives.\u00a0 \n\n\n \nSocialize with business expert to gather business insight in the respective area of model monitoring and data analytics.\n\n\n \nCollaboration within the team and related parties correspondence to data related activities i.e. data derivation rules etc. \n\n\n \nGood knowledge of relevant regulatory requirements on risk models and risk parameters.\n \nGood understanding on the respective area\u2019s business products and operations.\n \nGood analytical skills.\n \nGood statistical modeling knowledge.\n \nGood understanding of relational databases and data models.\n \nGood programming skills in data handling and statistical modeling.\n\n\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","277":"To produce regular experience analysis reports granularity for Accident and Health plans, in support of the Company\u2019s medical claim management strategy.\nTo produce regular mortality and morbidity claim experience analysis.\nTo work closely with the business and operation teams (ie. claim, underwriting, agency, marketing, etc.) to understand business requirements and to formulate an analytical work plan based on the stated objectives.\nExecute the analytical work plan end-to-end from producing data requirements, extracting data to completing the analysis and presenting the results\/analytic insights to business user.\nDevelop deep understanding of operational and business data and continuously improve existing workflow.\nPreparing reports for the management stating trends, patterns, and predictions using relevant data.\nAnalyzing local, national, and global trends that impact both the organization and the industry\nUsing statistical tools to identify, analyze, and interpret patterns and trends in complex data sets could be helpful for the diagnosis and prediction.\nA bachelor\u2019s degree in Actuarial Science, Computer Science, Information Management, IT, Applied Statistics, Finance, Accounting, Data Analytics or any related discipline.\nMinimum 6 years\u2019 experience in relevant fields (Domain knowledge: Insurance\/Takaful operations, Claims, NBUW etc)\nProficient in both written and spoken English and Bahasa.\u00a0\nProficient in Microsoft Office applications and analysis tool (SQL, Power BI, Qlik Sense, SAS, Python, Oracle DB etc)\nAbility to work with minimum supervision, flexible and agile in ways of working.\u00a0\nAnalytical skills and strong organizational abilities.\nGood presentation skills, ability to interpret and present to senior management.\nA team player with good communication skills being key in managing stakeholders.\nBackground in market research and project management skills will be an added advantage.\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following languages are you fluent in?","278":"Min 3 years working experience\nProficient in SQL, Python, Snowflake \/ Azure \/ AWS \/ GCP\nExpert in ETL processes, Data Transformation, Pipeline Development, Database Management and Data Warehousing\nCompetitive salary and benefits package\nInnovation Solutions but using cutting-edge technologies","279":"Manage critical technical maintenance activities associated with all mechanical systems to reduce operational risk and in accordance with the MOP.\u00a0\nResponsible for developing the SOP, EOP and MOP for all the critical facility equipment and activities\nProvide technical support during the construction phase, responding to RFIs and addressing any issues that arise.\nWork with the Shift team on incident investigation, follow up actions and the submission of the interim and final report to Senior management for review.\u00a0\nTo identify the parameters to be trend in the BMS\/DCIM system data and focusing on data analysis to identify opportunities to improve the reliability\/efficiency of the Critical equipment or processes.\nTo support in the Green Mark DC Certification and ensure that the existing Chiller Plant is compliance to the Green Mark requirement.\nParticipate in perform drill \/ Tabletop exercise \/ dry run-on equipment failure in developing the Emergency Operating Procedures.\nTo support and coordinate in Major activities like Annual Shutdown, Overhaul etc\u00a0\nCoordinating with multiple disciplines to ensure that projects are delivered within budget and on schedule while managing the mechanical team including HVAC, fire protection, plumbing.\nKeep abreast of changes in codes and technologies appropriate to the mechanical, plumbing and fire protection disciplines.\nAnalyse and evaluate mechanical system performance, identifying areas for improvement and making recommendations for upgrades.\nEvaluate and recommend new technologies and equipment to enhance system performance and reduce operational costs.\nCollaborate with cross-functional teams, including electrical and mechanical engineers, to ensure seamless integration of the chiller systems with other data centre infrastructure.\nAnalyse energy usage, identifying opportunities for optimization and cost savings.\nDiploma\/ degree in Mechanical Engineering\/ Building Services or equivalent.\n5 years of working experience in data center or critical infrastructure industry\u00a0like refinery or oil and gas\nFamiliar with Microsoft Excel and Word, BMS, CMMS\/ DCIM, ERP and Microsoft BI.\nExcellent in problem solving and root cause analysis.\nAbility to articulate and explain technical concepts to non-technical trained stakeholder\nWhich of the following statements best describes your right to work in Malaysia?\nHow many years' experience do you have as a mechanical engineer?","280":"\n\nDesign, develop, document and implement end-to-end data pipelines and data integration processes, both batch and real-time. This includes data analysis, data profiling, data cleansing, data lineage, data mapping, data transformation, developing ETL \/ ELT jobs and workflows, and deployment of data solutions.\n\n\nMonitor, recommend, develop and implement ways to improve data quality including reliability, efficiency and cleanliness, and to optimize and fine-tune ETL \/ ELT processes.\n\n\nRecommend, execute and deliver best practices in data management and data lifecycle processes, including modular development of ETL \/ ELT processes, coding and configuration standards, error handling and notification standards, auditing standards, and data archival standards.\n\n\nEnsure development adheres to guidelines and governance policies on data and business intelligence platform.\n\n\nCollaborate with IT team members, SMEs, vendors and internal business stakeholders, to understand data needs, gather requirements and implement data solutions to deliver business goals.\n\n\nBAU supports any data issues and change requests, documents all investigations, findings, recommendations and resolutions.\n\n\nSupport daily operation incidents and service requests.\n\n\n\n\nHands-on experience on Azure Data Solution such as Azure Synapse Spark, Synapse DB, Data Factory, Databricks, Azure Lake Storage and Power BI.\n\n\nExperience with various ETL\/ELT frameworks, data warehousing concepts, data management framework and data lifecycle processes.\n\n\nExperienced in handling and processing different types of data (structured, semi-structured and unstructured).\n\n\nUtilized Azure DevOps to implement CI\/CD workflows and deployment of ETL jobs across multiple environments.\n\n\nStrong knowledge in various database technologies (RDBMS, NoSQL and columnar).\n\n\nProficient in ETL programming languages like Python, PySpark and SQL.\n\n\nExperience with Microsoft Fabric is an added advantage.\n\n\nAbility to communicate and present technical information in a clear and unambiguous manner.\n\n\nStrong ability to work independently and cooperate with diverse teams in a multiple stakeholder environment.\n\n\nStrong sense of work ownership, high affinity with any data and a desire for constant improvements.\n\n\nExperience with SAP data sources preferred.\n\n","281":" \nAttractive remuneration, great perks, and performance incentives\n \nComprehensive medical, insurance, or social security coverage\n \nWorld-class workspaces\n \nEngaging activities and recognition programs\n \nStrong learning and development plans for your career growth\n \nPositive culture for you to #BeMore at work\n \nEasy to locate area with direct access to public transport\n \nFlexible working arrangements\n \nBe coached and mentored by experts in your field\n \nJoin a global company, winner of hundreds of industry awards\n \n \nData Architecture Design: \n \nDesign and implement effective data architecture, solutions and models to store, retrieve, cleanse, process company data that would fit the dynamic nature of our clients' data systems and analytics needs\n \nExamine and identify data architectural and processes necessities by evaluating client operations, applications, and programming.\n \nAssess data architecture implementation procedures to ensure they comply with internal and external regulations.\n \n \n \nData Governance and Quality: \n \nLead data governance initiatives to ensure data accuracy, completeness, security, and regulatory compliance.\n \nMonitor data quality, identify data inconsistencies, and implement corrective strategies to address short and long terms challenges.\n \n \n \nData Strategy and Policy Development: \n \nDevelop and implement comprehensive data management policies and procedures to ensure the integrity, availability, and confidentiality of data.\n \nCollaborate with IT security to implement robust data security measures.\n \n \n \nData Integration and Migration: \n \nPlan and execute data migration between systems, ensuring data integrity and minimal impact on ongoing business, data and development operations.\n \nOversee the integration of new data management technologies and software engineering tools into the existing system.\n \n \n \nTeam Leadership & Project Management: \n \nOversee data-related projects from inception to completion, ensuring they meet deadlines, budgets, and quality standards.\n \nManage and lead the data management team, setting clear objectives and evaluating performance.\n \nCollaborate with other departments to identify and meet data requirements, ensuring that data is accessible and useful across the organization.\n \nPrioritize and allocate resources effectively to manage multiple projects simultaneously. Any other duties and responsibilities that may be assigned to you by the management from time to time, within your category of employment in the organization.\n \n \n \n \nDesign and implement effective data architecture, solutions and models to store, retrieve, cleanse, process company data that would fit the dynamic nature of our clients' data systems and analytics needs\n \nExamine and identify data architectural and processes necessities by evaluating client operations, applications, and programming.\n \nAssess data architecture implementation procedures to ensure they comply with internal and external regulations.\n \n \nLead data governance initiatives to ensure data accuracy, completeness, security, and regulatory compliance.\n \nMonitor data quality, identify data inconsistencies, and implement corrective strategies to address short and long terms challenges.\n \n \nDevelop and implement comprehensive data management policies and procedures to ensure the integrity, availability, and confidentiality of data.\n \nCollaborate with IT security to implement robust data security measures.\n \n \nPlan and execute data migration between systems, ensuring data integrity and minimal impact on ongoing business, data and development operations.\n \nOversee the integration of new data management technologies and software engineering tools into the existing system.\n \n \nOversee data-related projects from inception to completion, ensuring they meet deadlines, budgets, and quality standards.\n \nManage and lead the data management team, setting clear objectives and evaluating performance.\n \nCollaborate with other departments to identify and meet data requirements, ensuring that data is accessible and useful across the organization.\n \nPrioritize and allocate resources effectively to manage multiple projects simultaneously. Any other duties and responsibilities that may be assigned to you by the management from time to time, within your category of employment in the organization.\n \n \nBachelor's or master's degree in Data Science, Computer Science, Information Management, or a related field.\n \nProven experience (7-10 years' experience) in data management, data governance, and significant experience in data architecture or a similar role.\n \nStrong understanding of databases, data analysis procedures, and data administration.\n \nIn-depth knowledge of data architecture design and deployment, database management, and data modeling tools.\n \nExperience with data management software and tools.\n \nExcellent leadership and team management skills.\n \nStrong communication and interpersonal abilities.\n \nHands-on approach, getting things done fast and ability to work without continual guidance.\n \nKnowledge of data privacy laws and compliance requirements.\n \nCertification in data management (e.g., CDMP) and data architecture (e.g., TOGAF, CDA) is preferred.\n \nExperience in data development & management on Cloud platforms like AWS, GCP, Azure, with basic familiarity of BI software i,e., Power BI, Looker Studio or Tableau is preferred.\n \nGood to have experience with Workflow Management i.e. Airflow and Jenkins, and CI\/CD tools such as Git and JIRA.\n \nCreative thinker with agile mind and ability to recognize inefficiencies and challenge the status quo.\n \nAttention to detail.\n \nExcellent presentation skills.\n \nWorks well in ambiguity and embraces the adventure!\n \n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","282":"\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","283":"Develop and implement data-driven strategies for workforce planning, including forecasting talent needs, succession planning, and identifying skill gaps.\nUtilize predictive analytics to anticipate future workforce trends, such as attrition, hiring needs, and capability shifts.\nDesign and implement dashboards for ongoing workforce tracking, enabling proactive decisions around hiring, promotions, and internal mobility.\nCreate comprehensive reports and visualizations that communicate actionable insights to HR leadership and business stakeholders, and prepare standard reporting capabilities.\nAutomate reporting processes and integrate various data sources to provide cohesive reporting capabilities.\nPresent data insights to non-technical stakeholders in a clear, concise manner, ensuring understanding across diverse business units.\nBuild and maintain dynamic, real-time dashboards using Power BI, providing leadership with key insights into HR metrics.\nWork closely with HR, finance, and business leaders to understand their data needs and deliver customized solutions.\nSupport the HR function in transforming data into insights that inform talent acquisition, retention, and development strategies.\u00a0\nLead and support projects focused on improving HR processes and outcomes through data-driven strategies.\nStay updated on industry trends and best practices in people analytics, incorporating them into the company's HR strategy.\nEnsure compliance with data protection laws and regulations (e.g., GDPR) when handling employee data.\nMaintain the highest level of integrity and confidentiality when dealing with sensitive employee data.\nBachelor\u2019s or Master\u2019s degree in Data Science, Statistics, or Business Administration, or a related field.\n5 years of experience in data analytics, preferably within an HR context.\nExperience with SAP SuccessFactors Reporting\nStrong experience in data-driven approaches to anticipate future workforce needs\nProven track record of delivering actionable insights that positively impact business outcomes.\nProficiency in statistical analysis software (e.g., R, Python) and Excel for complex data analyses.\nAdvanced Power BI skills, including the ability to create dynamic, user-friendly dashboards.\nStrong problem-solving and critical-thinking abilities, especially in interpreting HR data.\nExcellent communication skills, with the ability to present data to non-technical stakeholders.\nStrong project management and organizational skills, capable of managing multiple initiatives simultaneously.\nStrong attention to detail and a commitment to data accuracy.\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","284":"Which of the following statements best describes your right to work in Malaysia?\nWhich of the following types of qualifications do you have?\nWhich of the following languages are you fluent in?\nWhat is your degree CGPA range?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","285":"Architect and Design Solutions:\n\u00a0Lead the design and architecture of scalable, secure, and resilient cloud solutions across multiple cloud platforms (AWS, Azure, Google Cloud).\nData and AI Integration:\n\u00a0Develop and implement data strategies, including data lakes, data warehouses, and real-time data processing. Integrate AI and machine learning models to enhance business processes and decision-making.\nTechnical Leadership:\n\u00a0Provide technical leadership and guidance to development teams, ensuring best practices in cloud architecture, data management, and AI implementation.\nStakeholder Collaboration:\n\u00a0Collaborate with business stakeholders to understand requirements and translate them into technical solutions. Communicate complex technical concepts to non-technical stakeholders.\nInnovation and Strategy:\n\u00a0Stay updated with the latest trends and technologies in cloud computing, data, and AI. Drive innovation and strategic initiatives to enhance our technology stack.\nSecurity and Compliance:\n\u00a0Ensure that all solutions adhere to security best practices and compliance requirements. Implement robust security measures to protect data and applications.\nPerformance Optimization:\n\u00a0Monitor and optimize the performance of cloud-based applications and data systems. Identify and resolve performance bottlenecks.\nDocumentation and Training:\n\u00a0Create comprehensive documentation for designed solutions. Provide training and support to internal teams and clients.\nEducation:\n\u00a0Bachelor\u2019s or Master\u2019s degree in Computer Science, Information Technology, or a related field.\nExperience:\n\u00a0Minimum of 8 years of experience in solution architecture, with a focus on cloud computing, data management, and AI.\nCloud Expertise:\n\u00a0Proficiency in multiple cloud platforms (AWS, Azure, Google Cloud). Certification in one or more cloud platforms is a plus.\nData Management:\n\u00a0Strong experience with data architecture, data lakes, data warehouses, and real-time data processing.\nAI and Machine Learning:\n\u00a0Hands-on experience with AI and machine learning frameworks and tools (e.g., TensorFlow, PyTorch, Azure ML, AWS SageMaker).\nTechnical Skills:\n\u00a0Proficiency in programming languages such as Python, Java, or C#. Experience with containerization (Docker, Kubernetes) and CI\/CD pipelines.\nSoft Skills:\n\u00a0Excellent communication, problem-solving, and leadership skills. Ability to work collaboratively in a fast-paced environment.\nCertifications:\n\u00a0Relevant certifications in cloud computing, data management, and AI are highly desirable.\nWhich of the following types of qualifications do you have?\nWhich of the following statements best describes your right to work in Malaysia?\nWhich of the following programming languages are you experienced in?\nWhat's your expected monthly basic salary?\nHave you worked in a role which requires experience with machine learning?\nHow many years' experience do you have as a solutions architect?\nHow many years' experience do you have as an Artificial Intelligence Specialist?","286":"\n\nCollaborate with cross-functional teams to analyze and drive actions to improve End to End Yield.\n\n\nDevelop and implement algorithms and methodologies to identify and address yield issues.\n\n\nDesign and maintain web services for data analysis and visualization.\n\n\nUtilize coding skills to automate data collection, analysis, and reporting processes.\n\n\nImplement AI Techniques to develop predictive yield models and optimize production & Test performance.\n\n\nWork closely with engineering teams to optimize manufacturing processes and reduce scraps.\n\n\nMonitor and analyze production data to identify trends and potential areas for improvement.\n\n\nDrive continuous improvement initiatives to enhance yield performance and product quality.\n\n\nProvide regular reports and updates on yield metrics and performance.\n\n\nAble to sustain existing process systems will be added advantage.\n\n\n\n\nBachelor\u2019s degree in electrical engineering, Computer Engineering, or related field.\n\n\nAt least 4 years\u2019 experience in yield engineering or semiconductor manufacturing.\n\n\nStrong coding skills, with proficiency in languages such as Python, SQL, Java, or C++.\n\n\nStrong data analysis and statistical techniques.\n\n\nKnowledge of database systems and data management.\n\n\nKnowledge on AI and machine learning algorithms will be added advantage.\n\n\nFamiliarity with semiconductor assembly process and test methodology.\u00a0\n\n\nExperience in web service development and maintenance.\n\n\nExcellent communication and collaboration skills.\n\n\nAbility to work effectively in a fast-paced, dynamic environment.\n\n\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","287":"Develop, maintain, and improve dashboards to monitor and assess chatbot performance.\u00a0\nExperience with conversational design principles and best practices for chatbot user interfaces would be an advantages.\u00a0\nConduct market research to stay abreast of industry trends, competitor offerings, and emerging technologies in AI and chatbots.\nAssist in creating and maintaining product roadmaps that align with business goals and user needs.\nCommunicate product features, updates, and user feedback to both technical and non-technical stakeholders.\nContribute to the continuous improvement of our \nAI models \nand natural language processing\u00a0capabilities.\nBachelor's degree in Computer Science or a related technical field.\n5~8 years of experience in product management\n, preferably in AI, chatbots, or related technologies.\nStrong understanding of AI and Machine Learning concepts, particularly in \nnatural language processing (NLP)\n and Gen AI.\nProficiency in data analysis and interpretation, with experience using tools such as R, SQL, or Python.\nExcellent problem-solving skills with the ability to translate data insights into actionable product improvements.\nStrong project management skills.\nOutstanding communication and collaboration skills, with the ability to work effectively in cross-functional teams.\nDemonstrated ability to manage priorities and drive product outcomes.\nKnowledge of regulations related to \ndata privacy and protection\n as they apply to AI and chatbots.\nTechnical leadership and guidance in the evaluation, selection and integration of software and cloud-based technologies.\n\u00a0\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Solution Lead?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","288":"The individual will be responsible to provide ETL (extract-transfer-load) solutions and deployment of these solutions thus involve in various BI and Big Data Analytics related projects.\nThe individual will also be responsible in building necessary automation data feeds (ETL\/ELT) mechanisms for data transfer from various source applications to target applications. Perform data integration - administration, optimization of performance evaluation & monitoring to the data feeds.\nSupport existing production portfolio and troubleshoot issues in providing fixes and solutions.\nParticipate in all aspects of software product development life cycle (SDLC) including requirement gathering, work flow architecture design, development, testing, demo, training and documentation. Plan, prepare and lead User Acceptance Test (UAT) for releases and ensure testing completeness.\nThe individual should demonstrate hi-energy and desire for data mining, scripting, problem solving and data analysis.\nWork collaboratively with DBAs, infrastructure, network, data enablement teams and application BA analysts.\nCollaborate improvements in data governance, methodologies and processes. Demonstrate a deep interest and understanding of big data, data modelling, data structures, data catalogue and how to manipulate data in an efficient manner. Quick in formulating quality, feasible and practical solution fit to big data application\nAble to perform knowledge sharing of theoretical and practical.\nKnack of exploring and try out new things related to Data Analytics world.\nTraining will be provided on needed basis.\nSomeone with minimum 5 years of IT working experience especially into Business Intelligence or Data Analytics related job.\nPossess at least a Degree in Computer Science, Information Technology, Engineering or related courses.\nData integration (ETL), mining, analytics \nexperiences is A MUST. \nExperience in manipulating and analyzing complex, high-volume, high-dimensionality data from varying sources and perform ETL (extract transfer load) scripts.\nDevelopment\u00a0experience in Data Lake solutions such as Data Bricks, Azure DataLake, Fabric, AWS, Snowflake, Cloudera or Data Fabric such as Atlan, cinchy, IBM for \nBig Data solution is preferred.\nHave experience in development in Hadoop environment is an added advantage and understand components the applications in Hadoop eco-system using ETL framework components such as Nifi, Kafka, Pentaho, Spark, Datalake Insights etc.\nCloud environment \ndevelopment\u00a0 experience is y preferred. HCIA\/HCIP\/HCIE certificate in cloud computing, or equivalent certificates in the industry preferred, ep: \nAWS, Azure, GCP cloud certificates\n. Familiarity with AWS particularly services S3, Lambda, EMR, EC2 is added advantage.\nSQL \nexperience a MUST\n. Perform SQL as daily routine job. Working experiences in development database (such as MSSQL Server, Teradata or Oracle).\nHave working experience or exposure with Business Intelligence tools is highly recommended. Preferably: \nTableau, Power Query, Power BI Desktop etc\n.\nComing from manufacturing background (but not essential).\nOther preferred software skill(s): \nPHP, Python, Java, Javascript is an added advantage\n.\nStrong visualization capability and passionate in quantitative analysis \u2013 statistics, math, modeling, design etc.\nStrong written and verbal communication skills. Good communication background. Good command in English speaking, listening and writing is highly desired. Important as this needed to work will multi organization manufacturing and enterprise within the company\nMust be result oriented with strong analytical, troubleshooting & problem-solving skills with minimal supervision.\nKnowledge of Project Management and Safe Agile process is an added advantage.\nExtremely passionate with data from source to end solution\nExperienced working in a virtual team environment is a plus.\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Data Engineer?\nHow many years' experience do you have using SQL queries?\nWhich of the following programming languages are you experienced in?\nWhich of the following data analytics tools are you experienced with?\nHow much notice are you required to give your current employer?\nHow many years' experience do you have as a Data Integration Engineer?","289":"As a Data Engineer for Big Data Solutions\u00a0you will actively collaborate in the development of IT pipelines to transfer data between different systems in the international semiconductor operations network (SO)\nThis includes working on ETL (Extract \u2013 Transfer \u2013 Load) development for Hadoop ecosystem, SQL and other related technologies\nSupport in developing and programming a custom ETL framework in Python\nWork with customer departments and senior management to understand business objectives and requirements of the organization and develop solutions\nCollaborate with IT departments from different plants worldwide to roll out our developed solutions to the semiconductor IPN\nBe part of an agile development team and take responsibility for tasks defined by the product owner\nUniversity Degree (Bachelor\/Master) in Information Technology or comparable qualifications\nCandidate posses 3-5 years similar work experience in the same field\nGood communication skills (Verbal and Written) especially in meetings and reviews with all levels and departments\nAble to work in an intercultural team\nStrong interest in modern technologies, agile mindset and ability to work under pressure\nReliability and flexibility to work in a pioneer team\nKnowledge of programming language like Python, Java, C++\nExperience with working in a Hadoop Ecosystem (eg. PySpark, Airflow, Kafka)\nStructured and independent way of working, analytical skills to grasp complex interrelationships\nWillingness to take over responsibility\nExperience with project management tools and processes\nTechnical background within semiconductor business\nFluent in English (written and spoken), German skills are a plus\u00a0\nLeave Entitlement e.g: Annual Leave, Medical Leave and etc\nCompany Insurances and etc","290":"What's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as an Information Technology Business Analyst?\nWhich of the following languages are you fluent in?\nHave you worked in a role which requires a sound understanding of the software development lifecycle?\nHow would you rate your English language skills?\nWhich of the following Microsoft Office products are you experienced with?\nHow many years' experience do you have using SQL queries?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","291":"Act as the Level 1 & Level 2 Application Support for applications like ERP\nProvide training to end users.\nInvolve in analyzing problems escalated from Level 1 and finding solutions.\nInvolve in working and communicating with the vendor whenever a problem cannot be resolved locally.\nSupport local application development and support across the product supply and commercial processes\nUnderstanding in the areas of application programming, database, and system design.\nUse Excel to create a required dashboard.\nUpdate website info as and when needed\nDegree in Computer Science, Information Technology, or any relevant discipline.\nAt least 2 years of experience in supporting and delivering IT applications, preferably prior experience working on ERP system\nExperience in Epicor will be an added advantage.\nAdvanced knowledge of Excel is preferred.\nAssists in the enforcement of project deadlines and schedules.\nAd-hoc tasks assigned by superior\nProficiency in English, Bahasa Malaysia, and Mandarin in both written and oral.\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as an Information Technology Business Analyst?\nHow would you rate your English language skills?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","292":"Conduct research on strategic and competitiveness issues, including macroeconomics, microeconomics, sustainable development, societal well-being, planetary health and climate, health and well-being, future of work, poverty and inequality, justice and equity, emerging science, technology and innovation, foresight exercises, etc.\nContribute to consulting projects based on project requirements.\nAssist in designing and implementing research outputs, including policy briefs, working papers, conference presentations, and peer-reviewed journal articles.\nUndertake data collection and ensure ethical practices in collection, storage, sharing, and dissemination.\nPerform data analysis using appropriate methods. Quantitative work may involve modelling and statistical analysis with R, EViews, STATA, or Python, while qualitative work may include focus groups, interviews, and thematic analysis with NVivo or ATLAS.ti.\nDerive and deliver key insights for final project deliverables such as slides and reports.\nConduct workshops and training for the Institute and University.\nBachelor's degree with a focus on empirical analysis (Fresh graduates are welcome to apply).\nPossesses a good understanding of policies, programmes, and theoretical foundations of strategy competitiveness across Sunway IGSC\u2019s three primary work domains: Economy, Society, and Environment.\nProficient in English (fluency in Bahasa Malaysia or an additional language is an added advantage).\nStrong critical thinking and problem-solving skills.\nProficient in the latest data analysis methods, with a solid understanding of data structures and processing techniques.\u00a0\nStrong interest and capability in both quantitative and qualitative research methodologies.\nExceptional written and verbal communication skills, with the ability to engage and collaborate effectively with a diverse range of stakeholders.\nProven track record as a valuable team member, combined with the ability to exercise sound judgement, initiative, and independence in various tasks.\nStrong organizational abilities, including effective prioritization, time management, and planning skills to consistently meet tight deadlines.","293":"Provides on-going training and technical support of our Epicor ERP system and in-house developed MES system, and tooling management system.\nDevelop dashboards and reports to support department and business needs\nPerforms routine maintenance, patch updates, and day-to-day maintenance work on all ERP and integration platforms.\nWork closely with corporate IT in China to ensure all the IT policies, procedures and standards are in consistence in place.\u00a0\nCustomize and configure Epicor ERP modules to align with the organization's specific business needs.\nAssist with implementing, maintaining, supporting, and troubleshooting application systems as assigned.\nFacilitates training of end users and testing of business applications\nPerform other duties as assigned.\nBS in Computer Science\/Information Systems or equivalent technical experience preferred\nExperience with ERP systems is highly desirable, Minimum 2+ years' experience in ERP support & development area required. Prior consulting experience in ERP implementation is a plus\nStrong analytical and problem-solving skills\nGood verbal, presentation and written communication skills\u00a0\nExperience in Systems Analysis & troubleshooting\nBusiness Intelligence tool skills, e.g. QlikView is an added advantage\nWhich of the following types of qualifications do you have?\nWhich of the following statements best describes your right to work in Malaysia?\nHave you worked in a role which requires a sound understanding of business intelligence (BI) best practices?\nWhat's your expected monthly basic salary?\nHave you worked in a role which requires Qlikview development experience?\nHow many years' experience do you have as an Application Suport Analyst?\nHow many years' experience do you have in an application support function?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","294":"\n\nDesign, develop, document and implement end-to-end data pipelines and data integration processes, both batch and real-time. This includes data analysis, data profiling, data cleansing, data lineage, data mapping, data transformation, developing ETL \/ ELT jobs and workflows, and deployment of data solutions.\n\n\nMonitor, recommend, develop and implement ways to improve data quality including reliability, efficiency and cleanliness, and to optimize and fine-tune ETL \/ ELT processes.Recommend, execute and deliver best practices in data management and data lifecycle processes, including modular development of ETL \/ ELT processes, coding and configuration standards, error handling and notification standards, auditing standards, and data archival standards.\n\n\nEnsure development adheres to guidelines and governance policies on data and business intelligence platform.\n\n\nCollaborate with IT team members, SMEs, vendors and internal business stakeholders, to understand data needs, gather requirements and implement data solutions to deliver business goals.\n\n\nBAU supports any data issues and change requests, documents all investigations, findings, recommendations and resolutions.\n\n\nSupport daily operation incidents and service requests.\n\n\n\n\nHands-on experience on Azure Data Solution such as Azure Synapse Spark, Synapse DB, Data Factory, Databricks, Azure Lake Storage and Power BI.\n\n\nExperience with various ETL\/ELT frameworks, data warehousing concepts, data management framework and data lifecycle processes.\n\n\nExperienced in handling and processing different types of data (structured, semi-structured and unstructured).\n\n\nUtilized Azure DevOps to implement CI\/CD workflows and deployment of ETL jobs across multiple environments.\n\n\nStrong knowledge in various database technologies (RDBMS, NoSQL and columnar).\n\n\nProficient in ETL programming languages like Python, PySpark and SQL.\n\n\nExperience with Microsoft Fabric is an added advantage.\n\n\nAbility to communicate and present technical information in a clear and unambiguous manner.\n\n\nStrong ability to work independently and cooperate with diverse teams in a multiple stakeholder environment.\n\n\nStrong sense of work ownership, high affinity with any data and a desire for constant improvements.\n\n\nExperience with SAP data sources preferred.\n\n","295":"Take ML models\/algorithms from conception to production, by designing and implementing ML microservices and pipelines in production environment.\u00a0\nDevelop pipelines for continuous operation, feedback and monitoring of ML models leveraging best practices from the CI\/CD vertical within the MLOps domain.\u00a0\u00a0\nThis can include monitoring for data drift, triggering model retraining and setting up rollbacks.\u00a0\nMaintain and continuously optimize live productive ML services with a focus on scalability, availability, and reliability.\u00a0\nStrive for automation and cloud operation readiness.\u00a0\nCollaborate with data scientists and data engineers to deliver ML models in productive services.\u00a0\nStay updated with the latest trends and technologies in AI\/ML, GenAI and MLOps to drive innovation and system enhancements.\u00a0\nBachelor's degree in computer science or equivalent. A minimum of 4 years' experience in software engineering or machine learning engineering is preferred.\u00a0\nStrong programming skills in Python, Java and SQL variants, with knowledge of design patterns, code optimization, and object-oriented design.\u00a0\nProficiency in ML operationalization and orchestration (MLOps) tools, techniques and platforms. This includes scaling delivery of models, managing and governing ML Models, and managing and scaling AI platforms\u00a0\nFamiliar with Kubernetes and Docker, including installation, deployment, configuration and optimization.\u00a0\nGood understanding of ML frameworks such as TensorFlow, Keras, PyTorch.\u00a0\nExperience in web development skills such as HTML, Javascript, CSS is a big plus.\u00a0\nKnowledge of AWS cloud platform would be an advantage.\u00a0\nWhich of the following statements best describes your right to work in Malaysia?\nWhat's your expected monthly basic salary?\nWhich of the following types of qualifications do you have?\nHow many years' experience do you have as a Machine Learning Engineer?\nWhich of the following programming languages are you experienced in?\nHave you worked in a role which requires experience with machine learning?\nHow many years' experience do you have using SQL queries?\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","296":"Min 3 years working experience\nProficient in SQL, Python, and cloud platforms like AWS, Azure, Snowflake, GCP\nFamiliar with BI Tools like Power BI and Tableau\nCompetitive salary and benefits package\nHybrid and supportive working culture\nInnovation Solutions but using cutting-edge technologies","297":"Work with property develop and construction-related datasets in regards to sustainability.\nConduct exploratory data analysis to uncover methods of data extraction, uncover insights and patterns throught data visualisation.\n.Implement prompt engineering and python to extract data from source files\nCreate informative data visualizations using Power BI and Autodesk tools to communicate findings effectively .\nCreate dashboards which are able to effectively monitor project's data.\nWork closely with cross-functional teams to build and communicate usage of the dashboards.\nDocument code, methodologies, and results to allow continuity of work.\nCover sustainability implementation in the organisation assigned.\nCandidates currently pursuing a Bachelor's in Computer Science, or a related field.\nHave basic understanding of prompt engineering and\u00a0 Power BI.\nAbility to process and analyse large volume of data and information.\u00a0\nPossess an excellent command of the English language (written & oral), strong communication, negotiation, and analytical skills.\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","298":"Bachelor or Master or PhD in Science (Biochemistry, Molecular Biology, Biotechnology, Biology, Biomedical Science) or equivalent.\nTypically, >4 years of relevant experience or >1 year of direct experience in NGS and qPCR applications.\nStrong understanding of molecular biology, analytical chemistry and laboratory equipment and procedures.\nRequires in-depth knowledge and experience in related field and ability to work independently.\nRequires having good teamwork with other competency such as instrument hardware\/software engineers.\nRequires basic knowledge in statistical analysis software (e.g., R, Python, SAS, Minitab), experimental design principles, hypothesis testing, and other statistical methods.\nRequires basic knowledge on data analytics and visualization (e.g. Macro, VBA, Power BI, Power Apps). Any relevant or similar data analytics and visualization could be considered.\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","299":"\n\nDesign and develop software applications for data collection, processing, analysis, and visualization.\n\n\nIntegrate various manufacturing and testing equipment with our data systems to automate data capture.\n\n\n\n\nImplement algorithms to process and analyze large datasets to identify trends, anomalies, and efficiency opportunities.\n\n\nDevelop machine learning models to predict machine failures and optimize manufacturing processes.\n\n\n\n\nWork closely with manufacturing engineers to understand their data needs and provide technical solutions.\n\n\nContinuously explore new technologies and methodologies to improve existing systems and processes.\n\n\n\n\nCreate dashboards and reports to visualize key manufacturing metrics and insights.\n\n\nEnsure accurate and timely delivery of data to stakeholders.\n\n\n\n\nEnsure the integrity and reliability of data analytics software.\n\n\nDocument code, processes, and methodologies for knowledge sharing.\n\n\n\n\nCollaborate with IT and operational teams to integrate software solutions into the broader company ecosystem.\n\n\nParticipate in cross-functional teams to support broader organizational goals.\n\n\n\n\nBachelor's\/Master\u2019s degree in Computer Science\/Engineering, data science or related field\n\n\n2-5 years of experience in software development\u00a0\n\n\nExperience in programming language (python, R) and database (SQL) to perform data mining and analysis.\n\n\nKnowledge of statistical techniques in data science (regression, properties of distribution)\n\n\nKnowledge in machine learning techniques (neural network, machine learning)\n\n\nStrong analytic skills and problem-solving skills.\n\n\n\n\nRole descriptions\n\n\nSalary insights\n\n\nTools to help you prepare for jobs\n\n","300":"\n\nAnalyze and organize raw data\u00a0\n\n\nBuild data systems and pipelines\n\n\nEvaluate business needs and objectives\n\n\nInterpret trends and patterns\n\n\nConduct complex data analysis and report on results\u00a0\n\n\nPrepare data for prescriptive and predictive modeling\n\n\nBuild algorithms and prototypes\n\n\nCombine raw information from different sources\n\n\nExplore ways to enhance data quality and reliability\n\n\nIdentify opportunities for data acquisition\n\n\nDevelop analytical tools and programs\n\n\nCollaborate with data scientists and architects on several projects\n\n\n\n\nProficiency in Oracle PL\/SQL and MS SQL.\n\n\nExperience with data replication, change data capture, and performance tuning.\n\n\nFamiliarity with data warehousing concepts and ETL processes.\n\n\n(Good to have) Knowledge of Kafka and Debezium.\n\n","301":"","302":"Propose new solutions and evolve existing ones to be used by product features that relies on AI.\nDesign and conduct online and offline evaluations to compare variants of AI-based product features.\nAssist the team in delivering AI projects that help the business to achieve their strategic priorities.\nBreak-down the problems and propose directions to overcome obstacles.\nResearch, build, deploy and maintain integrated AI solutions.\nWork with Strategy, Product, Operation, Commercial and Software Development teams to address a variety of challenging business problems.\nCollaborate with teams from Asia and Pacific partners.\nStrengthen secure coding practises and tooling within team.\nForm clear data addressable problem statements from current business problems.\nGather, validate, and understand data relevant to the problem statement.\nDesign and build data transformation pipelines and machine learning algorithms to solve the business problem.\nWork with product management and other business partners to review and iterate data products to fit emerging market trends.\nActively communicate with others in an effective, timely manner with empathy.\nContribute to the safety, work-life balance, and well-being of other team members.\nHelp creates a safe space for sharing of different opinions\/feedback.\nImprove your abilities through tutoring and set example behaviour.\nActively seek out learning opportunities for self and others through inviting and providing regular feedback.\nContributor to the data science community at SEEK Pass and SEEK (e.g., Open-source projects, Mentoring, Guilds).\nImproves self and others through inviting and providing regular feedback.\nA MSc or PhD qualification in Computer Science, Computational Physics, Mathematics, Statistics, or a related field.\n3 years of experience in Data Science.\nConsistently write effective, testable, readable, and secure code in one of the following programming languages: Python, Go, Scala, C\/C++, or Java\nSound experience using modern data science practices.\nExperience with Data Modeling and Machine Learning algorithms.\nExperience applying continuous integration and continuous deployment (CI\/CD).\nCommercial experience with agile methodologies (e.g., Kanban, Lean, Scrum).\nCommercial experience working in multi-functional technology teams.\nProactively manages professional growth and identifies learning opportunities.\nExperience giving and receiving effective feedback and contributing to others\u2019 learning.\nAbility to perform data exploratory analysis for proof of concepts and to Communicate the results to a diverse audience.\nPractice with:\nComputer Vision processing libraries (e.g., OpenCV, YOLO, Rekognition)\nRelational database such as MySQL or PostgreSQL.\nAmazon Web Services (e.g. EC2, S3, VPC, SQS, SageMaker).\nDistributed processing framework such as Hadoop or Spark.\nContainer package such as Docker.\nDeployment tools, such as Ansible, Terraform and Chef.\nUses data to support decision-making.\nKnowledge in:\nComputer Vision\nDeep Learning\nNatural Language Processing\nOptimisation\nAbility to adapt quickly and manage an environment of rapid change and development.\nComfortable in a start-up environment with ambiguity, minimum viable products, and rapid iteration & learning\nExperience integrating with third-party systems.\nExperience working with encrypted and highly sensitive data.\nSupport of flexible working, including a mix of office and work from home days depending on your role.\nThe opportunity to work from anywhere for up to 4 weeks per financial year\nCasual dress \u2013 every day"},"location":{"0":"Selangor","1":"Kuala Lumpur City Centre","2":"Petaling","3":"Kuala Lumpur","4":"Selangor","5":"Kuala Lumpur City Centre","6":"Petaling","7":"Kuala Lumpur","8":"Penang","9":"Kuala Lumpur","10":"Petaling","11":"Kuala Lumpur City Centre","12":"Kuala Lumpur","13":"Kuala Lumpur","14":"Penang Island","15":"Kuala Lumpur","16":"Kuala Lumpur","17":"Penang Island","18":"Penang","19":"Kuala Lumpur","20":"Kuala Lumpur","21":"Kuala Lumpur","22":"Kuala Lumpur","23":"Shamelin Perkasa","24":"Petaling","25":"Kuala Lumpur","26":"Kuala Lumpur City Centre","27":"Kuala Lumpur","28":"Kulim District","29":"Penang Island","30":"Kuala Lumpur","31":"Kuala Lumpur","32":"Gombak District","33":"Bangsar South","34":"Kuala Selangor District","35":"Kuala Lumpur City Centre","36":"Penang","37":"Klang District","38":"Petaling","39":"Bukit Jalil","40":"Kuala Lumpur","41":"Kuala Lumpur","42":"Melaka Tengah","43":"Kuala Lumpur","44":"Kuala Lumpur","45":"Petaling","46":"Kuala Lumpur","47":"Kuala Lumpur Sentral","48":"Petaling","49":"Kuala Lumpur","50":"Sepang","51":"Petaling","52":"Bandar Malaysia","53":"Kuala Lumpur","54":"Kuala Lumpur","55":"Petaling","56":"Kulim District","57":"Kuala Lumpur","58":"Shah Alam\/Subang","59":"Kulim District","60":"Kuala Lumpur","61":"Kuala Lumpur","62":"Kuala Lumpur","63":"Petaling","64":"Batu Pahat District","65":"Bangsar South","66":"Petaling","67":"Kuala Lumpur","68":"Kuala Lumpur Sentral","69":"Kuala Lumpur","70":"Petaling","71":"Kuala Lumpur","72":"Johor Bahru District","73":"Kuala Lumpur City Centre","74":"Kuala Lumpur City Centre","75":"Kuala Lumpur City Centre","76":"Kuala Lumpur","77":"Kulai District","78":"Kuala Lumpur","79":"Kuala Lumpur","80":"Kuala Lumpur City Centre","81":"Seberang Perai","82":"Sepang","83":"Kuala Lumpur City Centre","84":"Seberang Perai","85":"Mid Valley City","86":"Kuala Lumpur","87":"Seberang Perai","88":"Penang Island","89":"Johor Bahru District","90":"Petaling","91":"Kulim District","92":"Kuala Lumpur","93":"Penang","94":"Kuala Lumpur","95":"Petaling","96":"Penang Island","97":"Seberang Perai","98":"Kuala Lumpur City Centre","99":"Kuala Lumpur","100":"Kuala Lumpur City Centre","101":"Selangor","102":"Kuala Lumpur City Centre","103":"Petaling","104":"Kuala Lumpur","105":"Selangor","106":"Kuala Lumpur City Centre","107":"Petaling","108":"Kuala Lumpur","109":"Penang","110":"Kuala Lumpur","111":"Petaling","112":"Kuala Lumpur City Centre","113":"Kuala Lumpur","114":"Kuala Lumpur","115":"Penang Island","116":"Kuala Lumpur","117":"Kuala Lumpur","118":"Penang Island","119":"Penang","120":"Kuala Lumpur","121":"Kuala Lumpur","122":"Kuala Lumpur","123":"Kuala Lumpur","124":"Shamelin Perkasa","125":"Petaling","126":"Kuala Lumpur","127":"Kuala Lumpur City Centre","128":"Kuala Lumpur","129":"Kulim District","130":"Penang Island","131":"Kuala Lumpur","132":"Kuala Lumpur","133":"Gombak District","134":"Bangsar South","135":"Kuala Selangor District","136":"Kuala Lumpur City Centre","137":"Penang","138":"Klang District","139":"Petaling","140":"Bukit Jalil","141":"Kuala Lumpur","142":"Kuala Lumpur","143":"Melaka Tengah","144":"Kuala Lumpur","145":"Kuala Lumpur","146":"Petaling","147":"Kuala Lumpur","148":"Kuala Lumpur Sentral","149":"Petaling","150":"Kuala Lumpur","151":"Sepang","152":"Petaling","153":"Bandar Malaysia","154":"Kuala Lumpur","155":"Kuala Lumpur","156":"Petaling","157":"Kulim District","158":"Kuala Lumpur","159":"Shah Alam\/Subang","160":"Kulim District","161":"Kuala Lumpur","162":"Kuala Lumpur","163":"Kuala Lumpur","164":"Petaling","165":"Batu Pahat District","166":"Bangsar South","167":"Petaling","168":"Kuala Lumpur","169":"Kuala Lumpur Sentral","170":"Kuala Lumpur","171":"Petaling","172":"Kuala Lumpur","173":"Johor Bahru District","174":"Kuala Lumpur City Centre","175":"Kuala Lumpur City Centre","176":"Kuala Lumpur City Centre","177":"Kuala Lumpur","178":"Kulai District","179":"Kuala Lumpur","180":"Kuala Lumpur","181":"Kuala Lumpur City Centre","182":"Seberang Perai","183":"Sepang","184":"Kuala Lumpur City Centre","185":"Seberang Perai","186":"Mid Valley City","187":"Kuala Lumpur","188":"Seberang Perai","189":"Penang Island","190":"Johor Bahru District","191":"Petaling","192":"Kulim District","193":"Kuala Lumpur","194":"Penang","195":"Kuala Lumpur","196":"Petaling","197":"Penang Island","198":"Seberang Perai","199":"Kuala Lumpur City Centre","200":"Kuala Lumpur","201":"Kuala Lumpur City Centre","202":"Selangor","203":"Kuala Lumpur City Centre","204":"Petaling","205":"Kuala Lumpur","206":"Selangor","207":"Kuala Lumpur City Centre","208":"Petaling","209":"Kuala Lumpur","210":"Penang","211":"Kuala Lumpur","212":"Petaling","213":"Kuala Lumpur City Centre","214":"Kuala Lumpur","215":"Kuala Lumpur","216":"Penang Island","217":"Kuala Lumpur","218":"Kuala Lumpur","219":"Penang Island","220":"Penang","221":"Kuala Lumpur","222":"Kuala Lumpur","223":"Kuala Lumpur","224":"Kuala Lumpur","225":"Shamelin Perkasa","226":"Petaling","227":"Kuala Lumpur","228":"Kuala Lumpur City Centre","229":"Kuala Lumpur","230":"Kulim District","231":"Penang Island","232":"Kuala Lumpur","233":"Kuala Lumpur","234":"Gombak District","235":"Bangsar South","236":"Kuala Selangor District","237":"Kuala Lumpur City Centre","238":"Penang","239":"Klang District","240":"Petaling","241":"Bukit Jalil","242":"Kuala Lumpur","243":"Kuala Lumpur","244":"Melaka Tengah","245":"Kuala Lumpur","246":"Kuala Lumpur","247":"Petaling","248":"Kuala Lumpur","249":"Kuala Lumpur Sentral","250":"Petaling","251":"Kuala Lumpur","252":"Sepang","253":"Petaling","254":"Bandar Malaysia","255":"Kuala Lumpur","256":"Kuala Lumpur","257":"Petaling","258":"Kulim District","259":"Kuala Lumpur","260":"Shah Alam\/Subang","261":"Kulim District","262":"Kuala Lumpur","263":"Kuala Lumpur","264":"Kuala Lumpur","265":"Petaling","266":"Batu Pahat District","267":"Bangsar South","268":"Petaling","269":"Kuala Lumpur","270":"Kuala Lumpur Sentral","271":"Kuala Lumpur","272":"Petaling","273":"Kuala Lumpur","274":"Johor Bahru District","275":"Kuala Lumpur City Centre","276":"Kuala Lumpur City Centre","277":"Kuala Lumpur City Centre","278":"Kuala Lumpur","279":"Kulai District","280":"Kuala Lumpur","281":"Kuala Lumpur","282":"Kuala Lumpur City Centre","283":"Seberang Perai","284":"Sepang","285":"Kuala Lumpur City Centre","286":"Seberang Perai","287":"Mid Valley City","288":"Kuala Lumpur","289":"Seberang Perai","290":"Penang Island","291":"Johor Bahru District","292":"Petaling","293":"Kulim District","294":"Kuala Lumpur","295":"Penang","296":"Kuala Lumpur","297":"Petaling","298":"Penang Island","299":"Seberang Perai","300":"Kuala Lumpur City Centre","301":"Kuala Lumpur","302":"Kuala Lumpur City Centre"},"category":{"0":"Information & Communication Technology","1":"Information & Communication Technology","2":"Information & Communication Technology","3":"Science & Technology","4":"Information & Communication Technology","5":"Information & Communication Technology","6":"Science & Technology","7":"Science & Technology","8":"Science & Technology","9":"Information & Communication Technology","10":"Science & Technology","11":"Retail & Consumer Products","12":"Science & Technology","13":"Information & Communication Technology","14":"Information & Communication Technology","15":"Information & Communication Technology","16":"Science & Technology","17":"Information & Communication Technology","18":"Administration & Office Support","19":"Information & Communication Technology","20":"Information & Communication Technology","21":"Information & Communication Technology","22":"Information & Communication Technology","23":"Information & Communication Technology","24":"Information & Communication Technology","25":"Information & Communication Technology","26":"Information & Communication Technology","27":"Information & Communication Technology","28":"Information & Communication Technology","29":"Information & Communication Technology","30":"Information & Communication Technology","31":"Consulting & Strategy","32":"Information & Communication Technology","33":"Information & Communication Technology","34":"Science & Technology","35":"Information & Communication Technology","36":"Manufacturing, Transport & Logistics","37":"Consulting & Strategy","38":"Information & Communication Technology","39":"Information & Communication Technology","40":"Information & Communication Technology","41":"Information & Communication Technology","42":"Information & Communication Technology","43":"Information & Communication Technology","44":"Information & Communication Technology","45":"Banking & Financial Services","46":"Information & Communication Technology","47":"Information & Communication Technology","48":"Information & Communication Technology","49":"Consulting & Strategy","50":"Information & Communication Technology","51":"Information & Communication Technology","52":"Science & Technology","53":"Information & Communication Technology","54":"Information & Communication Technology","55":"Information & Communication Technology","56":"Science & Technology","57":"Information & Communication Technology","58":"Information & Communication Technology","59":"Information & Communication Technology","60":"Information & Communication Technology","61":"Information & Communication Technology","62":"Information & Communication Technology","63":"Science & Technology","64":"Farming, Animals & Conservation","65":"Information & Communication Technology","66":"Information & Communication Technology","67":"Information & Communication Technology","68":"Information & Communication Technology","69":"Information & Communication Technology","70":"Information & Communication Technology","71":"Science & Technology","72":"Information & Communication Technology","73":"Information & Communication Technology","74":"Banking & Financial Services","75":"Insurance & Superannuation","76":"Information & Communication Technology","77":"Engineering","78":"Information & Communication Technology","79":"Information & Communication Technology","80":"Banking & Financial Services","81":"Information & Communication Technology","82":"Insurance & Superannuation","83":"Information & Communication Technology","84":"Engineering","85":"Information & Communication Technology","86":"Information & Communication Technology","87":"Information & Communication Technology","88":"Information & Communication Technology","89":"Information & Communication Technology","90":"Consulting & Strategy","91":"Information & Communication Technology","92":"Information & Communication Technology","93":"Information & Communication Technology","94":"Information & Communication Technology","95":"Science & Technology","96":"Science & Technology","97":"Information & Communication Technology","98":"Information & Communication Technology","99":"Consulting & Strategy","100":"Information & Communication Technology","101":"Information & Communication Technology","102":"Information & Communication Technology","103":"Information & Communication Technology","104":"Science & Technology","105":"Information & Communication Technology","106":"Information & Communication Technology","107":"Science & Technology","108":"Science & Technology","109":"Science & Technology","110":"Information & Communication Technology","111":"Science & Technology","112":"Retail & Consumer Products","113":"Science & Technology","114":"Information & Communication Technology","115":"Information & Communication Technology","116":"Information & Communication Technology","117":"Science & Technology","118":"Information & Communication Technology","119":"Administration & Office Support","120":"Information & Communication Technology","121":"Information & Communication Technology","122":"Information & Communication Technology","123":"Information & Communication Technology","124":"Information & Communication Technology","125":"Information & Communication Technology","126":"Information & Communication Technology","127":"Information & Communication Technology","128":"Information & Communication Technology","129":"Information & Communication Technology","130":"Information & Communication Technology","131":"Information & Communication Technology","132":"Consulting & Strategy","133":"Information & Communication Technology","134":"Information & Communication Technology","135":"Science & Technology","136":"Information & Communication Technology","137":"Manufacturing, Transport & Logistics","138":"Consulting & Strategy","139":"Information & Communication Technology","140":"Information & Communication Technology","141":"Information & Communication Technology","142":"Information & Communication Technology","143":"Information & Communication Technology","144":"Information & Communication Technology","145":"Information & Communication Technology","146":"Banking & Financial Services","147":"Information & Communication Technology","148":"Information & Communication Technology","149":"Information & Communication Technology","150":"Consulting & Strategy","151":"Information & Communication Technology","152":"Information & Communication Technology","153":"Science & Technology","154":"Information & Communication Technology","155":"Information & Communication Technology","156":"Information & Communication Technology","157":"Science & Technology","158":"Information & Communication Technology","159":"Information & Communication Technology","160":"Information & Communication Technology","161":"Information & Communication Technology","162":"Information & Communication Technology","163":"Information & Communication Technology","164":"Science & Technology","165":"Farming, Animals & Conservation","166":"Information & Communication Technology","167":"Information & Communication Technology","168":"Information & Communication Technology","169":"Information & Communication Technology","170":"Information & Communication Technology","171":"Information & Communication Technology","172":"Science & Technology","173":"Information & Communication Technology","174":"Information & Communication Technology","175":"Banking & Financial Services","176":"Insurance & Superannuation","177":"Information & Communication Technology","178":"Engineering","179":"Information & Communication Technology","180":"Information & Communication Technology","181":"Banking & Financial Services","182":"Information & Communication Technology","183":"Insurance & Superannuation","184":"Information & Communication Technology","185":"Engineering","186":"Information & Communication Technology","187":"Information & Communication Technology","188":"Information & Communication Technology","189":"Information & Communication Technology","190":"Information & Communication Technology","191":"Consulting & Strategy","192":"Information & Communication Technology","193":"Information & Communication Technology","194":"Information & Communication Technology","195":"Information & Communication Technology","196":"Science & Technology","197":"Science & Technology","198":"Information & Communication Technology","199":"Information & Communication Technology","200":"Consulting & Strategy","201":"Information & Communication Technology","202":"Information & Communication Technology","203":"Information & Communication Technology","204":"Information & Communication Technology","205":"Science & Technology","206":"Information & Communication Technology","207":"Information & Communication Technology","208":"Science & Technology","209":"Science & Technology","210":"Science & Technology","211":"Information & Communication Technology","212":"Science & Technology","213":"Retail & Consumer Products","214":"Science & Technology","215":"Information & Communication Technology","216":"Information & Communication Technology","217":"Information & Communication Technology","218":"Science & Technology","219":"Information & Communication Technology","220":"Administration & Office Support","221":"Information & Communication Technology","222":"Information & Communication Technology","223":"Information & Communication Technology","224":"Information & Communication Technology","225":"Information & Communication Technology","226":"Information & Communication Technology","227":"Information & Communication Technology","228":"Information & Communication Technology","229":"Information & Communication Technology","230":"Information & Communication Technology","231":"Information & Communication Technology","232":"Information & Communication Technology","233":"Consulting & Strategy","234":"Information & Communication Technology","235":"Information & Communication Technology","236":"Science & Technology","237":"Information & Communication Technology","238":"Manufacturing, Transport & Logistics","239":"Consulting & Strategy","240":"Information & Communication Technology","241":"Information & Communication Technology","242":"Information & Communication Technology","243":"Information & Communication Technology","244":"Information & Communication Technology","245":"Information & Communication Technology","246":"Information & Communication Technology","247":"Banking & Financial Services","248":"Information & Communication Technology","249":"Information & Communication Technology","250":"Information & Communication Technology","251":"Consulting & Strategy","252":"Information & Communication Technology","253":"Information & Communication Technology","254":"Science & Technology","255":"Information & Communication Technology","256":"Information & Communication Technology","257":"Information & Communication Technology","258":"Science & Technology","259":"Information & Communication Technology","260":"Information & Communication Technology","261":"Information & Communication Technology","262":"Information & Communication Technology","263":"Information & Communication Technology","264":"Information & Communication Technology","265":"Science & Technology","266":"Farming, Animals & Conservation","267":"Information & Communication Technology","268":"Information & Communication Technology","269":"Information & Communication Technology","270":"Information & Communication Technology","271":"Information & Communication Technology","272":"Information & Communication Technology","273":"Science & Technology","274":"Information & Communication Technology","275":"Information & Communication Technology","276":"Banking & Financial Services","277":"Insurance & Superannuation","278":"Information & Communication Technology","279":"Engineering","280":"Information & Communication Technology","281":"Information & Communication Technology","282":"Banking & Financial Services","283":"Information & Communication Technology","284":"Insurance & Superannuation","285":"Information & Communication Technology","286":"Engineering","287":"Information & Communication Technology","288":"Information & Communication Technology","289":"Information & Communication Technology","290":"Information & Communication Technology","291":"Information & Communication Technology","292":"Consulting & Strategy","293":"Information & Communication Technology","294":"Information & Communication Technology","295":"Information & Communication Technology","296":"Information & Communication Technology","297":"Science & Technology","298":"Science & Technology","299":"Information & Communication Technology","300":"Information & Communication Technology","301":"Consulting & Strategy","302":"Information & Communication Technology"},"subcategory":{"0":"Engineering - Software","1":"Developers\/Programmers","2":"Engineering - Software","3":"Other","4":"Engineering - Software","5":"Business\/Systems Analysts","6":"Mathematics, Statistics & Information Sciences","7":"Mathematics, Statistics & Information Sciences","8":"Mathematics, Statistics & Information Sciences","9":"Business\/Systems Analysts","10":"Mathematics, Statistics & Information Sciences","11":"Planning","12":"Mathematics, Statistics & Information Sciences","13":"Networks & Systems Administration","14":"Business\/Systems Analysts","15":"Engineering - Software","16":"Mathematics, Statistics & Information Sciences","17":"Engineering - Software","18":"Administrative Assistants","19":"Business\/Systems Analysts","20":"Engineering - Software","21":"Business\/Systems Analysts","22":"Business\/Systems Analysts","23":"Business\/Systems Analysts","24":"Engineering - Software","25":"Engineering - Software","26":"Engineering - Software","27":"Engineering - Software","28":"Developers\/Programmers","29":"Business\/Systems Analysts","30":"Business\/Systems Analysts","31":"Analysts","32":"Engineering - Software","33":"Networks & Systems Administration","34":"Modelling & Simulation","35":"Business\/Systems Analysts","36":"Analysis & Reporting","37":"Corporate Development","38":"Database Development & Administration","39":"Developers\/Programmers","40":"Engineering - Software","41":"Database Development & Administration","42":"Developers\/Programmers","43":"Developers\/Programmers","44":"Business\/Systems Analysts","45":"Analysis & Reporting","46":"Engineering - Software","47":"Engineering - Software","48":"Business\/Systems Analysts","49":"Analysts","50":"Database Development & Administration","51":"Other","52":"Mathematics, Statistics & Information Sciences","53":"Architects","54":"Database Development & Administration","55":"Other","56":"Mathematics, Statistics & Information Sciences","57":"Database Development & Administration","58":"Business\/Systems Analysts","59":"Networks & Systems Administration","60":"Programme & Project Management","61":"Engineering - Software","62":"Engineering - Software","63":"Mathematics, Statistics & Information Sciences","64":"Agronomy & Farm Services","65":"Database Development & Administration","66":"Other","67":"Developers\/Programmers","68":"Engineering - Software","69":"Business\/Systems Analysts","70":"Engineering - Software","71":"Mathematics, Statistics & Information Sciences","72":"Engineering - Software","73":"Database Development & Administration","74":"Compliance & Risk","75":"Actuarial","76":"Other","77":"Mechanical Engineering","78":"Engineering - Software","79":"Database Development & Administration","80":"Analysis & Reporting","81":"Business\/Systems Analysts","82":"Actuarial","83":"Architects","84":"Electrical\/Electronic Engineering","85":"Other","86":"Engineering - Software","87":"Engineering - Software","88":"Business\/Systems Analysts","89":"Business\/Systems Analysts","90":"Analysts","91":"Business\/Systems Analysts","92":"Engineering - Software","93":"Engineering - Software","94":"Consultants","95":"Mathematics, Statistics & Information Sciences","96":"Laboratory & Technical Services","97":"Engineering - Software","98":"Consultants","99":"Management & Change Consulting","100":"Other","101":"Engineering - Software","102":"Developers\/Programmers","103":"Engineering - Software","104":"Other","105":"Engineering - Software","106":"Business\/Systems Analysts","107":"Mathematics, Statistics & Information Sciences","108":"Mathematics, Statistics & Information Sciences","109":"Mathematics, Statistics & Information Sciences","110":"Business\/Systems Analysts","111":"Mathematics, Statistics & Information Sciences","112":"Planning","113":"Mathematics, Statistics & Information Sciences","114":"Networks & Systems Administration","115":"Business\/Systems Analysts","116":"Engineering - Software","117":"Mathematics, Statistics & Information Sciences","118":"Engineering - Software","119":"Administrative Assistants","120":"Business\/Systems Analysts","121":"Engineering - Software","122":"Business\/Systems Analysts","123":"Business\/Systems Analysts","124":"Business\/Systems Analysts","125":"Engineering - Software","126":"Engineering - Software","127":"Engineering - Software","128":"Engineering - Software","129":"Developers\/Programmers","130":"Business\/Systems Analysts","131":"Business\/Systems Analysts","132":"Analysts","133":"Engineering - Software","134":"Networks & Systems Administration","135":"Modelling & Simulation","136":"Business\/Systems Analysts","137":"Analysis & Reporting","138":"Corporate Development","139":"Database Development & Administration","140":"Developers\/Programmers","141":"Engineering - Software","142":"Database Development & Administration","143":"Developers\/Programmers","144":"Developers\/Programmers","145":"Business\/Systems Analysts","146":"Analysis & Reporting","147":"Engineering - Software","148":"Engineering - Software","149":"Business\/Systems Analysts","150":"Analysts","151":"Database Development & Administration","152":"Other","153":"Mathematics, Statistics & Information Sciences","154":"Architects","155":"Database Development & Administration","156":"Other","157":"Mathematics, Statistics & Information Sciences","158":"Database Development & Administration","159":"Business\/Systems Analysts","160":"Networks & Systems Administration","161":"Programme & Project Management","162":"Engineering - Software","163":"Engineering - Software","164":"Mathematics, Statistics & Information Sciences","165":"Agronomy & Farm Services","166":"Database Development & Administration","167":"Other","168":"Developers\/Programmers","169":"Engineering - Software","170":"Business\/Systems Analysts","171":"Engineering - Software","172":"Mathematics, Statistics & Information Sciences","173":"Engineering - Software","174":"Database Development & Administration","175":"Compliance & Risk","176":"Actuarial","177":"Other","178":"Mechanical Engineering","179":"Engineering - Software","180":"Database Development & Administration","181":"Analysis & Reporting","182":"Business\/Systems Analysts","183":"Actuarial","184":"Architects","185":"Electrical\/Electronic Engineering","186":"Other","187":"Engineering - Software","188":"Engineering - Software","189":"Business\/Systems Analysts","190":"Business\/Systems Analysts","191":"Analysts","192":"Business\/Systems Analysts","193":"Engineering - Software","194":"Engineering - Software","195":"Consultants","196":"Mathematics, Statistics & Information Sciences","197":"Laboratory & Technical Services","198":"Engineering - Software","199":"Consultants","200":"Management & Change Consulting","201":"Other","202":"Engineering - Software","203":"Developers\/Programmers","204":"Engineering - Software","205":"Other","206":"Engineering - Software","207":"Business\/Systems Analysts","208":"Mathematics, Statistics & Information Sciences","209":"Mathematics, Statistics & Information Sciences","210":"Mathematics, Statistics & Information Sciences","211":"Business\/Systems Analysts","212":"Mathematics, Statistics & Information Sciences","213":"Planning","214":"Mathematics, Statistics & Information Sciences","215":"Networks & Systems Administration","216":"Business\/Systems Analysts","217":"Engineering - Software","218":"Mathematics, Statistics & Information Sciences","219":"Engineering - Software","220":"Administrative Assistants","221":"Business\/Systems Analysts","222":"Engineering - Software","223":"Business\/Systems Analysts","224":"Business\/Systems Analysts","225":"Business\/Systems Analysts","226":"Engineering - Software","227":"Engineering - Software","228":"Engineering - Software","229":"Engineering - Software","230":"Developers\/Programmers","231":"Business\/Systems Analysts","232":"Business\/Systems Analysts","233":"Analysts","234":"Engineering - Software","235":"Networks & Systems Administration","236":"Modelling & Simulation","237":"Business\/Systems Analysts","238":"Analysis & Reporting","239":"Corporate Development","240":"Database Development & Administration","241":"Developers\/Programmers","242":"Engineering - Software","243":"Database Development & Administration","244":"Developers\/Programmers","245":"Developers\/Programmers","246":"Business\/Systems Analysts","247":"Analysis & Reporting","248":"Engineering - Software","249":"Engineering - Software","250":"Business\/Systems Analysts","251":"Analysts","252":"Database Development & Administration","253":"Other","254":"Mathematics, Statistics & Information Sciences","255":"Architects","256":"Database Development & Administration","257":"Other","258":"Mathematics, Statistics & Information Sciences","259":"Database Development & Administration","260":"Business\/Systems Analysts","261":"Networks & Systems Administration","262":"Programme & Project Management","263":"Engineering - Software","264":"Engineering - Software","265":"Mathematics, Statistics & Information Sciences","266":"Agronomy & Farm Services","267":"Database Development & Administration","268":"Other","269":"Developers\/Programmers","270":"Engineering - Software","271":"Business\/Systems Analysts","272":"Engineering - Software","273":"Mathematics, Statistics & Information Sciences","274":"Engineering - Software","275":"Database Development & Administration","276":"Compliance & Risk","277":"Actuarial","278":"Other","279":"Mechanical Engineering","280":"Engineering - Software","281":"Database Development & Administration","282":"Analysis & Reporting","283":"Business\/Systems Analysts","284":"Actuarial","285":"Architects","286":"Electrical\/Electronic Engineering","287":"Other","288":"Engineering - Software","289":"Engineering - Software","290":"Business\/Systems Analysts","291":"Business\/Systems Analysts","292":"Analysts","293":"Business\/Systems Analysts","294":"Engineering - Software","295":"Engineering - Software","296":"Consultants","297":"Mathematics, Statistics & Information Sciences","298":"Laboratory & Technical Services","299":"Engineering - Software","300":"Consultants","301":"Management & Change Consulting","302":"Other"},"type":{"0":"Full time","1":"Full time","2":"Full time","3":"Contract\/Temp","4":"Full time","5":"Full time","6":"Full time","7":"Full time","8":"Full time","9":"Full time","10":"Contract\/Temp","11":"Full time","12":"Full time","13":"Contract\/Temp","14":"Full time","15":"Full time","16":"Full time","17":"Full time","18":"Part time","19":"Full time","20":"Full time","21":"Full time","22":"Full time","23":"Full time","24":"Full time","25":"Contract\/Temp","26":"Full time","27":"Full time","28":"Full time","29":"Full time","30":"Full time","31":"Full time","32":"Full time","33":"Full time","34":"Full time","35":"Full time","36":"Full time","37":"Full time","38":"Full time","39":"Full time","40":"Full time","41":"Contract\/Temp","42":"Contract\/Temp","43":"Contract\/Temp","44":"Full time","45":"Full time","46":"Full time","47":"Full time","48":"Contract\/Temp","49":"Full time","50":"Full time","51":"Full time","52":"Contract\/Temp","53":"Full time","54":"Full time","55":"Full time","56":"Full time","57":"Full time","58":"Full time","59":"Full time","60":"Contract\/Temp","61":"Full time","62":"Full time","63":"Full time","64":"Contract\/Temp","65":"Full time","66":"Contract\/Temp","67":"Full time","68":"Full time","69":"Full time","70":"Full time","71":"Full time","72":"Full time","73":"Full time","74":"Full time","75":"Full time","76":"Full time","77":"Full time","78":"Full time","79":"Full time","80":"Full time","81":"Full time","82":"Contract\/Temp","83":"Contract\/Temp","84":"Full time","85":"Full time","86":"Full time","87":"Full time","88":"Contract\/Temp","89":"Full time","90":"Full time","91":"Full time","92":"Full time","93":"Full time","94":"Full time","95":"Contract\/Temp","96":"Full time","97":"Full time","98":"Full time","99":"Part time","100":"Full time","101":"Full time","102":"Full time","103":"Full time","104":"Contract\/Temp","105":"Full time","106":"Full time","107":"Full time","108":"Full time","109":"Full time","110":"Full time","111":"Contract\/Temp","112":"Full time","113":"Full time","114":"Contract\/Temp","115":"Full time","116":"Full time","117":"Full time","118":"Full time","119":"Part time","120":"Full time","121":"Full time","122":"Full time","123":"Full time","124":"Full time","125":"Full time","126":"Contract\/Temp","127":"Full time","128":"Full time","129":"Full time","130":"Full time","131":"Full time","132":"Full time","133":"Full time","134":"Full time","135":"Full time","136":"Full time","137":"Full time","138":"Full time","139":"Full time","140":"Full time","141":"Full time","142":"Contract\/Temp","143":"Contract\/Temp","144":"Contract\/Temp","145":"Full time","146":"Full time","147":"Full time","148":"Full time","149":"Contract\/Temp","150":"Full time","151":"Full time","152":"Full time","153":"Contract\/Temp","154":"Full time","155":"Full time","156":"Full time","157":"Full time","158":"Full time","159":"Full time","160":"Full time","161":"Contract\/Temp","162":"Full time","163":"Full time","164":"Full time","165":"Contract\/Temp","166":"Full time","167":"Contract\/Temp","168":"Full time","169":"Full time","170":"Full time","171":"Full time","172":"Full time","173":"Full time","174":"Full time","175":"Full time","176":"Full time","177":"Full time","178":"Full time","179":"Full time","180":"Full time","181":"Full time","182":"Full time","183":"Contract\/Temp","184":"Contract\/Temp","185":"Full time","186":"Full time","187":"Full time","188":"Full time","189":"Contract\/Temp","190":"Full time","191":"Full time","192":"Full time","193":"Full time","194":"Full time","195":"Full time","196":"Contract\/Temp","197":"Full time","198":"Full time","199":"Full time","200":"Part time","201":"Full time","202":"Full time","203":"Full time","204":"Full time","205":"Contract\/Temp","206":"Full time","207":"Full time","208":"Full time","209":"Full time","210":"Full time","211":"Full time","212":"Contract\/Temp","213":"Full time","214":"Full time","215":"Contract\/Temp","216":"Full time","217":"Full time","218":"Full time","219":"Full time","220":"Part time","221":"Full time","222":"Full time","223":"Full time","224":"Full time","225":"Full time","226":"Full time","227":"Contract\/Temp","228":"Full time","229":"Full time","230":"Full time","231":"Full time","232":"Full time","233":"Full time","234":"Full time","235":"Full time","236":"Full time","237":"Full time","238":"Full time","239":"Full time","240":"Full time","241":"Full time","242":"Full time","243":"Contract\/Temp","244":"Contract\/Temp","245":"Contract\/Temp","246":"Full time","247":"Full time","248":"Full time","249":"Full time","250":"Contract\/Temp","251":"Full time","252":"Full time","253":"Full time","254":"Contract\/Temp","255":"Full time","256":"Full time","257":"Full time","258":"Full time","259":"Full time","260":"Full time","261":"Full time","262":"Contract\/Temp","263":"Full time","264":"Full time","265":"Full time","266":"Contract\/Temp","267":"Full time","268":"Contract\/Temp","269":"Full time","270":"Full time","271":"Full time","272":"Full time","273":"Full time","274":"Full time","275":"Full time","276":"Full time","277":"Full time","278":"Full time","279":"Full time","280":"Full time","281":"Full time","282":"Full time","283":"Full time","284":"Contract\/Temp","285":"Contract\/Temp","286":"Full time","287":"Full time","288":"Full time","289":"Full time","290":"Contract\/Temp","291":"Full time","292":"Full time","293":"Full time","294":"Full time","295":"Full time","296":"Full time","297":"Contract\/Temp","298":"Full time","299":"Full time","300":"Full time","301":"Part time","302":"Full time"},"salary":{"0":"","1":"RM\u00a09,500 \u2013 RM\u00a014,000 per month","2":"","3":"$10 per hour","4":"","5":"","6":"","7":"","8":"","9":"RM\u00a04,000 \u2013 RM\u00a06,000 per month","10":"RM\u00a0900 \u2013 RM\u00a01,000 per month","11":"RM\u00a03,800 \u2013 RM\u00a05,000 per month","12":"RM\u00a011,000 \u2013 RM\u00a014,000 per month","13":"RM\u00a012,000 \u2013 RM\u00a018,000 per month","14":"","15":"RM\u00a05,000 \u2013 RM\u00a07,000 per month","16":"","17":"","18":"RM\u00a040 \u2013 RM\u00a045 per hour","19":"MYR8k - MYR9k p.m.","20":"RM\u00a07,000 \u2013 RM\u00a09,000 per month","21":"RM 3,500 \u2013 RM 6,000 per month","22":"","23":"","24":"","25":"RM\u00a09,000 \u2013 RM\u00a013,000 per month","26":"RM\u00a08,000 \u2013 RM\u00a010,000 per month","27":"RM\u00a06,800 \u2013 RM\u00a09,500 per month","28":"","29":"","30":"RM\u00a05,000 \u2013 RM\u00a07,000 per month","31":"RM\u00a05,500 \u2013 RM\u00a08,250 per month","32":"","33":"","34":"","35":"","36":"","37":"RM\u00a04,000 \u2013 RM\u00a04,500 per month","38":"$8000.0 - $10000.0 p.m.","39":"","40":"RM\u00a08,000 \u2013 RM\u00a012,000 per month","41":"RM\u00a08,000 \u2013 RM\u00a010,000 per month","42":"","43":"RM\u00a07,000 \u2013 RM\u00a09,000 per month","44":"","45":"","46":"","47":"RM\u00a08,000 \u2013 RM\u00a012,000 per month","48":"RM\u00a04,000 \u2013 RM\u00a06,000 per month","49":"","50":"","51":"","52":"RM\u00a06,000 \u2013 RM\u00a09,000 per month","53":"","54":"","55":"","56":"Transport,Dental,Optical,Meal Allowance","57":"","58":"","59":"","60":"","61":"RM\u00a04,000 \u2013 RM\u00a06,000 per month","62":"","63":"RM\u00a015,000 \u2013 RM\u00a020,000 per month","64":"","65":"","66":"RM\u00a0900 per month","67":"","68":"","69":"RM\u00a04,000 \u2013 RM\u00a06,000 per month","70":"","71":"","72":"RM\u00a06,500 \u2013 RM\u00a08,000 per month","73":"","74":"","75":"","76":"Competitive salary and benefits package","77":"","78":"","79":"","80":"","81":"","82":"","83":"RM\u00a014,000 \u2013 RM\u00a020,000 per month","84":"","85":"","86":"","87":"","88":"RM\u00a04,500 \u2013 RM\u00a06,500 per month","89":"","90":"","91":"","92":"","93":"RM\u00a05,000 \u2013 RM\u00a07,000 per month","94":"Competitive salary and benefits package","95":"","96":"","97":"","98":"","99":"","100":"","101":"","102":"RM\u00a09,500 \u2013 RM\u00a014,000 per month","103":"","104":"$10 per hour","105":"","106":"","107":"","108":"","109":"","110":"RM\u00a04,000 \u2013 RM\u00a06,000 per month","111":"RM\u00a0900 \u2013 RM\u00a01,000 per month","112":"RM\u00a03,800 \u2013 RM\u00a05,000 per month","113":"RM\u00a011,000 \u2013 RM\u00a014,000 per month","114":"RM\u00a012,000 \u2013 RM\u00a018,000 per month","115":"","116":"RM\u00a05,000 \u2013 RM\u00a07,000 per month","117":"","118":"","119":"RM\u00a040 \u2013 RM\u00a045 per hour","120":"MYR8k - MYR9k p.m.","121":"RM\u00a07,000 \u2013 RM\u00a09,000 per month","122":"RM 3,500 \u2013 RM 6,000 per month","123":"","124":"","125":"","126":"RM\u00a09,000 \u2013 RM\u00a013,000 per month","127":"RM\u00a08,000 \u2013 RM\u00a010,000 per month","128":"RM\u00a06,800 \u2013 RM\u00a09,500 per month","129":"","130":"","131":"RM\u00a05,000 \u2013 RM\u00a07,000 per month","132":"RM\u00a05,500 \u2013 RM\u00a08,250 per month","133":"","134":"","135":"","136":"","137":"","138":"RM\u00a04,000 \u2013 RM\u00a04,500 per month","139":"$8000.0 - $10000.0 p.m.","140":"","141":"RM\u00a08,000 \u2013 RM\u00a012,000 per month","142":"RM\u00a08,000 \u2013 RM\u00a010,000 per month","143":"","144":"RM\u00a07,000 \u2013 RM\u00a09,000 per month","145":"","146":"","147":"","148":"RM\u00a08,000 \u2013 RM\u00a012,000 per month","149":"RM\u00a04,000 \u2013 RM\u00a06,000 per month","150":"","151":"","152":"","153":"RM\u00a06,000 \u2013 RM\u00a09,000 per month","154":"","155":"","156":"","157":"Transport,Dental,Optical,Meal Allowance","158":"","159":"","160":"","161":"","162":"RM\u00a04,000 \u2013 RM\u00a06,000 per month","163":"","164":"RM\u00a015,000 \u2013 RM\u00a020,000 per month","165":"","166":"","167":"RM\u00a0900 per month","168":"","169":"","170":"RM\u00a04,000 \u2013 RM\u00a06,000 per month","171":"","172":"","173":"RM\u00a06,500 \u2013 RM\u00a08,000 per month","174":"","175":"","176":"","177":"Competitive salary and benefits package","178":"","179":"","180":"","181":"","182":"","183":"","184":"RM\u00a014,000 \u2013 RM\u00a020,000 per month","185":"","186":"","187":"","188":"","189":"RM\u00a04,500 \u2013 RM\u00a06,500 per month","190":"","191":"","192":"","193":"","194":"RM\u00a05,000 \u2013 RM\u00a07,000 per month","195":"Competitive salary and benefits package","196":"","197":"","198":"","199":"","200":"","201":"","202":"","203":"RM\u00a09,500 \u2013 RM\u00a014,000 per month","204":"","205":"$10 per hour","206":"","207":"","208":"","209":"","210":"","211":"RM\u00a04,000 \u2013 RM\u00a06,000 per month","212":"RM\u00a0900 \u2013 RM\u00a01,000 per month","213":"RM\u00a03,800 \u2013 RM\u00a05,000 per month","214":"RM\u00a011,000 \u2013 RM\u00a014,000 per month","215":"RM\u00a012,000 \u2013 RM\u00a018,000 per month","216":"","217":"RM\u00a05,000 \u2013 RM\u00a07,000 per month","218":"","219":"","220":"RM\u00a040 \u2013 RM\u00a045 per hour","221":"MYR8k - MYR9k p.m.","222":"RM\u00a07,000 \u2013 RM\u00a09,000 per month","223":"RM 3,500 \u2013 RM 6,000 per month","224":"","225":"","226":"","227":"RM\u00a09,000 \u2013 RM\u00a013,000 per month","228":"RM\u00a08,000 \u2013 RM\u00a010,000 per month","229":"RM\u00a06,800 \u2013 RM\u00a09,500 per month","230":"","231":"","232":"RM\u00a05,000 \u2013 RM\u00a07,000 per month","233":"RM\u00a05,500 \u2013 RM\u00a08,250 per month","234":"","235":"","236":"","237":"","238":"","239":"RM\u00a04,000 \u2013 RM\u00a04,500 per month","240":"$8000.0 - $10000.0 p.m.","241":"","242":"RM\u00a08,000 \u2013 RM\u00a012,000 per month","243":"RM\u00a08,000 \u2013 RM\u00a010,000 per month","244":"","245":"RM\u00a07,000 \u2013 RM\u00a09,000 per month","246":"","247":"","248":"","249":"RM\u00a08,000 \u2013 RM\u00a012,000 per month","250":"RM\u00a04,000 \u2013 RM\u00a06,000 per month","251":"","252":"","253":"","254":"RM\u00a06,000 \u2013 RM\u00a09,000 per month","255":"","256":"","257":"","258":"Transport,Dental,Optical,Meal Allowance","259":"","260":"","261":"","262":"","263":"RM\u00a04,000 \u2013 RM\u00a06,000 per month","264":"","265":"RM\u00a015,000 \u2013 RM\u00a020,000 per month","266":"","267":"","268":"RM\u00a0900 per month","269":"","270":"","271":"RM\u00a04,000 \u2013 RM\u00a06,000 per month","272":"","273":"","274":"RM\u00a06,500 \u2013 RM\u00a08,000 per month","275":"","276":"","277":"","278":"Competitive salary and benefits package","279":"","280":"","281":"","282":"","283":"","284":"","285":"RM\u00a014,000 \u2013 RM\u00a020,000 per month","286":"","287":"","288":"","289":"","290":"RM\u00a04,500 \u2013 RM\u00a06,500 per month","291":"","292":"","293":"","294":"","295":"RM\u00a05,000 \u2013 RM\u00a07,000 per month","296":"Competitive salary and benefits package","297":"","298":"","299":"","300":"","301":"","302":""}}